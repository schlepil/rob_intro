<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Principle of Optimality - an overview | ScienceDirect Topics</title><meta name="robots" content="INDEX,FOLLOW,NOARCHIVE,NOODP,NOYDIR"><link rel="canonical" href="https://www.sciencedirect.com/topics/engineering/principle-of-optimality" /><meta name="SDTech" content="Proudly brought to you by the SD Technology team in London, Dayton, and Amsterdam">
<link rel='shortcut icon' href='https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/13/images/favSD.ico' type='image/x-icon' />
<link rel='icon' href='https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/13/images/favSD.ico' type='image/x-icon'>
<link rel='stylesheet' href='https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/726ce6de1d3d8212198e38c30b5dd31f20fa8fff/style.css'>

<script crossorigin="anonymous" type="2975f070f66ff17199d53d68-text/javascript">
        (function(){
          if(window.BOOMR && window.BOOMR.version){return;}
          var dom,doc,where,iframe = document.createElement('iframe'),win = window;

          function boomerangSaveLoadTime(e) {
            win.BOOMR_onload=(e && e.timeStamp) || new Date().getTime();
          }
          if (win.addEventListener) {
            win.addEventListener("load", boomerangSaveLoadTime, false);
          } else if (win.attachEvent) {
            win.attachEvent("onload", boomerangSaveLoadTime);
          }

          iframe.src = "javascript:false";
          iframe.title = ""; iframe.role="presentation";
          (iframe.frameElement || iframe).style.cssText = "width:0;height:0;border:0;display:none;";
          where = document.getElementsByTagName('script')[0];
          where.parentNode.insertBefore(iframe, where);

          try {
            doc = iframe.contentWindow.document;
          } catch(e) {
            dom = document.domain;
            iframe.src="javascript:var d=document.open();d.domain='"+dom+"';void(0);";
            doc = iframe.contentWindow.document;
          }
          doc.open()._l = function() {
            var js = this.createElement("script");
            if(dom) this.domain = dom;
            js.id = "boomr-if-as";
            js.src = 'https://c.go-mpulse.net/boomerang/2FBN2-NKMGU-EJKY8-ZANKZ-SUJZF';
            js.crossorigin = "anonymous";
            BOOMR_lstart=new Date().getTime();
            this.body.appendChild(js);
          };
          doc.write('<body onload="document._l();">');
          doc.close();
        })();
      </script>

<script id="adobe-dtm" src= https://assets.adobedtm.com/376c5346e33126fdb6b2dbac81e307cbacfd7935/satelliteLib-b7cfe8df39a4e5eec5536bba80e13f4b6fa0dd7c.js type="2975f070f66ff17199d53d68-text/javascript"></script>
</head>
<body>
<!--[if lt IE 9]>
      <div id="ie8Warning" class="warning">
        <script>function ie8click() {
  const node = document.getElementById('ie8Warning');
  document.cookie = 'ie_warning_state=1';
  node.parentNode.removeChild(node);
}</script>
        <p>Please note that Internet Explorer version 8.x is not supported as of January 1, 2016.
        Please refer to <a href="https://service.elsevier.com/app/answers/detail/a_id/9831/supporthub/sciencedirect/">this page</a> for more information.</p>
        <a class="warning-close" onclick="ie8click()" title="Close IE warning">&times;</a>
      </div>
    <![endif]-->
<a class="skip" title="Skip to Main content" href="#main_content">
Skip to Main content
</a>
<div id="react-root" class="react-root"><div data-reactroot=""><div id="header"><div class="customer-banner u-hide-from-lg"><div id="library-banner" class="desktop-library-banner u-show-from-lg u-margin-xs-right"><div class="customer-banner-container text-xs"><a target="_blank" href="http://www.jubil.upmc.fr/" rel="nofollow" class="img-customer-banner"><img src="www.jubil.upmc.fr/modules/resources/download/bupmc/docs-bu/logos/logo-bupmc-vert-2.jpg" alt="You have institutional access" width="234" height="60" /></a></div></div><div class="mobile-library-banner move-top move-center u-bg-grey1 u-padding-xxl-ver u-hide-from-lg u-display-block" id="mobile-library-banner" style="width:100%;position:relative"><div class="customer-banner-container text-xs move-middle move-center"><a target="_blank" href="http://www.jubil.upmc.fr/" rel="nofollow" class="img-customer-banner"><img src="www.jubil.upmc.fr/modules/resources/download/bupmc/docs-bu/logos/logo-bupmc-vert-2.jpg" alt="You have institutional access" width="234" height="60" /></a></div><button id="close-library-banner" class="button button-anchor move-top move-right u-padding-s-right u-clr-grey7" type="button"><span class="button-text"><span class="u-hide-visually">Close</span></span><svg focusable="false" viewBox="0 0 70 128" width="13.125" height="24" class="icon icon-cross"><path d="m68.94 36.12l-6.94-7.12-27 27-27-27-7 7 27 27-27 27 7 7 27-27 27 27 7-7-27-27 26.94-26.88"></path></svg></button></div></div><div class="u-bg-white" style="overflow:visible" role="banner"><div class="els-header" style="min-height:80px"><a id="els-main-title-link" href="/"><svg id="els-header-wordmark" class="u-fill-orange u-margin-l-top u-margin-s-left u-margin-l-left-from-sm" viewBox="-3334 3439.4 163 26" style="width:163px;height:24px"><title>ScienceDirect</title><g transform="scale(.8125,.8125)"><path d="M-4099.8,4240.4c0-1.8,1-3.6,4.4-3.6c1.7,0,3.7,0.5,5.5,1.6l0.2-3.1c-1.7-0.7-3.5-1.1-5.6-1.1 c-5.5,0-7.8,2.9-7.8,6.4c0,6.6,10.4,7.2,10.4,11.7c0,1.8-1.4,3.6-4.6,3.6c-2,0-4-0.7-5.6-1.6l-0.4,3.1c1.8,0.9,4.2,1.2,6.1,1.2 c5,0,7.9-2.9,7.9-6.5C-4089.4,4245.8-4099.8,4244.9-4099.8,4240.4"></path><path id="c" d="M-4080.3,4242.9c0.3-0.1,0.8-0.3,2-0.3c2,0,2.9,0.4,2.9,1.9h2.8c0-0.4,0-0.9,0-1.3 c-0.3-2.3-2.5-3.2-5.8-3.2c-3.6,0-7.9,2.7-7.9,9.2c0,6.2,3.3,9.4,7.8,9.4c2,0,4.1-0.4,5.9-1.6l-0.2-2.7c-1.2,1-3.4,1.8-4.8,1.8 c-2.5,0-5.4-2-5.4-7C-4083.1,4244.3-4080.6,4243.1-4080.3,4242.9"></path><path id="i" d="M-4068,4233.1c-1.1,0-1.9,1.1-1.9,2.1c0,1.1,0.9,2.2,1.9,2.2s2-1.1,2-2.2 C-4066,4234.1-4067,4233.1-4068,4233.1 M-4069.5,4258.1h3v-17.7h-3V4258.1z"></path><path id="e" d="M-4057.1,4243.1c0.2-0.2,1.5-0.5,2.3-0.5c2.9,0,4.4,0.6,4.6,4.1h-8.8 C-4058.7,4244.4-4057.4,4243.3-4057.1,4243.1z M-4047.5,4248.9c0-6.1-1.7-8.9-7.1-8.9c-4.6,0-7.9,3.3-7.9,9.4 c0,5.8,3.5,9.2,7.9,9.2c3.3,0,5.1-0.7,6.7-1.7l-0.2-2.7c-1.1,0.9-3.5,1.8-5.5,1.8c-3.7,0-5.8-2.3-5.8-6.5v-0.6L-4047.5,4248.9"></path><path d="M-4034.8,4240c-2.6,0-4.3,1.3-5.7,3.1l-0.5-2.6h-2.8l0.2,1.4c0.1,0.9,0.2,2.1,0.2,3.5v12.8h3v-11.9 c0.8-1.1,2.5-2.9,2.9-3.1c0.3-0.2,1.5-0.5,2.5-0.5c2.7,0,2.9,1.4,3,4c0,1.4,0,3.7,0,3.7c0,3.5-0.1,7.6-0.1,7.6h3 c0,0,0.1-5.3,0.1-8.2c0-1.8,0-3.5-0.1-5.3C-4029.5,4241-4031.6,4240-4034.8,4240"></path><path d="M-3982.5,4255.6h-4.4v-18.6h4.8c6.4,0,8.2,5.2,8.2,9.2C-3973.8,4252.2-3976.5,4255.6-3982.5,4255.6z M-3981.6,4234.6h-8.4v23.5h8.1c8.6,0,11.5-6.7,11.5-11.9C-3970.4,4240.9-3973.2,4234.6-3981.6,4234.6"></path><path d="M-3950.5,4240c-1.9,0-3.4,1.7-4,3.2l-0.5-2.8h-2.8l0.2,1.4c0.1,0.9,0.2,2.1,0.2,3.4v12.8h3v-11.2 c0.6-1.5,2-4.4,3.7-4.4c1.1,0,1.2,1.2,1.2,1.4l2.5-0.7v-0.2c0,0,0-0.2-0.1-0.5C-3947.4,4240.9-3948.5,4240-3950.5,4240"></path><path d="M-3903.5,4255.2c-1.1,0.4-2,0.8-3,0.8c-1.4,0-1.9-0.8-1.9-2.8v-10.4h4.6v-2.3h-4.6v-4.7h-2.9v4.7h-3.2v2.3h3.2 v11.4c0,3.1,1.6,4.4,3.9,4.4c1.4,0,3-0.5,4.1-0.9L-3903.5,4255.2"></path><g><path d="M-3923.3,4242.9c0.3-0.1,0.8-0.3,2-0.3c2,0,2.9,0.4,2.9,1.9h2.8c0-0.4,0-0.9,0-1.3 c-0.3-2.3-2.5-3.2-5.8-3.2c-3.6,0-7.9,2.7-7.9,9.2c0,6.2,3.3,9.4,7.8,9.4c2,0,4.1-0.4,5.9-1.6l-0.2-2.7c-1.2,1-3.4,1.8-4.8,1.8 c-2.5,0-5.4-2-5.4-7C-3926.1,4244.3-3923.6,4243.1-3923.3,4242.9"></path></g><g><path d="M-3941.6,4243.1c0.2-0.2,1.5-0.5,2.3-0.5c2.9,0,4.4,0.6,4.6,4.1h-8.8 C-3943.2,4244.4-3941.8,4243.3-3941.6,4243.1z M-3932,4248.9c0-6.1-1.7-8.9-7.1-8.9c-4.6,0-7.9,3.3-7.9,9.4c0,5.8,3.5,9.2,7.9,9.2 c3.3,0,5.1-0.7,6.7-1.7l-0.2-2.7c-1.1,0.9-3.5,1.8-5.5,1.8c-3.7,0-5.8-2.3-5.8-6.5v-0.6L-3932,4248.9"></path></g><g><path d="M-3964.5,4233.1c-1.1,0-1.9,1.1-1.9,2.1c0,1.1,0.9,2.2,1.9,2.2s2-1.1,2-2.2 C-3962.5,4234.1-3963.4,4233.1-3964.5,4233.1 M-3965.9,4258.1h3v-17.7h-3V4258.1z"></path></g><g><path d="M-4004.4,4243.1c0.2-0.2,1.5-0.5,2.3-0.5c2.9,0,4.4,0.6,4.6,4.1h-8.8 C-4006,4244.4-4004.6,4243.3-4004.4,4243.1z M-3994.7,4248.9c0-6.1-1.7-8.9-7.1-8.9c-4.6,0-7.9,3.3-7.9,9.4c0,5.8,3.5,9.2,7.9,9.2 c3.3,0,5.1-0.7,6.7-1.7l-0.2-2.7c-1.1,0.9-3.5,1.8-5.5,1.8c-3.7,0-5.8-2.3-5.8-6.5v-0.6L-3994.7,4248.9"></path></g><g><path d="M-4019.1,4242.9c0.3-0.1,0.8-0.3,2-0.3c2,0,2.9,0.4,2.9,1.9h2.8c0-0.4,0-0.9,0-1.3 c-0.3-2.3-2.5-3.2-5.8-3.2c-3.6,0-7.9,2.7-7.9,9.2c0,6.2,3.3,9.4,7.8,9.4c2,0,4.1-0.4,5.9-1.6l-0.2-2.7c-1.2,1-3.4,1.8-4.8,1.8 c-2.5,0-5.4-2-5.4-7C-4021.8,4244.3-4019.4,4243.1-4019.1,4242.9"></path></g></g></svg></a><div class="move-right u-display-inline-block"><nav class="u-clr-grey8 u-show-from-md"><div class="u-display-inline-block" style="margin-top:29px"><span><span class="u-margin-l-right"><a class="anchor qa-journals-and-books u-margin-l-right anchor-has-inherit-color" href="/browse/journals-and-books" id="els-header-navigation-section-journals-and-books" style="border-bottom:"><span class="anchor-text">Journals &amp; Books</span></a></span><a class="anchor qa-journals-and-books u-margin-l-right anchor-has-inherit-color" href="/user/register?returnURL=%2Ftopics%2Fengineering%2Fprinciple-of-optimality" id="els-header-navigation-section-register"><span class="anchor-text">Register</span></a></span><a class="anchor qa-no-js-fallback-link anchor-has-inherit-color" href="/user/login?returnURL=%2Ftopics%2Fengineering%2Fprinciple-of-optimality" id="els-header-user-sign-in"><span class="anchor-text">Sign in</span><svg focusable="false" viewBox="0 0 54 128" width="10.125" height="24" class="icon icon-navigate-right"><path d="m1 99l38-38-38-38 7-7 45 45-45 45z"></path></svg></a><span><a class="anchor u-margin-l-hor help-link anchor-has-inherit-color" href="https://service.elsevier.com/app/answers/detail/a_id/25793/supporthub/sciencedirect/" id="help" title="Help" aria-label="Help" target="_blank"><span class="anchor-text"><svg focusable="false" viewBox="0 0 114 128" style="margin-top:-10px" width="21.375" height="24" class="icon icon-help"><path d="m57 8c-14.7 0-28.5 5.72-38.9 16.1-10.38 10.4-16.1 24.22-16.1 38.9 0 30.32 24.68 55 55 55 14.68 0 28.5-5.72 38.88-16.1 10.4-10.4 16.12-24.2 16.12-38.9 0-30.32-24.68-55-55-55zm0 1e1c24.82 0 45 20.18 45 45 0 12.02-4.68 23.32-13.18 31.82s-19.8 13.18-31.82 13.18c-24.82 0-45-20.18-45-45 0-12.02 4.68-23.32 13.18-31.82s19.8-13.18 31.82-13.18zm-0.14 14c-11.55 0.26-16.86 8.43-16.86 18v2h1e1v-2c0-4.22 2.22-9.66 8-9.24 5.5 0.4 6.32 5.14 5.78 8.14-1.1 6.16-11.78 9.5-11.78 20.5v6.6h1e1v-5.56c0-8.16 11.22-11.52 12-21.7 0.74-9.86-5.56-16.52-16-16.74-0.39-0.01-0.76-0.01-1.14 0zm-4.86 5e1v1e1h1e1v-1e1h-1e1z"></path></svg></span></a></span></div><div class="customer-banner u-show-from-lg move-top move-right u-display-inline-block u-position-relative"><div id="library-banner" class="desktop-library-banner u-show-from-lg u-margin-xs-right"><div class="customer-banner-container text-xs"><a target="_blank" href="http://www.jubil.upmc.fr/" rel="nofollow" class="img-customer-banner"><img src="www.jubil.upmc.fr/modules/resources/download/bupmc/docs-bu/logos/logo-bupmc-vert-2.jpg" alt="You have institutional access" width="234" height="60" /></a></div></div><div class="mobile-library-banner move-top move-center u-bg-grey1 u-padding-xxl-ver u-hide-from-lg u-display-block" id="mobile-library-banner" style="width:100%;position:relative"><div class="customer-banner-container text-xs move-middle move-center"><a target="_blank" href="http://www.jubil.upmc.fr/" rel="nofollow" class="img-customer-banner"><img src="www.jubil.upmc.fr/modules/resources/download/bupmc/docs-bu/logos/logo-bupmc-vert-2.jpg" alt="You have institutional access" width="234" height="60" /></a></div><button id="close-library-banner" class="button button-anchor move-top move-right u-padding-s-right u-clr-grey7" type="button"><span class="button-text"><span class="u-hide-visually">Close</span></span><svg focusable="false" viewBox="0 0 70 128" width="13.125" height="24" class="icon icon-cross"><path d="m68.94 36.12l-6.94-7.12-27 27-27-27-7 7 27 27-27 27 7 7 27-27 27 27 7-7-27-27 26.94-26.88"></path></svg></button></div></div></nav></div><div class="u-hide-from-md move-right"><ul><li style="list-style:none;display:inline-block;margin-top:32px" class="u-margin-s-hor u-margin-l-hor-from-sm"><div class="hamburger-button"><button class="button-link button-link-primary" aria-label="Mobile menu" aria-expanded="false" type="button"><svg viewBox="0 0 40 18" width="40" height="18" y="52"><path d="M0 16h40v2H0zm0-8h40v2H0zm0-8h40v2H0z"></path></svg><span class="button-link-text"></span></button></div></li></ul><div style="bottom:0;left:0;position:fixed;top:0;width:100%;z-index:70;opacity:.8" class="u-bg-grey1 u-display-none"></div><div id="mobile-menu" style="overflow:auto;position:fixed;width:288px;right:0;top:0;z-index:1000;height:100%" aria-label="Mobile menu" class="u-bg-grey7 u-clr-grey1 u-display-none" role="navigation"><div class="u-bg-black panel-s"></div><div class="u-bg-grey8 panel-s"><h3 class="text-xs u-clr-grey4 u-margin-xs-bottom"><span>Sorbonne University Pierre and Marie Curie Campus</span></h3><ul><li style="list-style:none"><a class="anchor journals-and-books-link u-padding-xs-top anchor-has-inherit-color" href="/browse/journals-and-books" style="border-bottom:" id="mobile-journals-and-books-link"><span class="anchor-text">Journals &amp; Books</span></a></li><li style="list-style:none"><a class="anchor u-padding-xs-top anchor-has-inherit-color" href="/user/register?returnURL=%2Ftopics%2Fengineering%2Fprinciple-of-optimality" id="mobile-register-link"><span class="anchor-text">Register</span></a></li></ul></div><div class="panel-s u-bg-grey7"><ul class="text-xs"></ul><ul class="u-margin-s-top text-s"><li style="list-style:none"><a class="anchor anchor-has-inherit-color" href="/user/login?returnURL=%2Ftopics%2Fengineering%2Fprinciple-of-optimality" id="mobile-sign-in-out-link" rel="nofollow"><span class="anchor-text">Sign In</span></a></li><span><a class="anchor u-padding-xs-top text-s help-link anchor-has-inherit-color" href="https://service.elsevier.com/app/answers/detail/a_id/25793/supporthub/sciencedirect/" id="mobile-help" title="Help" aria-label="Help" target="_blank"><span class="anchor-text">Help</span></a></span></ul></div></div></div></div></div></div><main id="main_content" role="main" class="notpdfdownload"><div class="u-padding-s-ver"></div><section class="topic-definition-wrapper row"><div class="definition-inner padding-resp-m u-dark-theme"><div class="row gutters"><section class="col-sm-24 col-md-24 col-lg-16 col-xl-16 u-padding-m-ver topic-definition"><div class="title-container"><h1 class="u-font-serif u-text-light alt-xl">Principle of Optimality</h1></div><p></p></section><section class="col-sm-24 col-md-24 col-lg-6 col-xl-6 padding-resp-ver-m related-terms move-right"><h2 class="u-h3">Related terms:</h2><ul class="list-tags u-clr-blue size-l" data-aa-region="aa-tp-related-terms"><li class="list-tags-item"><a class="anchor" href="/topics/engineering/sustainable-development" data-aa-name="Sustainable Development"><span class="anchor-text">Sustainable Development</span></a></li><li class="list-tags-item"><a class="anchor" href="/topics/engineering/prosthetics" data-aa-name="Prosthetics"><span class="anchor-text">Prosthetics</span></a></li><li class="list-tags-item"><a class="anchor" href="/topics/engineering/optimality" data-aa-name="Optimality"><span class="anchor-text">Optimality</span></a></li><li class="list-tags-item"><a class="anchor" href="/topics/engineering/dynamic-programming" data-aa-name="dynamic programming"><span class="anchor-text">dynamic programming</span></a></li><li class="list-tags-item"><a class="anchor" href="/topics/engineering/optimal-policy" data-aa-name="Optimal Policy"><span class="anchor-text">Optimal Policy</span></a></li><li class="list-tags-item"><a class="anchor" href="/topics/engineering/performance-criterion" data-aa-name="Performance Criterion"><span class="anchor-text">Performance Criterion</span></a></li></ul><div class="index-page-link u-margin-m-top"><a class="anchor anchor-has-colored-icon" href="/topics/index" data-aa-region="aa-tp-view-topic-index" data-aa-name=""><span class="anchor-text">View all Topics</span><svg focusable="false" viewBox="0 0 54 128" width="10.125" height="24" class="icon icon-navigate-right"><path d="m1 99l38-38-38-38 7-7 45 45-45 45z"></path></svg></a></div></section></div><div class="hor-line u-show-from-md" style="border-color:#505050"></div><div class="action-buttons u-margin-l-top u-show-from-md"><div class="u-display-inline-block"><button class="button-link u-show-from-md u-margin-m-right action-buttons button-link-primary" data-aa-region="aa-tp-download-topic-PDF" data-aa-name="" type="button"><svg focusable="false" viewBox="0 0 98 128" width="18.375" height="24" class="icon icon-download"><path d="m77.38 56.18l-6.6-7.06-16.78 17.24v-40.36h-1e1v40.34l-17.72-17.24-7.3 7.08 29.2 29.32 29.2-29.32m10.62 17.82v2e1h-78v-2e1h-1e1v3e1h98v-3e1h-1e1"></path></svg><span class="button-link-text">Download as PDF</span></button></div><div class="u-display-inline-block"><button class="button-link u-show-from-md action-buttons button-link-primary" type="button"><svg focusable="false" viewBox="0 0 108 128" width="20.25" height="24" class="icon icon-bell"><path d="m44.76 112h-10.39c1.78 9.18 9.9 16 19.63 16s17.85-6.82 19.63-16h-10.39c-1.49 3.64-5.07 6.21-9.24 6.21s-7.75-2.57-9.24-6.21zm-31.68-18c7.08-7.97 19.68-25.19 21.35-48.16l1.18-16.59c3.2-1.33 9.63-3.45 18.17-3.45 8.53 0 15.71 2.12 18.91 3.46l1.21 16.58c1.68 22.98 14.12 40.2 21.09 48.16zm94.91-1.07l-1.63-1.49c-0.2-0.18-20.48-18.96-22.49-46.33l-1.61-21.91-2.27-1.33c-0.41-0.24-10.96-5.87-26.23-5.87-15.26 0-25.05 5.64-25.46 5.88l-2.26 1.33-1.59 21.9c-1.98 27.35-22.77 46.3-22.77 46.3l-1.68 1.49v11.1h108l-0.01-11.07"></path></svg><span class="button-link-text">Set alert</span></button></div><div class="popover u-show-from-md text-m move-right" id="about-this-page"><div id="popover-trigger-about-this-page"><button class="button-link action-buttons u-padding-s-bottom button-link-primary" role="button" aria-expanded="false" aria-haspopup="true" type="button"><svg focusable="false" viewBox="0 0 100 128" aria-hidden="true" width="18.75" height="24" class="icon icon-info"><path d="m5e1 14c-13.08 0-25.4 5.1-34.64 14.36-9.26 9.24-14.36 21.56-14.36 34.64 0 27.02 21.98 49 49 49 13.1 0 25.4-5.1 34.66-14.36 9.24-9.24 14.34-21.56 14.34-34.64 0-27.02-21.98-49-49-49zm0 9.6c21.72 0 39.4 17.68 39.4 39.4 0 10.52-4.1 20.42-11.54 27.86s-17.34 11.52-27.86 11.52c-21.72 0-39.4-17.66-39.4-39.38 0-10.52 4.1-20.42 11.54-27.86s17.34-11.54 27.86-11.54zm-5 14.4v1e1h1e1v-1e1h-1e1zm0 16v34h1e1v-34h-1e1z"></path></svg><span class="button-link-text">About this page</span></button></div></div></div></div></section><section id="snippets-container" class="snippets-container screen"><div class="snippets-container-inner padding-resp-hor-m u-padding-l-ver"><div class="snippets-actions"><h2 class="u-padding-m-top u-padding-s-bottom u-clr-grey8 move-left">Learn more about Principle of Optimality</h2></div><div id="snippets-wrapper"><article class="snippet"><div class="snippet-inner"><h2 class="u-font-serif u-text-light" id="tp-snippet-chp-title-B9780080446745500250"><a class="anchor" href="/science/article/pii/B9780080446745500250" data-aa-region="aa-tp-snippet-chp-title" data-aa-name="Variational Calculus and Optimal Control" data-hack="#"><span class="anchor-text">Variational Calculus and Optimal Control</span></a></h2><div class="size-l"><cite><p><span>Alexander S. Poznyak, in </span><a href="/book/9780080446745" class="anchor" data-aa-region="aa-tp-snippet-bk-title" data-aa-name="Advanced Mathematical Tools for Automatic Control Engineers: Deterministic Techniques, Volume 1" data-hack="#"><span class="anchor-text">Advanced Mathematical Tools for Automatic Control Engineers: Deterministic Techniques, Volume 1</span></a>, 2008</p></cite><section id="B9780080446745500250-cesec135"><h3>Claim 22.1. (Bellman&#x27;s principle (BP) of optimality) “Any tail of an optimal trajectory is optimal too.”</h3><p id="B9780080446745500250-para591"><span><sup>2</sup></span></p><div><p id="B9780080446745500250-para592">In other words, if some trajectory in the phase space connects the initial <span class="math"><math><mi>x</mi><mrow><mo>(</mo><mn>0</mn><mo>)</mo></mrow></math></span> and terminal <span class="math"><math><mi>x</mi><mrow><mo>(</mo><mi>T</mi><mo>)</mo></mrow></math></span> points and is optimal in the sense of some cost functional, then the sub-trajectory, connecting any intermediate point <span class="math"><math><mi>x</mi><mrow><mo>(</mo><mrow><msup><mi>t</mi><mo>'</mo></msup></mrow><mo>)</mo></mrow></math></span> of the same trajectory with the same terminal point <span class="math"><math><mi>x</mi><mrow><mo>(</mo><mi>T</mi><mo>)</mo></mrow></math></span>, should also be optimal (see <span>Fig. 22.2</span>).</p><figure id="B9780080446745500250-f2"><div class="download-image"><div class="image-holder"><script src="https://ajax.cloudflare.com/cdn-cgi/scripts/95c75768/cloudflare-static/rocket-loader.min.js" data-cf-settings="2975f070f66ff17199d53d68-|49"></script><img src="https://ars.els-cdn.com/content/image/3-s2.0-B9780080446745500250-f22-02-9780080446745.gif?_" height="255" alt="" crossorigin="anonymous" onerror="this.onerror=null;window.IMG_NO_CORS=!0;this.removeAttribute('crossorigin');this.src=this.src.replace(/\?.*$/,'')" /></div><div class="u-margin-s-ver text-s"></div></div><div class="captions"><span id="B9780080446745500250-cecap2"><p id="B9780080446745500250-spara2"><span class="label">Fig. 22.2</span>. Illustration of Bellman&#x27;s principle of optimality.</p></span></div></figure></div></section></div><p class="u-padding-s-top u-padding-xs-bottom read-full-chapter-link"><a href="/science/article/pii/B9780080446745500250" class="button-alternative button-alternative-primary" aria-describedby="tp-snippet-chp-title-B9780080446745500250" data-aa-region="aa-tp-snippet-read-full-chp" data-aa-name="" data-hack="#"><svg focusable="false" viewBox="0 0 54 128" width="32" height="32" class="icon icon-navigate-right button-alternative-icon"><path d="m1 99l38-38-38-38 7-7 45 45-45 45z"></path></svg><span class="button-alternative-text">Read full chapter</span></a></p></div><div class="u-padding-m-bottom"></div></article><article class="snippet"><div class="snippet-inner"><h2 class="u-font-serif u-text-light" id="tp-snippet-chp-title-B9781785480492500049"><a class="anchor" href="/science/article/pii/B9781785480492500049" data-aa-region="aa-tp-snippet-chp-title" data-aa-name="Dynamic Programming" data-hack="#"><span class="anchor-text">Dynamic Programming</span></a></h2><div class="size-l"><cite><p><span>Jean-Michel Réveillac, in </span><a href="/book/9781785480492" class="anchor" data-aa-region="aa-tp-snippet-bk-title" data-aa-name="Optimization Tools for Logistics" data-hack="#"><span class="anchor-text">Optimization Tools for Logistics</span></a>, 2015</p></cite><section id="B9781785480492500049-s0010"><h3>4.1 <span id="B9781785480492500049-p55"></span>The principles of dynamic programming</h3><p id="B9781785480492500049-p0010"><span>Dynamic programming is an optimization method based on the <span class="topic-highlight">principle of optimality</span> defined by Bellman</span><span><sup>1</sup></span> in the 1950s: “<em>An optimal policy has the property that whatever the initial state and initial decision are, the remaining decisions must constitute an optimal policy with regard to the state resulting from the first decision</em>.<em>”</em></p><p id="B9781785480492500049-p0015"><em>It can be summarized simply as follows: “every optimal policy consists only of optimal sub policies.”</em></p><p id="B9781785480492500049-p0020">It is a very powerful technique, but its application framework is limited. Nevertheless, numerous variants exist to best meet the different problems encountered.</p><p id="B9781785480492500049-p0025">This method is a variant of the “divide and conquer” method given that a solution to a problem depends on the previous solutions obtained from subproblems. The main and major difference between these two methods relates to the superimposition of subproblems in dynamic programming. A subproblem can be used to solve a number of different subproblems. In the “divide and conquer” approach, subproblems are entirely independent and can be solved separately. Moreover, recursion is used, unlike in dynamic <span id="B9781785480492500049-p56"></span>programming where a combination of small subproblems is used to obtain increasingly larger subproblems.</p><p id="B9781785480492500049-p0030">To sum up, it can be said that the “divide and conquer” method works by following a top-down approach whereas dynamic programming follows a bottom-up approach.</p><div><p>How these two methods function can be illustrated and compared in two arborescent graphs.</p><figure id="B9781785480492500049-f0025"><div class="download-image"><div class="image-holder"><script src="https://ajax.cloudflare.com/cdn-cgi/scripts/95c75768/cloudflare-static/rocket-loader.min.js" data-cf-settings="2975f070f66ff17199d53d68-|49"></script><img src="https://ars.els-cdn.com/content/image/3-s2.0-B9781785480492500049-u04-01-9781785480492.jpg?_" height="145" alt="" crossorigin="anonymous" onerror="this.onerror=null;window.IMG_NO_CORS=!0;this.removeAttribute('crossorigin');this.src=this.src.replace(/\?.*$/,'')" /></div><div class="u-margin-s-ver text-s"></div></div><div class="captions"><span id="B9781785480492500049-ca0030"><p id="B9781785480492500049-sp0030"><span class="label">Figure 4.1</span>. The methods: dynamic programming (left) and divide and conquer (right)</p></span></div></figure></div><p id="B9781785480492500049-p0040">Problems concerning manufacturing management and regulation, stock management, investment strategy, macro planning, training, game theory, computer theory, systems control and so on result in decision-making that is regular and based on sequential processes which are perfectly in line with dynamic programming techniques.</p></section></div><p class="u-padding-s-top u-padding-xs-bottom read-full-chapter-link"><a href="/science/article/pii/B9781785480492500049" class="button-alternative button-alternative-primary" aria-describedby="tp-snippet-chp-title-B9781785480492500049" data-aa-region="aa-tp-snippet-read-full-chp" data-aa-name="" data-hack="#"><svg focusable="false" viewBox="0 0 54 128" width="32" height="32" class="icon icon-navigate-right button-alternative-icon"><path d="m1 99l38-38-38-38 7-7 45 45-45 45z"></path></svg><span class="button-alternative-text">Read full chapter</span></a></p></div><div class="u-padding-m-bottom"></div></article><article class="snippet"><div class="snippet-inner"><h2 class="u-font-serif u-text-light" id="tp-snippet-chp-title-B9780444632340500294"><a class="anchor" href="/science/article/pii/B9780444632340500294" data-aa-region="aa-tp-snippet-chp-title" data-aa-name="23rd European Symposium on Computer Aided Process Engineering" data-hack="#"><span class="anchor-text">23rd European Symposium on Computer Aided Process Engineering</span></a></h2><div class="size-l"><cite><p><span>Carlos E. Lopez-Landeros, ... Sergio Frausto-Hernandez, in </span><a href="/science/bookseries/15707946" class="anchor" data-aa-region="aa-tp-snippet-bk-title" data-aa-name="Computer Aided Chemical Engineering" data-hack="#"><span class="anchor-text">Computer Aided Chemical Engineering</span></a>, 2013</p></cite><section id="B9780444632340500294-s0025"><h3>4 Iterative Dynamic Programming Algorithm</h3><div><p>IDPA is a dynamic optimization numerical tool developed by <span>Luus (1990)</span><span> and it is based on the <span class="topic-highlight">principle of optimality</span> of Bellman and Hamilton-Jacobi-Bellman formulation (HJB) [</span><span>Bellman, 1957</span>]. In this formulation, the objective function <em>J</em> of <span>Equations 4-6</span> becomes the partial differential equation:</p><div class="formula"><span class="label">(7)</span><span class="math"><math><mrow><mfrac><mrow><mo>∂</mo><mi>V</mi><mrow><mo stretchy="true">(</mo><mrow><mstyle mathvariant="bold"><mi>x</mi></mstyle><mo>,</mo><mi>t</mi></mrow><mo stretchy="true">)</mo></mrow></mrow><mrow><mo>∂</mo><mi>t</mi></mrow></mfrac><mo>+</mo><mtext>min</mtext><mrow><mo stretchy="true">(</mo><mrow><mfrac><mrow><mo>∂</mo><mi>V</mi><mrow><mo stretchy="true">(</mo><mrow><mstyle mathvariant="bold"><mi>x</mi></mstyle><mo>,</mo><mi>t</mi></mrow><mo stretchy="true">)</mo></mrow></mrow><mrow><mo>∂</mo><mstyle mathvariant="bold"><mi>x</mi></mstyle></mrow></mfrac><mstyle mathvariant="bold"><mi>F</mi></mstyle><mrow><mo stretchy="true">(</mo><mrow><mstyle mathvariant="bold"><mi>x</mi></mstyle><mo>,</mo><mstyle mathvariant="bold"><mi>u</mi></mstyle></mrow><mo stretchy="true">)</mo></mrow><mo>+</mo><msup><mstyle mathvariant="bold"><mi>μ</mi></mstyle><mstyle mathvariant="bold"><mi>T</mi></mstyle></msup><mstyle mathvariant="bold"><mi>S</mi></mstyle><mrow><mo stretchy="true">(</mo><mrow><mstyle mathvariant="bold"><mi>x</mi></mstyle><mo>,</mo><mstyle mathvariant="bold"><mi>u</mi></mstyle></mrow><mo stretchy="true">)</mo></mrow></mrow><mo stretchy="true">)</mo></mrow><mo>=</mo><mn>0</mn></mrow></math></span></div></div><div><p>With boundary conditions:</p><div class="formula"><span class="label">(8)</span><span class="math"><math><mrow><msub><mrow><mrow><mrow><mfrac><mrow><mo>∂</mo><mi>V</mi><mrow><mo stretchy="true">(</mo><mrow><mstyle mathvariant="bold"><mi>x</mi></mstyle><mo>,</mo><mi>t</mi></mrow><mo stretchy="true">)</mo></mrow></mrow><mrow><mo>∂</mo><mi>t</mi></mrow></mfrac></mrow><mo stretchy="true">|</mo></mrow></mrow><mrow><msub><mi>t</mi><mi>f</mi></msub></mrow></msub><mo>=</mo><mn>0</mn></mrow></math></span></div><div class="formula"><span class="label">(9)</span><span class="math"><math><mrow><mi>V</mi><mrow><mo stretchy="true">(</mo><mrow><mstyle mathvariant="bold"><mi>x</mi></mstyle><mrow><mo stretchy="true">(</mo><mrow><msub><mi>t</mi><mi>f</mi></msub></mrow><mo stretchy="true">)</mo></mrow><mo>,</mo><msub><mi>t</mi><mi>f</mi></msub></mrow><mo stretchy="true">)</mo></mrow><mo>=</mo><mi>φ</mi><mrow><mo stretchy="true">(</mo><mrow><mstyle mathvariant="bold"><mi>x</mi></mstyle><mrow><mo stretchy="true">(</mo><mrow><msub><mi>t</mi><mi>f</mi></msub></mrow><mo stretchy="true">)</mo></mrow></mrow><mo stretchy="true">)</mo></mrow><mo>+</mo><msup><mstyle mathvariant="bold"><mi>v</mi></mstyle><mstyle mathvariant="bold"><mi>T</mi></mstyle></msup><mstyle mathvariant="bold"><mi>T</mi></mstyle><mrow><mo stretchy="true">(</mo><mrow><mstyle mathvariant="bold"><mi>x</mi></mstyle><mrow><mo stretchy="true">(</mo><mrow><msub><mi>t</mi><mi>f</mi></msub></mrow><mo stretchy="true">)</mo></mrow></mrow><mo stretchy="true">)</mo></mrow></mrow></math></span></div></div><div><p>Where <em>V</em> (<strong>x</strong>,<em>t</em>) is called back function, and represents a minimal cost if the system is in state <strong>x</strong> at time <em>t</em> ≤ <em>t<sub>f</sub></em>. The <span>Equation 9</span> is a transversally condition. IDPA estimates the value of <em>V</em> (<strong>x</strong>,<em>t</em>) of the <span>Equation 7</span> with the discretization of the state variables and control variables. The minimization is carried out through an exhaustive search procedure within a feasible region. The time interval (<em>t<sub>0</sub></em>, <em>t<sub>f</sub></em>) is divided into <em>P</em> stages where the last one corresponds to the interval (<em>t<sub>P-1</sub></em>, <em>t<sub>P</sub></em>). Considering the fact that:</p><div class="formula"><span class="label">(10)</span><span class="math"><math><mrow><mfrac><mrow><mo>∂</mo><mi>V</mi><mrow><mo stretchy="true">(</mo><mrow><mstyle mathvariant="bold"><mi>x</mi></mstyle><mo>,</mo><mi>t</mi></mrow><mo stretchy="true">)</mo></mrow></mrow><mrow><mo>∂</mo><mi>t</mi></mrow></mfrac><mi>Δ</mi><mi>t</mi><mo>+</mo><mfrac><mrow><mo>∂</mo><mi>V</mi><mrow><mo stretchy="true">(</mo><mrow><mstyle mathvariant="bold"><mi>x</mi></mstyle><mo>,</mo><mi>t</mi></mrow><mo stretchy="true">)</mo></mrow></mrow><mrow><mo>∂</mo><mstyle mathvariant="bold"><mi>x</mi></mstyle></mrow></mfrac><mfrac><mrow><mi>d</mi><mstyle mathvariant="bold"><mi>x</mi></mstyle></mrow><mrow><mi>d</mi><mi>t</mi></mrow></mfrac><mi>Δ</mi><mi>t</mi><mo>=</mo><mi>V</mi><mrow><mo stretchy="true">(</mo><mrow><mstyle mathvariant="bold"><mi>x</mi></mstyle><mrow><mo stretchy="true">(</mo><mrow><mi>t</mi><mo>+</mo><mi>Δ</mi><mi>t</mi></mrow><mo stretchy="true">)</mo></mrow><mo>,</mo><mi>t</mi><mo>+</mo><mi>Δ</mi><mi>t</mi></mrow><mo stretchy="true">)</mo></mrow><mo>-</mo><mi>V</mi><mrow><mo stretchy="true">(</mo><mrow><mstyle mathvariant="bold"><mi>x</mi></mstyle><mrow><mo stretchy="true">(</mo><mi>t</mi><mo stretchy="true">)</mo></mrow><mo>,</mo><mi>t</mi></mrow><mo stretchy="true">)</mo></mrow></mrow></math></span></div></div><div><p>The <span>Equation 7</span> can be integrated over the interval (<em>t<sub>P-1</sub></em>, <em>t<sub>P</sub></em>). Then the back function at time <em>t<sub>P-1</sub></em> can be written as:</p><div class="formula"><span class="label">(11)</span><span class="math"><math><mrow><mi>V</mi><mrow><mo stretchy="true">(</mo><mrow><msub><mstyle mathvariant="bold"><mi>x</mi></mstyle><mrow><mi>P</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>t</mi><mrow><mi>P</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow><mo stretchy="true">)</mo></mrow><mo>=</mo><mtext>min</mtext><mrow><mo stretchy="true">(</mo><mrow><mi>V</mi><mrow><mo stretchy="true">(</mo><mrow><msub><mstyle mathvariant="bold"><mi>x</mi></mstyle><mi>P</mi></msub><mo>,</mo><msub><mi>t</mi><mi>P</mi></msub></mrow><mo stretchy="true">)</mo></mrow><mo>+</mo><mstyle displaystyle="true"><mrow><msubsup><mo>∫</mo><mrow><mi>P</mi><mo>-</mo><mn>1</mn></mrow><mi>P</mi></msubsup><mrow><msup><mstyle mathvariant="bold"><mi>μ</mi></mstyle><mstyle mathvariant="bold"><mi>T</mi></mstyle></msup><mstyle mathvariant="bold"><mi>S</mi></mstyle><mrow><mo stretchy="true">(</mo><mrow><mstyle mathvariant="bold"><mi>x</mi></mstyle><mo>,</mo><mstyle mathvariant="bold"><mi>u</mi></mstyle></mrow><mo stretchy="true">)</mo></mrow><mi>d</mi><mi>t</mi></mrow></mrow></mstyle></mrow><mo stretchy="true">)</mo></mrow></mrow></math></span></div></div><p id="B9780444632340500294-p0080">Where <strong>x</strong><em><sub>P</sub></em> is the state <em>t<sub>P</sub></em> obtained from the integration of the system with control variables <strong>u</strong> and initial conditions <strong>x</strong> (<em>t<sub>P-1</sub></em>) = <strong>x</strong><sub>P-1</sub> on the interval (<em>t<sub>P-1</sub></em>,<em>t<sub>P</sub></em>). Since the boundary condition <em>V</em> is known at final time according to <span>Equation 9</span>, the <span>Equation 11</span> is solved iteratively for decreasing values of <em>P</em>. One of the main advantages of IDPA over other methods of dynamic optimization is that it is one of the few tools available to calculate global optima. Also unlike the algorithms of Optimal Control Theory, it does not require complex mathematics [<span>Srinivasan et al., 2003</span>]. The implementation of this tool is immediately made in the determination of a therapeutic regimen for the improvement of a biological system.</p></section></div><p class="u-padding-s-top u-padding-xs-bottom read-full-chapter-link"><a href="/science/article/pii/B9780444632340500294" class="button-alternative button-alternative-primary" aria-describedby="tp-snippet-chp-title-B9780444632340500294" data-aa-region="aa-tp-snippet-read-full-chp" data-aa-name="" data-hack="#"><svg focusable="false" viewBox="0 0 54 128" width="32" height="32" class="icon icon-navigate-right button-alternative-icon"><path d="m1 99l38-38-38-38 7-7 45 45-45 45z"></path></svg><span class="button-alternative-text">Read full chapter</span></a></p></div><div class="u-padding-m-bottom"></div></article><article class="snippet"><div class="snippet-inner"><h2 class="u-font-serif u-text-light" id="tp-snippet-chp-title-B9780128052464000070"><a class="anchor" href="/science/article/pii/B9780128052464000070" data-aa-region="aa-tp-snippet-chp-title" data-aa-name="Stochastic Adaptive Dynamic Programming for Robust Optimal Control Design" data-hack="#"><span class="anchor-text">Stochastic Adaptive Dynamic Programming for Robust Optimal Control Design</span></a></h2><div class="size-l"><cite><p><span>T. Bian, Z.-P. Jiang, in </span><a href="/book/9780128052464" class="anchor" data-aa-region="aa-tp-snippet-bk-title" data-aa-name="Control of Complex Systems" data-hack="#"><span class="anchor-text">Control of Complex Systems</span></a>, 2016</p></cite><section id="B9780128052464000070-s0010"><h3>1 Introduction</h3><p id="B9780128052464000070-p0085">Dynamic programming (DP) [<span>1</span><span>] aims at solving the optimal control problem for dynamic systems using Bellman’s <span class="topic-highlight">principle of optimality</span>. However, the direct implementation of DP in real-world applications is usually prohibited by the “curse of dimensionality” [</span><span>2</span>] and the “curse of modeling” [<span>3</span>]. One way of solving these two shortcomings is to use approximate DP, which was proposed by Werbos [<span>4</span>, <span>5</span>] to bring reinforcement learning and DP together to approximate the (generally intractable) solution to Bellman’s equation via online learning. Inspired by Werbos’s original work, numerous approximate DP methods, such as Q-learning [<span>6</span>, <span>7</span>], temporal-difference learning [<span>8</span>, <span>9</span>], and actor-critic algorithms [<span>10–12</span>], have been widely adopted to solve the optimal control problem for Markov decision processes (MDPs) in the past two decades. Similar ideas have been proposed by Bertsekas and Tsitsiklis under the name of <em>neuro-DP</em> [<span>3</span>]. The interested reader can consult [<span>3</span>, <span>13</span>, <span>14</span>] for a nice tutorial. Despite their popularity in real-world applications, the above-mentioned methods usually overlooked the stability issue. Moreover, the underlying state and action spaces are assumed to be either finite or countable, which is restrictive for many real-world applications.</p><p id="B9780128052464000070-p0090">Different from the early approximate DP methods, adaptive dynamic programming (ADP) was introduced to find a stabilizing optimal controller for continuous-state space control systems. Over the past decade, ADP-based control design has been extensively studied by several research groups for both continuous-time systems [<span>15–26</span>] and discrete-time [<span>27–32</span>] systems. See also [<span>33–35</span>] for three review papers, and [<span>36</span>] for a recent book. Unfortunately, most existing ADP methods are devised for deterministic systems. Although preliminary results [<span>37</span>, <span>38</span>] have been obtained for a class of continuous-time stochastic systems, additive noise is excluded from the model in question. Since the quadratic cost in the classic linear-quadratic regulator problem may become ill-posed because of the presence of the additive noise, we need to consider new types of cost functionals for stochastic optimal control problems in the presence of additive noise. In the first part of this chapter <span>(Sections 2–5)</span> we investigate the optimal control problem for linear stochastic systems subject to both multiplicative noise and additive noise. In <span>Section 2</span>, two cost functionals—the discounted cost and the biased cost—are presented. The optimal control problems corresponding to these two types of cost functionals are solved in <span>Sections 3</span> and <span>4</span>, respectively, with rigorous convergence and stability analysis provided. In <span>Section 5</span>, ADP techniques are developed to design stochastic adaptive optimal controllers through online successive approximations.</p><p id="B9780128052464000070-p0095">In the second part of this chapter (<span>Sections 6</span> and <span>7</span>) we further develop a stochastic robust ADP (RADP) method to solve the stochastic robust optimal control problem for continuous-time linear stochastic systems subject to nonlinear dynamic uncertainties. Different from the traditional ADP, RADP can address the presence of dynamic uncertainties caused by the modeling error in linear and nonlinear dynamic systems (see, eg, [<span>35</span>, <span>39–42</span>], and references therein). By use of the RADP algorithm, precise information on the system dynamics and order is no longer required, and robust optimal control laws are designed directly on the basis of the real-time data. In <span>Section 6</span> we conduct robust optimality and stability analysis for a class of continuous-time partially linear stochastic systems, by employing the stochastic <span class="math"><math><msup><mrow><mi>H</mi></mrow><mrow><mi>∞</mi></mrow></msup></math></span> theory [<span>43</span>, <span>44</span>] and the small-gain theory [<span>45–47</span>]. It can be shown that if the input-dependent noise is small enough, then the robust stability of the closed-loop system under the optimal control policy is guaranteed by tuning <em>Q</em> and <em>R</em> matrices properly. On the basis of the robust optimality results obtained, a stochastic RADP algorithm with convergence and stability analysis is given in <span>Section 7</span>.</p><p id="B9780128052464000070-p0100">To illustrate the results obtained, we present three practical examples from the engineering and computational neuroscience fields in <span>Section 8</span>. In the first example the two-joint human arm movement in a divergent force field [<span>48</span>] is considered, where an undiscounted cost is used. This example shows that our stochastic ADP method appears to be a suitable candidate for a computational learning mechanism in the central nervous system to coordinate movements. Then we apply the stochastic ADP algorithms to solve a vehicle suspension control problem, where stochastic additive noise is involved. Both discount-optimal control and bias-optimal control are derived. Finally, to illustrate the stochastic RADP algorithm, a partially linear single-joint human arm movement model is presented in the third example. These three examples demonstrate that the stochastic ADP method presented in this chapter serves as a powerful tool to solve data-driven, non-model-based robust optimal control problems for stochastic systems.</p><p id="B9780128052464000070-p0105">Throughout this chapter we use <span class="math"><math><mi mathvariant="double-struck">R</mi></math></span> to denote the set of real numbers. <em>I</em><sub><em>n</em></sub> denotes the identity matrix of dimension <em>n</em>. |⋅| denotes the Euclidean norm for vectors, or the induced matrix norm for matrices. For a matrix <span class="math"><math><mi>A</mi><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mrow><mi>n</mi><mo>×</mo><mi>m</mi></mrow></msup></math></span>, <span class="math"><math><mtext>vec</mtext><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mrow><mo stretchy="false">[</mo><msubsup><mrow><mi>a</mi></mrow><mrow><mn>1</mn></mrow><mrow><mtext>T</mtext></mrow></msubsup><mspace width="1em"></mspace><msubsup><mrow><mi>a</mi></mrow><mrow><mn>2</mn></mrow><mrow><mtext>T</mtext></mrow></msubsup><mspace width="1em"></mspace><mo>⋯</mo><mspace width="1em"></mspace><msubsup><mrow><mi>a</mi></mrow><mrow><mi>m</mi></mrow><mrow><mtext>T</mtext></mrow></msubsup><mo stretchy="false">]</mo></mrow><mrow><mtext>T</mtext></mrow></msup></math></span>, where <span class="math"><math><msub><mrow><mi>a</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mrow><mi>n</mi></mrow></msup></math></span> is the <em>i</em>th column of <em>A</em>. ⊗ indicates the Kronecker product. We denote by <span class="math"><math><mo stretchy="false">(</mo><mi>Ω</mi><mo>,</mo><mi mathvariant="script">F</mi><mo>,</mo><mi>P</mi><mo stretchy="false">)</mo></math></span> the underlying probability space [<span>49</span>, Chapter 5.2], where <em>Ω</em> is a sample space, <em>P</em> is a probability measure, and <span class="math"><math><mi mathvariant="script">F</mi></math></span> is a <em>σ</em>-field of Borel sets equipped with a nature filtration <span class="math"><math><mo stretchy="false">{</mo><msub><mrow><mi mathvariant="script">F</mi></mrow><mrow><mi>t</mi></mrow></msub><mo stretchy="false">}</mo></math></span>, <span class="math"><math><msub><mrow><mi mathvariant="script">F</mi></mrow><mrow><mi>s</mi></mrow></msub><mo>⊆</mo><msub><mrow><mi mathvariant="script">F</mi></mrow><mrow><mi>t</mi></mrow></msub><mo>⊆</mo><mi mathvariant="script">F</mi></math></span> for 0 ≤ <em>s</em> ≤ <em>t</em>. <span class="math"><math><mi mathvariant="script">E</mi></math></span> and <span class="math"><math><mi mathvariant="script">L</mi></math></span> denote the expectation operator and the differential generator, respectively.</p></section></div><p class="u-padding-s-top u-padding-xs-bottom read-full-chapter-link"><a href="/science/article/pii/B9780128052464000070" class="button-alternative button-alternative-primary" aria-describedby="tp-snippet-chp-title-B9780128052464000070" data-aa-region="aa-tp-snippet-read-full-chp" data-aa-name="" data-hack="#"><svg focusable="false" viewBox="0 0 54 128" width="32" height="32" class="icon icon-navigate-right button-alternative-icon"><path d="m1 99l38-38-38-38 7-7 45 45-45 45z"></path></svg><span class="button-alternative-text">Read full chapter</span></a></p></div><div class="u-padding-m-bottom"></div></article><article class="snippet"><div class="snippet-inner"><h2 class="u-font-serif u-text-light" id="tp-snippet-chp-title-B9780080273105500138"><a class="anchor" href="/science/article/pii/B9780080273105500138" data-aa-region="aa-tp-snippet-chp-title" data-aa-name="Reactor Strategy Calculations" data-hack="#"><span class="anchor-text">Reactor Strategy Calculations</span></a></h2><div class="size-l"><cite><p><span>P. SILVENNOINEN, in </span><a href="/book/9780080273105" class="anchor" data-aa-region="aa-tp-snippet-bk-title" data-aa-name="Nuclear Fuel Cycle Optimization" data-hack="#"><span class="anchor-text">Nuclear Fuel Cycle Optimization</span></a>, 1982</p></cite><section id="B9780080273105500138-cesec11"><h3><span id="B9780080273105500138-p103"></span>APPLICATION OF DYNAMIC PROGRAMMING</h3><p id="B9780080273105500138-para31">The algorithm outlined in <span>Fig. 8.1</span><span> involves a multistage optimization procedure where decisions on preferred plant types are taken during each round. A wide class of corresponding problems are handled by means of dynamic programming. This method exploits the <span class="topic-highlight">principle of optimality</span>; at any state of the optimal policy the sequence of remaing decisions must constitute an optimal policy with regard to the state resulting from the previous decisions. The approach, originally proposed by Bellman, is widely elaborated on in the literature, e.g. by </span><span>Intriligator (1971)</span>.</p><p id="B9780080273105500138-para32">The principal reason for abandoning the simple simulation procedure presented in the preceding sections is the fact that long planning horizons and the inclusion of three to four different reactor types lead to long running times on a computer. Using the optimality criterion one is able to delete a number of feasible plant combinations and the algorithm becomes more efficient.</p><p id="B9780080273105500138-para33">Realizing that dynamic programming is a well established approach it is natural to employ the conventional nomenclature. The problem embodied in <span>Fig. 8.1</span> is transformed to dynamic programming as follows. Deriving the optimal reactor strategy for the planning period is tantamount to splitting the process into stages each of which corresponds to a given time step T, or equivalently, to one cycle in the algorithm of <span>Fig. 8.1</span>. At the stage n, i.e. during the nth time interval, one is asked to define the value of a decision variable d<sub>n</sub>. The values of the variable d<sub>n</sub> refer to the reactor and fuel cycle strategies available at the stage n. A relevant example might be as follows: d<sub>1</sub> = use LWR, d<sub>2</sub> = initiate reprocessing and LWR recycle, d<sub>3</sub> = bring in FBR.</p><p id="B9780080273105500138-para34">The information on the earlier decisions, i.e. on the current fuel cycle status and material inventories, is contained in a state vector x<sub>n</sub> whose components are stored throughout the computation. The initial state X<sub>1</sub> is known as it contains the description of the power generation system at the beginning of the planning horizon.</p><div><p id="B9780080273105500138-para35">An arbitrary stage n is described in <span>Fig. 8.2</span>.</p><figure id="B9780080273105500138-f2"><div class="download-image"><div class="image-holder"><script src="https://ajax.cloudflare.com/cdn-cgi/scripts/95c75768/cloudflare-static/rocket-loader.min.js" data-cf-settings="2975f070f66ff17199d53d68-|49"></script><img src="https://ars.els-cdn.com/content/image/3-s2.0-B9780080273105500138-f08-02-9780080273105.gif?_" height="138" alt="" crossorigin="anonymous" onerror="this.onerror=null;window.IMG_NO_CORS=!0;this.removeAttribute('crossorigin');this.src=this.src.replace(/\?.*$/,'')" /></div><div class="u-margin-s-ver text-s"></div></div><div class="captions"><span id="B9780080273105500138-cecap2"><p id="B9780080273105500138-spara2"><span class="label">Fig. 8.2</span>. Decision stage n.</p></span></div></figure></div><div><p>The state x<sub>n</sub> is known as it is determined from the initial state X<sub>1</sub> by the decisions d<sub>1</sub>,d<sub>2</sub>, … d<sub>n-1</sub>. The decision d<sub>n</sub> leads to a new system state x<sub>n+1</sub>. If a transfer operator T describes the implications of the decision, one may write formally</p><div class="formula"><span class="label">(8.10)</span><span class="math"><math><mrow><msub><mtext>x</mtext><mrow><mtext>n</mtext><mo>+</mo><mtext>1</mtext></mrow></msub><mo>=</mo><msub><mrow><mtext>T(x</mtext></mrow><mtext>n</mtext></msub><msub><mrow><mtext>,d</mtext></mrow><mtext>n</mtext></msub><mtext>)</mtext><mtext>.</mtext></mrow></math></span></div></div><p id="B9780080273105500138-para37"><span id="B9780080273105500138-p104"></span>From the standpoint of optimizing the reactor strategy decisions, it is relevant to calculate the revenue requirements R<sub>n</sub> for the plant decided on at the stage n.</p><div><p>The total lifetime costs for one plant and the associated fuel cycle operations were discussed in the preceding sections and, in fact, <span>Eq. (8.4)</span> provides a general formula. The revenue requirement R<sub>n</sub> represents an incremental step in calculating the cumulative revenue requirements of the entire reactor strategy. The expression of R<sub>n</sub> is simply the value of TRR for the particular reactor type chosen by the decision d<sub>n</sub>. Discounting the cost TRR(d<sub>n</sub>) to the beginning of the planning period one has</p><div class="formula"><span class="label">(8.11)</span><span class="math"><math><mrow><msub><mtext>R</mtext><mtext>n</mtext></msub><mo>=</mo><msub><mrow><mtext>TRR(d</mtext></mrow><mtext>n</mtext></msub><mo stretchy="false">)</mo><msup><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mtext>r</mtext><mo stretchy="false">)</mo></mrow><mrow><mo>−</mo><msub><mtext>T</mtext><mtext>n</mtext></msub></mrow></msup></mrow></math></span></div></div><p id="B9780080273105500138-para39">where T<sub>n</sub> denotes the timing of the decision stage n. Clearly, the costs can be referenced to any other date agreed on.</p><div><p>The cumulative revenue requirements CRR<sub>n</sub> consist of the discounted cost of all the reactor plants installed by and at the stage n and include the respective fuel cycle and operation costs over the plant lifetimes. Up to the stage n the cost CRR<sub>n</sub> is defined by</p><div class="formula"><span class="label">(8.12)</span><span class="math"><math><mrow><msub><mrow><mtext>CRR</mtext></mrow><mtext>n</mtext></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mtext>i</mtext><mo>=</mo><mn>1</mn></mrow><mtext>n</mtext></munderover><mrow><msub><mtext>R</mtext><mtext>i</mtext></msub><mo stretchy="false">(</mo><msub><mtext>x</mtext><mtext>i</mtext></msub><mo>,</mo><msub><mtext>d</mtext><mtext>i</mtext></msub><mo stretchy="false">)</mo></mrow></mstyle><mo>.</mo></mrow></math></span></div></div><p id="B9780080273105500138-para41">If there are N+1 stages, then CRR<sub>N</sub> gives the total discounted costs of the reactor strategy. The expression of CRR<sub>N</sub> being separable is an adequate condition for the application of the optimality principle.</p><div><p>According to the optimality principle the decision d<sub>n</sub> shall be taken such as to minimize the total revenue requirements from the state x<sub>n</sub> to x<sub>N</sub>. Denoting the minimum by MC(x<sub>n</sub>) one has the objective function</p><div class="formula"><span class="label">(8.13)</span><span class="math"><math><mrow><msub><mrow><mtext>MC(x</mtext></mrow><mtext>n</mtext></msub><mo stretchy="false">)</mo><mo>=</mo><mi>min</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mtext>i</mtext><mo>=</mo><mtext>n</mtext></mrow><mtext>N</mtext></munderover><mrow><msub><mtext>R</mtext><mtext>i</mtext></msub><mo stretchy="false">(</mo><msub><mtext>x</mtext><mtext>i</mtext></msub><mo>,</mo><msub><mtext>d</mtext><mtext>i</mtext></msub><mo stretchy="false">)</mo></mrow></mstyle></mrow></math></span></div></div><div><p><span>Equation (8.13)</span> is now split by separating the term i=n and the expression obtains the form</p><div class="formula"><span class="label">(8.14)</span><span class="math"><math><mrow><msub><mrow><mtext>MC(x</mtext></mrow><mtext>n</mtext></msub><mo stretchy="false">)</mo><mo>=</mo><munder><mrow><mi>min</mi></mrow><mrow><msub><mtext>d</mtext><mtext>n</mtext></msub></mrow></munder><mo stretchy="false">[</mo><msub><mtext>R</mtext><mtext>n</mtext></msub><mo stretchy="false">(</mo><msub><mtext>x</mtext><mtext>n</mtext></msub><mo>,</mo><msub><mtext>d</mtext><mtext>n</mtext></msub><mo stretchy="false">)</mo><mo>+</mo><msub><mrow><mtext>MC(T</mtext></mrow><mtext>n</mtext></msub><mo stretchy="false">(</mo><msub><mtext>x</mtext><mtext>n</mtext></msub><mo>,</mo><msub><mtext>d</mtext><mtext>n</mtext></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>.</mo></mrow></math></span></div></div><p id="B9780080273105500138-para44">Because T(x<sub>n</sub>,d<sub>n</sub>) refers to the state x<sub>n+1</sub>, <span>Eq. (8.14)</span> constitutes a recursive relation.</p><p id="B9780080273105500138-para45">The calculation of the minimum cost policy is commenced at the final state X<sub>N+1</sub>. For n = N in <span>Eq. (8.14)</span>, the second term in the brackets, i.e. MC(X<sub>N+1</sub>), disappears by definition because this stage was arrived at by the decision d<sub>n</sub>. Proceeding backwards with n ≤ N, <span>Eq. (8.14)</span> gives the minimum cost for each stage and fixes the decision on where to go.</p><p id="B9780080273105500138-para46">When the stage n=1 is reached, the optimum policy has been solved for. Comparing <span>Eqs. (8.12)</span> and <span>(8.13)</span> it is seen that MC(x<sub>1</sub>) gives the minimum value of the cumulative revenue requirements CRR for the strategy.</p><p id="B9780080273105500138-para47"><span id="B9780080273105500138-p105"></span>The basic algorithm outlined above is extended in the following section. An application to a reactor strategy study will be presented there as well.</p></section></div><p class="u-padding-s-top u-padding-xs-bottom read-full-chapter-link"><a href="/science/article/pii/B9780080273105500138" class="button-alternative button-alternative-primary" aria-describedby="tp-snippet-chp-title-B9780080273105500138" data-aa-region="aa-tp-snippet-read-full-chp" data-aa-name="" data-hack="#"><svg focusable="false" viewBox="0 0 54 128" width="32" height="32" class="icon icon-navigate-right button-alternative-icon"><path d="m1 99l38-38-38-38 7-7 45 45-45 45z"></path></svg><span class="button-alternative-text">Read full chapter</span></a></p></div><div class="u-padding-m-bottom"></div></article><article class="snippet"><div class="snippet-inner"><h2 class="u-font-serif u-text-light" id="tp-snippet-chp-title-B9780128052464000227"><a class="anchor" href="/science/article/pii/B9780128052464000227" data-aa-region="aa-tp-snippet-chp-title" data-aa-name="Intelligent Control of a Prosthetic Ankle Joint Using Gait Recognition" data-hack="#"><span class="anchor-text">Intelligent Control of a Prosthetic Ankle Joint Using Gait Recognition</span></a></h2><div class="size-l"><cite><p><span>A. Mai, S. Commuri, in </span><a href="/book/9780128052464" class="anchor" data-aa-region="aa-tp-snippet-bk-title" data-aa-name="Control of Complex Systems" data-hack="#"><span class="anchor-text">Control of Complex Systems</span></a>, 2016</p></cite><section id="B9780128052464000227-s0065"><h3>Critic Network</h3><div><p>From the discussion of the optimization principles of human gait in <span>Section 3.1</span><span> it can be hypothesized that there is a finite optimizable index which indicates the long-term performance of the prosthetic ankle joint in tracking of the desired gait-based trajectory. According to Bellman’s <span class="topic-highlight">principle of optimality</span>, such a long-term performance index is expressed as the weighted sum of the short-term (instantaneous) cost at the subsequent iterations as follows: </span></p><div class="formula"><span class="label">(7)</span><span class="math"><math><mtable columnalign="left"><mtr><mtd columnalign="right"><mfenced close="|" open=""><mrow><mi>L</mi></mrow></mfenced><msub><mrow></mrow><mrow><mo stretchy="false">[</mo><mi>k</mi><mo>−</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></msub></mtd><mtd columnalign="left"><mo>=</mo><mfenced close="|" open=""><mrow><mi>S</mi></mrow></mfenced><msub><mrow></mrow><mrow><mo stretchy="false">[</mo><mi>k</mi><mo stretchy="false">]</mo></mrow></msub><mo>+</mo><mi>α</mi><mfenced close="|" open=""><mrow><mi>S</mi></mrow></mfenced><msub><mrow></mrow><mrow><mo stretchy="false">[</mo><mi>k</mi><mo>+</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></msub><mo>+</mo><msup><mrow><mi>α</mi></mrow><mrow><mn>2</mn></mrow></msup><mfenced close="|" open=""><mrow><mi>S</mi></mrow></mfenced><msub><mrow></mrow><mrow><mo stretchy="false">[</mo><mi>k</mi><mo>+</mo><mn>2</mn><mo stretchy="false">]</mo></mrow></msub><mo>+</mo><mo>⋯</mo></mtd></mtr><mtr><mtd columnalign="right"></mtd><mtd columnalign="left"><mo>=</mo><mfenced close="|" open=""><mrow><mi>S</mi></mrow></mfenced><msub><mrow></mrow><mrow><mo stretchy="false">[</mo><mi>k</mi><mo stretchy="false">]</mo></mrow></msub><mo>+</mo><mi>α</mi><mfenced close="|" open=""><mrow><mi>L</mi></mrow></mfenced><msub><mrow></mrow><mrow><mo stretchy="false">[</mo><mi>k</mi><mo stretchy="false">]</mo></mrow></msub><mo>,</mo></mtd></mtr></mtable></math></span></div><p>in which <span class="math"><math><mfenced close="|" open=""><mrow><mi>L</mi></mrow></mfenced><msub><mrow></mrow><mrow><mo stretchy="false">[</mo><mi>k</mi><mo>−</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></msub></math></span> is the long-term performance index at iteration <em>k</em> − 1, <span class="math"><math><mi>S</mi><mfenced close="" open="|"><mrow><msub><mrow></mrow><mrow><mo stretchy="false">[</mo><mi>k</mi><mo stretchy="false">]</mo></mrow></msub></mrow></mfenced></math></span> is the instantaneous cost at iteration <span class="math"><math><mfenced close="]" open="["><mrow><mi>k</mi></mrow></mfenced></math></span>, and so on, and 0 &lt; <em>α</em> &lt; 1 is the discount factor.</p></div><div><p>In the DNDP approach, that performance index is approximated by a multilayer neural network (critic network) with ideal weights <span class="math"><math><msub><mrow><mi>W</mi></mrow><mrow><mtext>C</mtext></mrow></msub><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mrow><msub><mrow><mi>N</mi></mrow><mrow><mtext>hC</mtext></mrow></msub><mo>×</mo><mn>1</mn></mrow></msup></math></span> and <span class="math"><math><msub><mrow><mi>V</mi></mrow><mrow><mtext>C</mtext></mrow></msub><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mrow><msub><mrow><mi>N</mi></mrow><mrow><mtext>xC</mtext></mrow></msub><mo>×</mo><msub><mrow><mi>N</mi></mrow><mrow><mtext>hC</mtext></mrow></msub></mrow></msup></math></span> as </p><div class="formula"><span class="label">(8)</span><span class="math"><math><mtable columnalign="left"><mtr><mtd columnalign="right"><mfenced close="|" open=""><mrow><mi>L</mi><mfenced close=")" open="("><mrow><msub><mrow><mi>x</mi></mrow><mrow><mtext>C</mtext></mrow></msub></mrow></mfenced></mrow></mfenced><msub><mrow></mrow><mrow><mfenced close="]" open="["><mrow><mi>k</mi></mrow></mfenced></mrow></msub><mo>=</mo><mfenced close="|" open=""><mrow><mfenced close="]" open="["><mrow><msubsup><mrow><mi>W</mi></mrow><mrow><mtext>C</mtext></mrow><mrow><mtext>T</mtext></mrow></msubsup><mi>σ</mi><mfenced close=")" open="("><mrow><msubsup><mrow><mi>V</mi></mrow><mrow><mtext>C</mtext></mrow><mrow><mtext>T</mtext></mrow></msubsup><msub><mrow><mi>x</mi></mrow><mrow><mtext>C</mtext></mrow></msub></mrow></mfenced><mo>+</mo><msub><mrow><mi>ε</mi></mrow><mrow><mtext>C</mtext></mrow></msub></mrow></mfenced></mrow></mfenced><msub><mrow></mrow><mrow><mfenced close="]" open="["><mrow><mi>k</mi></mrow></mfenced></mrow></msub><mo>,</mo></mtd></mtr></mtable></math></span></div><p>in which <span class="math"><math><msub><mrow><mi>x</mi></mrow><mrow><mtext>C</mtext></mrow></msub><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mrow><msub><mrow><mi>N</mi></mrow><mrow><mtext>xC</mtext></mrow></msub><mo>×</mo><mn>1</mn></mrow></msup></math></span> is the vector of the neural network inputs, <em>ε</em><sub>C</sub> is the bounded approximation error (ie, <span class="math"><math><mfenced close="‖" open="‖"><mrow><msub><mrow><mi>ε</mi></mrow><mrow><mtext>C</mtext></mrow></msub></mrow></mfenced><mo><</mo><msub><mrow><mi>ε</mi></mrow><mrow><mtext>BC</mtext></mrow></msub><mo>∈</mo><mi mathvariant="double-struck">R</mi></math></span>), <span class="math"><math><mi>σ</mi><mfenced close=")" open="("><mrow><mo>.</mo></mrow></mfenced></math></span> is a sigmoidal activation function, and <em>N</em><sub>hC</sub> is the number of nodes in the hidden layer. For simplifying purposes, the notation of the iteration <span class="math"><math><mfenced close="|" open=""><mrow></mrow></mfenced><msub><mrow></mrow><mrow><mfenced close="]" open="["><mrow><mi>k</mi></mrow></mfenced></mrow></msub></math></span> will be presented only when needed. The ideal weights <em>W</em><sub>C</sub> and <em>V</em><sub>C</sub> in Eq. (<span>8</span>) are unknown but they can be approximated by adjustable weights <span class="math"><math><msub><mrow><mi>Ŵ</mi></mrow><mrow><mtext>C</mtext></mrow></msub><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mrow><msub><mrow><mi>N</mi></mrow><mrow><mtext>hC</mtext></mrow></msub><mo>×</mo><mn>1</mn></mrow></msup></math></span> and <span class="math"><math><msub><mrow><mover accent="true"><mrow><mi>V</mi></mrow><mo>^</mo></mover></mrow><mrow><mtext>C</mtext></mrow></msub><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mrow><msub><mrow><mi>N</mi></mrow><mrow><mtext>xC</mtext></mrow></msub><mo>×</mo><msub><mrow><mi>N</mi></mrow><mrow><mtext>hC</mtext></mrow></msub></mrow></msup></math></span> with the network weight errors </p><div class="formula"><span class="label">(9)</span><span class="math"><math><mtable columnalign="left"><mtr><mtd columnalign="right"><mtable><mtr><mtd><msub><mrow><mover accent="true"><mrow><mi>W</mi></mrow><mo>~</mo></mover></mrow><mrow><mtext>C</mtext></mrow></msub></mtd><mtd><mo>=</mo><msub><mrow><mi>W</mi></mrow><mrow><mtext>C</mtext></mrow></msub><mo>−</mo><msub><mrow><mi>Ŵ</mi></mrow><mrow><mtext>C</mtext></mrow></msub><mo>,</mo></mtd></mtr><mtr><mtd><msub><mrow><mover accent="true"><mrow><mi>V</mi></mrow><mo>~</mo></mover></mrow><mrow><mtext>C</mtext></mrow></msub></mtd><mtd><mo>=</mo><msub><mrow><mi>V</mi></mrow><mrow><mtext>C</mtext></mrow></msub><mo>−</mo><msub><mrow><mover accent="true"><mrow><mi>V</mi></mrow><mo>^</mo></mover></mrow><mrow><mtext>C</mtext></mrow></msub><mo>.</mo></mtd></mtr><mtr><mtd></mtd></mtr></mtable></mtd></mtr></mtable></math></span></div><p>As a result, the critic network will generate <span class="math"><math><mi>J</mi><mfenced close=")" open="("><mrow><msub><mrow><mi>x</mi></mrow><mrow><mtext>C</mtext></mrow></msub></mrow></mfenced></math></span>, which is the approximation of the cost function defined in Eq. (<span>8</span>): </p><div class="formula"><span class="label">(10)</span><span class="math"><math><mtable columnalign="left"><mtr><mtd columnalign="right"><mi>J</mi><mfenced close=")" open="("><mrow><msub><mrow><mi>x</mi></mrow><mrow><mtext>C</mtext></mrow></msub></mrow></mfenced><mo>=</mo><msubsup><mrow><mi>Ŵ</mi></mrow><mrow><mtext>C</mtext></mrow><mrow><mtext>T</mtext></mrow></msubsup><msub><mrow><mover accent="true"><mrow><mi>σ</mi></mrow><mo>^</mo></mover></mrow><mrow><mtext>C</mtext></mrow></msub><mfenced close=")" open="("><mrow><msubsup><mrow><mover accent="true"><mrow><mi>V</mi></mrow><mo>^</mo></mover></mrow><mrow><mtext>C</mtext></mrow><mrow><mtext>T</mtext></mrow></msubsup><msub><mrow><mi>x</mi></mrow><mrow><mtext>C</mtext></mrow></msub></mrow></mfenced><mo>=</mo><munderover><mrow><mo>∑</mo></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><msub><mrow><mi>N</mi></mrow><mrow><mtext>hC</mtext></mrow></msub></mrow></munderover><msubsup><mrow><mi>Ŵ</mi></mrow><mrow><mtext>C</mtext></mrow><mrow><mtext>T</mtext></mrow></msubsup><mfenced close=")" open="("><mrow><mn>1</mn><mo>,</mo><mi>i</mi></mrow></mfenced><msub><mrow><mover accent="true"><mrow><mi>σ</mi></mrow><mo>^</mo></mover></mrow><mrow><mtext>C</mtext></mrow></msub><mfenced close=")" open="("><mrow><munderover><mrow><mo>∑</mo></mrow><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><msub><mrow><mi>N</mi></mrow><mrow><mtext>xC</mtext></mrow></msub></mrow></munderover><msubsup><mrow><mover accent="true"><mrow><mi>V</mi></mrow><mo>^</mo></mover></mrow><mrow><mtext>C</mtext></mrow><mrow><mtext>T</mtext></mrow></msubsup><mfenced close=")" open="("><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></mfenced><msub><mrow><mi>x</mi></mrow><mrow><mtext>C</mtext></mrow></msub><mfenced close=")" open="("><mrow><mi>j</mi><mo>,</mo><mn>1</mn></mrow></mfenced></mrow></mfenced><mo>,</mo></mtd></mtr></mtable></math></span></div><p>where <em>N</em><sub>hC</sub> is the number of nodes in the hidden layer and <em>N</em><sub>xC</sub> is the number of inputs to the critic network. The backpropagation error of the critic network indicates how closely the approximated long-term cost function <em>J</em> follows Bellman’s principle of optimality and is defined as follows: </p><div class="formula"><span class="label">(11)</span><span class="math"><math><mtable columnalign="left"><mtr><mtd columnalign="right"><mfenced close="|" open=""><mrow><msub><mrow><mi>e</mi></mrow><mrow><mtext>C</mtext></mrow></msub></mrow></mfenced><msub><mrow></mrow><mrow><mfenced close="]" open="["><mrow><mi>k</mi></mrow></mfenced></mrow></msub><mo>=</mo><munder><mrow><munder accentunder="false"><mrow><mfenced close="]" open="["><mrow><mfenced close="|" open=""><mrow><mi>J</mi></mrow></mfenced><msub><mrow></mrow><mrow><mfenced close="]" open="["><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></mfenced></mrow></msub><mo>−</mo><mfenced close="|" open=""><mrow><mi>S</mi></mrow></mfenced><msub><mrow></mrow><mrow><mfenced close="]" open="["><mrow><mi>k</mi></mrow></mfenced></mrow></msub></mrow></mfenced></mrow><mo>︸</mo></munder></mrow><mrow><mi mathvariant="normal">target</mi></mrow></munder><mo>−</mo><munder><mrow><munder accentunder="false"><mrow><mi>α</mi><mfenced close="|" open=""><mrow><mi>J</mi></mrow></mfenced><msub><mrow></mrow><mrow><mfenced close="]" open="["><mrow><mi>k</mi></mrow></mfenced></mrow></msub><mo>.</mo></mrow><mo>︸</mo></munder></mrow><mrow><mtable columnalign="left"><mtr><mtd><mstyle mathvariant="normal"><mi>current</mi><mspace width="1em"></mspace><mi>outcome</mi></mstyle></mtd></mtr><mtr><mtd></mtd></mtr></mtable></mrow></munder></mtd></mtr></mtable></math></span></div></div></section></div><p class="u-padding-s-top u-padding-xs-bottom read-full-chapter-link"><a href="/science/article/pii/B9780128052464000227" class="button-alternative button-alternative-primary" aria-describedby="tp-snippet-chp-title-B9780128052464000227" data-aa-region="aa-tp-snippet-read-full-chp" data-aa-name="" data-hack="#"><svg focusable="false" viewBox="0 0 54 128" width="32" height="32" class="icon icon-navigate-right button-alternative-icon"><path d="m1 99l38-38-38-38 7-7 45 45-45 45z"></path></svg><span class="button-alternative-text">Read full chapter</span></a></p></div><div class="u-padding-m-bottom"></div></article><article class="snippet"><div class="snippet-inner"><h2 class="u-font-serif u-text-light" id="tp-snippet-chp-title-S009052679680017X"><a class="anchor" href="/science/article/pii/S009052679680017X" data-aa-region="aa-tp-snippet-chp-title" data-aa-name="Stochastic Digital Control System Techniques" data-hack="#"><span class="anchor-text">Stochastic Digital Control System Techniques</span></a></h2><div class="size-l"><cite><p><span>Floyd B. Hanson, in </span><a href="/science/bookseries/00905267" class="anchor" data-aa-region="aa-tp-snippet-bk-title" data-aa-name="Control and Dynamic Systems" data-hack="#"><span class="anchor-text">Control and Dynamic Systems</span></a>, 1996</p></cite><section id="S009052679680017X-s0150"><h3>1 MCA Dynamic Programming Model Formulation</h3><div><p>Consider the stochastic diffusion without Poisson jumps governed by the stochastic differential equation (SDE)</p><div class="formula"><span class="label">(73)</span><span class="math"><math><mi>d</mi><mi mathvariant="bold">X</mi><mfenced close=")" open="("><mi>t</mi></mfenced><mo>=</mo><mi mathvariant="bold">F</mi><mfenced close=")" separators=",," open="("><mi mathvariant="bold">X</mi><mi mathvariant="bold">U</mi><mi>t</mi></mfenced><mi>d</mi><mi>t</mi><mo>+</mo><mi>G</mi><mfenced close=")" separators="," open="("><mi mathvariant="bold">X</mi><mi>t</mi></mfenced><mi>d</mi><mi mathvariant="bold">W</mi><mfenced close=")" open="("><mi>t</mi></mfenced><mtext>,</mtext></math></span></div></div><div><p>where the notation is the same as in <span>(1)</span>. It is assumed that drift <strong>F</strong> and Gaussian coefficient <em>G</em> are bounded, continuous and Lipshitz continuous in the state <strong>X</strong>, while <strong>F</strong> is uniformly so in the control <strong>U</strong>. Further, let the expected cost objective functional be</p><div class="formula"><span class="label">(74)</span><span class="math"><math><mtable columnalign="left"><mtr columnalign="left"><mtd columnalign="left"><mover accent="true"><mi>V</mi><mo stretchy="true">¯</mo></mover><mfenced close=")" separators=",," open="("><mi mathvariant="bold">x</mi><mi mathvariant="bold">u</mi><mi>t</mi></mfenced></mtd><mtd columnalign="left"><mo>=</mo></mtd><mtd columnalign="left"><mi mathvariant="normal">Mean</mi><mfenced close="" open="["><mstyle displaystyle="true"><msubsup><mo stretchy="true">∫</mo><mi>t</mi><msub><mi>t</mi><mi>f</mi></msub></msubsup><mrow><mi>d</mi><mi>τ</mi><mspace width="0.12em"></mspace><mi>C</mi><mfenced close=")" open="("><mrow><mi mathvariant="bold">X</mi><mfenced close=")" open="("><mi>τ</mi></mfenced><mo>,</mo><mi mathvariant="bold">U</mi><mfenced close=")" open="("><mrow><mi mathvariant="bold">X</mi><mfenced close=")" open="("><mi>τ</mi></mfenced><mo>,</mo><mi>τ</mi></mrow></mfenced><mo>,</mo><mi>τ</mi></mrow></mfenced></mrow></mstyle></mfenced></mtd></mtr><mtr columnalign="left"><mtd columnalign="left"></mtd><mtd columnalign="left"><mo stretchy="true">|</mo></mtd><mtd columnalign="left"><mfenced close="]" open=""><mrow><mi mathvariant="bold">X</mi><mfenced close=")" open="("><mi>t</mi></mfenced><mo>=</mo><mi mathvariant="bold">x</mi><mo>,</mo><mi mathvariant="bold">U</mi><mo>=</mo><mi mathvariant="bold">u</mi></mrow></mfenced><mo>+</mo><mover accent="true"><mi>Z</mi><mo stretchy="true">¯</mo></mover><mfenced close=")" separators="," open="("><mi mathvariant="bold">x</mi><msub><mi>t</mi><mi>f</mi></msub></mfenced><mtext>,</mtext></mtd></mtr></mtable></math></span></div></div><p id="S009052679680017X-p1240">with the same notation as in <span>(2)</span>. It is assumed that the instantaneous cost <em>C</em> and the salvage cost <span class="math"><math><mover accent="true"><mi>Z</mi><mo stretchy="true">¯</mo></mover></math></span> are bounded and continuous. Much also may depend on the boundary conditions. The final side condition is the same as that in <span>(8)</span> for SDP.</p><div><p>The optimal costs are defined as</p><div class="formula"><span class="label">(75)</span><span class="math"><math><msup><mi>υ</mi><mo>*</mo></msup><mfenced close=")" separators="," open="("><mi mathvariant="bold">x</mi><mi>t</mi></mfenced><mo>=</mo><munder><mo>inf</mo><mi mathvariant="bold">u</mi></munder><mfenced close="]" open="["><mrow><mover accent="true"><mi>V</mi><mo stretchy="true">¯</mo></mover><mfenced close=")" separators=",," open="("><mi mathvariant="bold">x</mi><mi mathvariant="bold">u</mi><mi>t</mi></mfenced></mrow></mfenced><mtext>,</mtext></math></span></div></div><p id="S009052679680017X-p1250">using the infimum (inf), instead of the less general minimum (min) in the spirit of <span>[76]</span>, over all admissible controls.</p><div><p><span>Upon application of the <span class="topic-highlight">principle of optimality</span>, the dynamic programming equation for the optimal expected cost </span><em>υ</em>* is</p><div class="formula"><span class="label">(76)</span><span class="math"><math><mtable columnalign="left"><mtr columnalign="left"><mtd columnalign="left"><mn>0</mn></mtd><mtd columnalign="left"><mo>=</mo></mtd><mtd columnalign="left"><msubsup><mi>υ</mi><mi>t</mi><mo>*</mo></msubsup><mo>+</mo><msub><mi mathvariant="normal">ℒ</mi><mi>x</mi></msub><mfenced close="]" open="["><msup><mi>υ</mi><mo>*</mo></msup></mfenced><mfenced close=")" separators="," open="("><mi mathvariant="bold">x</mi><mi>t</mi></mfenced></mtd></mtr><mtr columnalign="left"><mtd columnalign="left"></mtd><mtd columnalign="left"><mo>=</mo></mtd><mtd columnalign="left"><msubsup><mi>υ</mi><mi>t</mi><mo>*</mo></msubsup><mo>+</mo><munder><mo>inf</mo><mi mathvariant="bold">u</mi></munder><mfenced close="" open="["><mrow><msup><mi mathvariant="bold">F</mi><mi>T</mi></msup><mfenced close=")" open="("><mrow><mi mathvariant="bold">x</mi><mo>,</mo><mi mathvariant="bold">u</mi><mi>t</mi></mrow></mfenced><msub><mo>∇</mo><mi>x</mi></msub><mfenced close="]" open="["><msup><mi>υ</mi><mo>*</mo></msup></mfenced></mrow></mfenced><mo>+</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mfenced close=")" open="("><mrow><mi>G</mi><msup><mi>G</mi><mi>T</mi></msup></mrow></mfenced><mfenced close=")" separators="," open="("><mi mathvariant="bold">x</mi><mi>t</mi></mfenced><mo>:</mo><msub><mo>∇</mo><mi>x</mi></msub><msubsup><mo>∇</mo><mi>x</mi><mi>T</mi></msubsup><mfenced close="]" open="["><msup><mi>υ</mi><mo>*</mo></msup></mfenced></mtd></mtr><mtr columnalign="left"><mtd columnalign="left"></mtd><mtd columnalign="left"><mo>+</mo></mtd><mtd columnalign="left"><mi>C</mi><mfenced close=")" separators=",," open="("><mi mathvariant="bold">x</mi><mi mathvariant="bold">u</mi><mi>t</mi></mfenced><mtext>.</mtext></mtd></mtr></mtable></math></span></div></div><div><p><span id="S009052679680017X-p146"></span>Since <span>(76)</span> is a backward equation and since we want to keep it simple, <span>(76)</span> is approximated with the Backward Euler approximation</p><div class="formula"><span class="label">(77)</span><span class="math"><math><mtable columnalign="left"><mtr columnalign="left"><mtd columnalign="left"><msubsup><mi>υ</mi><mrow><mi>κ</mi><mo>−</mo><mn>1</mn></mrow><mo>*</mo></msubsup></mtd><mtd columnalign="left"><mo>=</mo></mtd><mtd columnalign="left"><msubsup><mi>υ</mi><mi>κ</mi><mo>*</mo></msubsup><mfenced close=")" open="("><mi mathvariant="bold">x</mi></mfenced><mo>+</mo><mi>Δ</mi><msub><mi>t</mi><mrow><mi>κ</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>⋅</mo><munder><mo>inf</mo><mi mathvariant="bold">u</mi></munder><mfenced close="" open="["><mrow><msubsup><mi mathvariant="bold">F</mi><mi>κ</mi><mi>T</mi></msubsup><mfenced close=")" separators="," open="("><mi mathvariant="bold">x</mi><mi mathvariant="bold">u</mi></mfenced><msub><mo>∇</mo><mi>x</mi></msub><mfenced close="]" open="["><msubsup><mi>υ</mi><mi>x</mi><mo>*</mo></msubsup></mfenced></mrow></mfenced></mtd></mtr><mtr columnalign="left"><mtd columnalign="left"></mtd><mtd columnalign="left"><mo>+</mo></mtd><mtd columnalign="left"><mfenced close="]" open=""><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><msub><mfenced close=")" open="("><mrow><mi>G</mi><msup><mi>G</mi><mi>T</mi></msup></mrow></mfenced><mi>κ</mi></msub><mfenced close=")" open="("><mi mathvariant="bold">x</mi></mfenced><mo>:</mo><msub><mo>∇</mo><mi>x</mi></msub><msubsup><mo>∇</mo><mi>x</mi><mi>T</mi></msubsup><mfenced close="]" open="["><msubsup><mi>υ</mi><mi>κ</mi><mo>*</mo></msubsup></mfenced><mo>+</mo><msub><mi>C</mi><mi>κ</mi></msub><mfenced close=")" separators="," open="("><mi mathvariant="bold">x</mi><mi mathvariant="bold">u</mi></mfenced></mrow></mfenced></mtd></mtr></mtable><mtext>,</mtext></math></span></div></div><p id="S009052679680017X-p1265">for <em>κ</em> = 1 to <em>K</em>, with <span class="math"><math><msubsup><mi>υ</mi><mi>κ</mi><mo>*</mo></msubsup><mfenced close=")" open="("><mi mathvariant="bold">x</mi></mfenced><mo>≃</mo><msup><mi>υ</mi><mo>*</mo></msup><mfenced close=")" separators="," open="("><mi mathvariant="bold">x</mi><msub><mi>t</mi><mi>κ</mi></msub></mfenced></math></span> and similarly for <strong>F</strong><em><sub>κ</sub></em>, <em>G<sub>κ</sub></em> and <em>C<sub>κ</sub></em>, while <em>t<sub>κ</sub></em> = <em>t</em><sub><em>κ</em>–1</sub> + Δ<em>t</em><sub><em>κ</em>–1</sub> is time in terms of the forward index <em>κ.</em> The final condition is <span class="math"><math><msubsup><mi>υ</mi><mi>K</mi><mo>*</mo></msubsup><mfenced close=")" open="("><mi mathvariant="bold">x</mi></mfenced><mo>≃</mo><msup><mi>υ</mi><mo>*</mo></msup><mfenced close=")" separators="," open="("><mi mathvariant="bold">x</mi><msub><mi>t</mi><mi>f</mi></msub></mfenced><mo>=</mo><msup><mover accent="true"><mi>Z</mi><mo stretchy="true">¯</mo></mover><mo>*</mo></msup><mfenced close=")" separators="," open="("><mi mathvariant="bold">x</mi><msub><mi>t</mi><mi>f</mi></msub></mfenced></math></span>. (The correlation, in the case of constant time increments, between the forward index <em>κ</em> and the backward index <em>k</em> used in SDP is that <em>T<sub>k</sub></em> = <em>t<sub>f</sub></em> – <em>k</em> · Δ<em>T</em> = (<em>K</em> – <em>k</em>) · Δ<em>T</em> = <em>t</em><sub><em>K</em>–<em>k</em></sub> = <em>t<sub>κ</sub></em>, so the forward and backward time indices are related by <em>κ</em> = <em>K</em> = <em>k</em>. Hence, <em>T</em><sub>0</sub> = <em>t<sub>f</sub></em> = <em>t<sub>K</sub></em> and <em>T<sub>K</sub></em> = 0 = <em>t</em><sub>0</sub>, are the final and initial times, respectively, in either time direction.) The interpolation time increment is denoted by Δ<em>t</em><sub><em>κ</em>–1</sub> = <em>t<sub>κ</sub></em> – <em>t</em><sub><em>κ</em>–1</sub> here and has important roles to play for modeling and for numerical convergence.</p><p id="S009052679680017X-p1270">However, since much of the literature on MCA, corresponding to much of the literature on stochastic control, is formulated as a stationary (time-independent) problem, the indices <em>k</em> and <em>κ</em> are treated as iteration indices for the time-independent problem. The time-independent problem may arise from ergodic problems or exit time problems or infinite horizon problems, for example.</p></section></div><p class="u-padding-s-top u-padding-xs-bottom read-full-chapter-link"><a href="/science/article/pii/S009052679680017X" class="button-alternative button-alternative-primary" aria-describedby="tp-snippet-chp-title-S009052679680017X" data-aa-region="aa-tp-snippet-read-full-chp" data-aa-name="" data-hack="#"><svg focusable="false" viewBox="0 0 54 128" width="32" height="32" class="icon icon-navigate-right button-alternative-icon"><path d="m1 99l38-38-38-38 7-7 45 45-45 45z"></path></svg><span class="button-alternative-text">Read full chapter</span></a></p></div><div class="u-padding-m-bottom"></div></article><article class="snippet"><div class="snippet-inner"><h2 class="u-font-serif u-text-light" id="tp-snippet-chp-title-B9780081010419000028"><a class="anchor" href="/science/article/pii/B9780081010419000028" data-aa-region="aa-tp-snippet-chp-title" data-aa-name="Introduction to Optimization" data-hack="#"><span class="anchor-text">Introduction to Optimization</span></a></h2><div class="size-l"><cite><p><span>Yavuz Eren, ... İlker Üstoğlu, in </span><a href="/book/9780081010419" class="anchor" data-aa-region="aa-tp-snippet-bk-title" data-aa-name="Optimization in Renewable Energy Systems" data-hack="#"><span class="anchor-text">Optimization in Renewable Energy Systems</span></a>, 2017</p></cite><section id="B9780081010419000028-s0010"><h3>2.1 Introduction</h3><p id="B9780081010419000028-p0010"><span id="B9780081010419000028-p27"></span>The existence of optimization methods can be traced back to the days of Newton, Lagrange, and Cauchy. Newton and Leibnitz made invaluable contributions to the literature of calculus which allowed the development of differential calculus methods for optimization. However, the minimization of some functions using calculus of variations has been established by Bernoulli, Euler, Lagrange, and Weierstrass. Then, Lagrange introduced the method of adding unknown multipliers to the minimization problem, which led him to cope with constrained optimization problems. For the solution of optimization problems, Cauchy introduced the first application of the steepest descent method to solve unconstrained optimization problems. By the middle of the 20th century, the high-speed digital computers made implementation of the complex optimization procedures possible and stimulated further research on newer methods. Spectacular advances followed, producing a massive literature on optimization techniques. This advancement also resulted in the emergence of several well-defined new areas in optimization theory.</p><p id="B9780081010419000028-p0015">Some of the major developments in the area of numerical methods of unconstrained optimization can be outlined as follows. The work on optimization theory was born by the development of the simplex method by Dantzig in 1947 for linear programming (LP) problems <span>[1]</span><span>. Then, the <span class="topic-highlight">principle of optimality</span> was presented by Bellman for dynamic programming problems in 1957 </span><span>[2]</span>. Work by Kuhn and Tucker in 1951 on the necessary and sufficient conditions for the optimal solution of programming problems laid the foundation for later research in non-LP (NLP) <span>[3]</span>. But the most valuable contributions to NLP were made by Zoutendijk and Rosen during the early 1960s <span>[4,5]</span>. Again in the same year, Duffin, Peterson, and Zener developed geometric programming, and Gomory did pioneering work in integer programming, which is one of the most exciting and rapidly developing areas of optimization <span>[6,7]</span>. The reason for this is that most real world applications fall under this category of problems. Also, Dantzig, Charnes, Cooper and, Symons developed stochastic programming techniques and solved problems by assuming design parameters to be independent and normally distributed <span>[8–10]</span>. In the last decade, simulated annealing (SA), genetic algorithms (GAs), and neural network methods were introduced to represent a new class of mathematical programming. Between them, SA is analogous to the physical process of annealing of metals and glass. The GAs are search techniques based on the mechanics of natural selection and natural genetics and finally neural network methods are based on solving the problem using the computing power of a network of interconnected “neuron” processors.<span id="B9780081010419000028-p28"></span></p><p id="B9780081010419000028-p0020">To indicate the widespread scope of the subject, some major applications in different engineering disciplines can be listed as follows: Design of civil engineering structures such as frames, foundations, bridges, towers, chimneys, and dams for minimum cost; design of minimum weight structures for earth quake, wind, and other types of random loading; design of water resources systems for obtaining maximum benefit; design of aircraft and aerospace structure for minimum weight; finding the optimal trajectories of space vehicles; design of pumps, turbines and heat transfer equipment for maximum efficiency; optimum design of electrical machinery such as motors, generators, and transformers; optimum design of electrical networks; finding out the optimal energy production and distribution strategy; optimum design of control systems; optimum design of chemical processing equipments and plants; optimal selection of a site for an industry; optimal planning of maintenance and replacement of equipment to reduce operating costs; allocation of resources or services among several activities to maximize the benefit; controlling the waiting and idle times in production lines to reduce the cost of production; designing the shortest route to be taken by a salesperson to visit various cities in a single tour and optimal production planning, controlling, and scheduling.</p></section></div><p class="u-padding-s-top u-padding-xs-bottom read-full-chapter-link"><a href="/science/article/pii/B9780081010419000028" class="button-alternative button-alternative-primary" aria-describedby="tp-snippet-chp-title-B9780081010419000028" data-aa-region="aa-tp-snippet-read-full-chp" data-aa-name="" data-hack="#"><svg focusable="false" viewBox="0 0 54 128" width="32" height="32" class="icon icon-navigate-right button-alternative-icon"><path d="m1 99l38-38-38-38 7-7 45 45-45 45z"></path></svg><span class="button-alternative-text">Read full chapter</span></a></p></div><div class="u-padding-m-bottom"></div></article><article class="snippet"><div class="snippet-inner"><h2 class="u-font-serif u-text-light" id="tp-snippet-chp-title-B9780128150108000065"><a class="anchor" href="/science/article/pii/B9780128150108000065" data-aa-region="aa-tp-snippet-chp-title" data-aa-name="iHorizon driver energy management for PHEV real-time control" data-hack="#"><span class="anchor-text">iHorizon driver energy management for PHEV real-time control</span></a></h2><div class="size-l"><cite><p><span>Clara Marina Martínez, Dongpu Cao, in </span><a href="/book/9780128150108" class="anchor" data-aa-region="aa-tp-snippet-bk-title" data-aa-name="Ihorizon-Enabled Energy Management for Electrified Vehicles" data-hack="#"><span class="anchor-text">Ihorizon-Enabled Energy Management for Electrified Vehicles</span></a>, 2019</p></cite><section id="B9780128150108000065-s0040"><h3>6.2.2 Optimal solution: Dynamic programming</h3><p id="B9780128150108000065-p0325">Dynamic programming is herewith implemented offline with low requirements in terms of computational time and effort. The algorithm is implemented with a simplified vehicle model with sufficient accuracy to capture the optimal working conditions of the hybrid components, but limited computational requirements as provided by a processor, the Intel CORE i7. This offline implementation allows the use of a dynamic programming algorithm implemented in MATLAB and used to optimise a vehicle model included in a MATLAB function file. Although there are numerous approaches in the literature to obtain optimal results that can reduce the computational effort required, the beneficial characteristics and numerous satisfactory implementations in the research on dynamic programming suggest the implementation of this methodology for this application.</p><p id="B9780128150108000065-p0330">The dynamic programming algorithm can obtain global optimal results of multivariable nonlinear problems. In common with other optimisation algorithms, the solution is found by minimising an unwanted outcome or maximising a sought benefit. In minimisation problems, this unwanted outcome is called a cost function, although other commonly used terms include target and objective function. The optimal solution is strongly conditioned by the target or targets of interest, which determine the control strategy to follow <span>[18]</span>. Dynamic programming is particularly recommended for offline energy management optimisation due to the possibility of achieving global optimal solutions and reducing the baseline problem into subproblems. <em>N</em>-Dimensional problems are divided into <em>N</em><span> problems of one dimension, easier and faster to solve, whose optimality is guaranteed through the <span class="topic-highlight">principle of optimality</span> </span><span>[37–39]</span>. This optimisation algorithm is particularly useful when dealing with solutions distributed in common branches that converge into a single state. In the event that more than one solution candidate converges into the same instantaneous conditions, the strategies associated with higher cost can be automatically discarded, as it can be ensured that they would not outperform the candidate converging into the same state with lower cost; “<em>optimal policies have optimal subpolicies</em>” <span>[37]</span>. This implies that, given a common state, alternative branches that lead to it can be simplified, maintaining only the ones that provide minimum cost <span>[40]</span>. This process reduces the solution candidates that need to be further elaborated and carried forward and consequently decrements considerably the computational effort required. Hybrid vehicle control is known to have a solution of the characteristics described, which is why they benefit from dynamic programming as observed in numerous publications. More information about the characteristics of this algorithm are detailed in <span>Section 2.4.2</span>.</p><p id="B9780128150108000065-p0335">Dynamic programming is implemented with its deterministic version, since the characteristics of the cycles are perfectly known and collected with complete information from real-life conditions. In offline optimisation and with the aim of generating expert data for training, it is assumed that all disturbances are perfectly controlled. After implementation, the optimal controller would operate based on the predicted future power demand, as generated by the long-term speed prediction algorithm. Although the methodology implementation is clear, the solution is particularly dependent on the selection criteria, that is, the cost function. The most popular objective is fuel consumption reduction; the objective function can be expressed in terms of other variables such as tailpipe emissions reduction, performance enhancement or a combination of these with multiobjective approaches. When dealing with conflicting objectives, the combined optimal values require parallel computation and pareto solutions analysis. This computationally expensive resolution can be simplified using a single objective function in which the objectives are mixed through weight summation or constrained within desired intervals. Whilst constrained objectives cannot be efficiently optimised, the combination of weighted objectives can achieve an optimal trade-off, provided the weights are properly selected, that is, they properly represent the relative importance of each objective and their selection is mathematically justified.</p><p id="B9780128150108000065-p0340">The approach taken here consists of a combination of electric and chemical power weighted using the relative cost between the sources of energy. Fuel and electricity prices are used to combine the two power signals and generate a cost function that targets the minimisation of the overall energy cost. This approach allows an analysis of the trade-off between electricity and fuel and the effect of the energy cost in the control strategy. However, in practise and due to the higher cost of fuel and the lower efficiency of the internal combustion engine compared to the electric components, the previous cost function is equivalent to fuel consumption minimisation. Nevertheless, it also allows for modification of the relative price of the electricity and fuel cost and study of their effect on the energy management strategy.</p></section></div><p class="u-padding-s-top u-padding-xs-bottom read-full-chapter-link"><a href="/science/article/pii/B9780128150108000065" class="button-alternative button-alternative-primary" aria-describedby="tp-snippet-chp-title-B9780128150108000065" data-aa-region="aa-tp-snippet-read-full-chp" data-aa-name="" data-hack="#"><svg focusable="false" viewBox="0 0 54 128" width="32" height="32" class="icon icon-navigate-right button-alternative-icon"><path d="m1 99l38-38-38-38 7-7 45 45-45 45z"></path></svg><span class="button-alternative-text">Read full chapter</span></a></p></div><div class="u-padding-m-bottom"></div></article><article class="snippet"><div class="snippet-inner"><h2 class="u-font-serif u-text-light" id="tp-snippet-chp-title-B9780080451411000020"><a class="anchor" href="/science/article/pii/B9780080451411000020" data-aa-region="aa-tp-snippet-chp-title" data-aa-name="Dynamic optimization problems" data-hack="#"><span class="anchor-text">Dynamic optimization problems</span></a></h2><div class="size-l"><cite><p><span>Stanisław Sieniutycz, Jacek Jeżowski, in </span><a href="/book/9780080451411" class="anchor" data-aa-region="aa-tp-snippet-bk-title" data-aa-name="Energy Optimization in Process Systems" data-hack="#"><span class="anchor-text">Energy Optimization in Process Systems</span></a>, 2009</p></cite><section id="B9780080451411000020-s0010"><h3>2.1 Discrete representations and dynamic programming algorithms</h3><div><p id="B9780080451411000020-p0010">In optimization, a process is regarded as dynamic when it can be described as a well-defined sequence of steps in time or space. Dynamic processes can be either discrete or continuous. Cascades (<span>Figure 2.1</span>), which are systems characterized by sequential arrangement of stages, are examples of dynamic discrete processes. The stages can be of finite size, in which case the process is “inherently discrete”, or may be infinitesimally small. The latter case refers to a limiting situation where the concept of very many steps serves to approximate the development of a continuous process. In general, optimization theories of discrete and continuous processes differ in their assumptions, formal descriptions and strength of optimality conditions; thus they usually constitute two different fields. Here, however, for brevity, we present a heuristic derivation of optimization conditions focusing on those which in many respects are common for both discrete and continuous processes. Consequently we shall formulate first a basic discrete algorithm for a general model of a discrete cascade process, and then consider its limiting properties when the number of infinitesimal discrete steps tends towards infinity.</p><figure id="B9780080451411000020-f0010"><div class="download-image"><div class="image-holder"><script src="https://ajax.cloudflare.com/cdn-cgi/scripts/95c75768/cloudflare-static/rocket-loader.min.js" data-cf-settings="2975f070f66ff17199d53d68-|49"></script><img src="https://ars.els-cdn.com/content/image/3-s2.0-B9780080451411000020-gr1.jpg?_" height="251" alt="" crossorigin="anonymous" onerror="this.onerror=null;window.IMG_NO_CORS=!0;this.removeAttribute('crossorigin');this.src=this.src.replace(/\?.*$/,'')" /></div><div class="u-margin-s-ver text-s"></div></div><div class="captions"><span><p id="B9780080451411000020-sp0010"><span class="label">Figure 2.1</span>. Backward optimization algorithm and typical mode of stage numbering in the dynamic programming method. The results are generated in terms of the initial states <strong>x</strong><sup><em>n</em></sup>.</p></span></div></figure></div><div><p id="B9780080451411000020-p0020">The method of dynamic programming (DP; <span class="intra-refs"><span class="intra-ref">Bellman, 1957; Aris, 1964; Findeisen et al., 1980</span><span><span class="intra-ref">Bellman, 1957</span></span><span><span class="intra-ref">Aris, 1964</span></span><span><span class="intra-ref">Findeisen et al., 1980</span></span></span>) constitutes a suitable tool to handle optimality conditions for inherently discrete processes. Yet, the method only enables an easy passage to<span id="B9780080451411000020-p46"></span><span> its limiting form for continuous systems under the differentiability assumption. Application of the method is straightforward when it is applied in optimization of control systems without feedback. Dynamic programming is crucial for the existence of the optimal performance potentials discussed in this book, and for the derivation of pertinent equations which describe these potentials. The DP method is based on Bellman&#x27;s <span class="topic-highlight">principle of optimality</span>, which makes it possible to replace the simultaneous evaluation of all optimal controls by sequences of local evaluations at sequentially included stages, for evolving subprocesses (</span><span>Figures 2.1 and 2.2</span>).</p><figure id="B9780080451411000020-f0020"><div class="download-image"><div class="image-holder"><script src="https://ajax.cloudflare.com/cdn-cgi/scripts/95c75768/cloudflare-static/rocket-loader.min.js" data-cf-settings="2975f070f66ff17199d53d68-|49"></script><img src="https://ars.els-cdn.com/content/image/3-s2.0-B9780080451411000020-gr2.jpg?_" height="265" alt="" crossorigin="anonymous" onerror="this.onerror=null;window.IMG_NO_CORS=!0;this.removeAttribute('crossorigin');this.src=this.src.replace(/\?.*$/,'')" /></div><div class="u-margin-s-ver text-s"></div></div><div class="captions"><span><p id="B9780080451411000020-sp0020"><span class="label">Figure 2.2</span>. Forward optimization algorithm; the results are generated in terms of the final states <strong>x</strong><sup><em>n</em></sup>.</p></span></div></figure></div><p id="B9780080451411000020-p0030">Let us focus first on <span>Figure 2.1</span>, where the optimal performance function is generated in terms of the initial states and initial time. The principle of optimality may then be stated as follows: <em>In a continuous or discrete process which is described by an additive performance criterion</em>, <em>the optimal strategy and optimal profit are functions of the initial state</em>, <em>initial time and (in a discrete process) total number of stages</em>. A consequence of this property is that each final segment of an optimal path (continuous or discrete) is optimal with respect to its own initial state, initial time and (in a discrete process) the corresponding number of stages. An easy proof of this formulation by contradiction uses the additivity property of the performance criterion (<span>Aris, 1964</span>).</p><p id="B9780080451411000020-p0040">The above formulation of the optimality principle refers to the so-called backward algorithm of the dynamic programming method (<span>Figure 2.1</span>). In this mode, the recursive procedure for applying a governing functional equation begins at the final process state and terminates at its initial state. Consequently, local optimizations take place in the direction opposite to the direction of physical time or the direction of flow of matter. (The process to which this can be applied may be arbitrary: it may be discrete by nature or may be obtained by the discretization of an originally continuous process.) The state transformations possess in the backward algorithm their most natural form, as they describe output states in terms<span id="B9780080451411000020-p47"></span> of input states and controls at a stage. The optimization at a stage and optimal functions recursively involve the information generated in earlier subprocesses.</p><p id="B9780080451411000020-p0050">However, one may also generate the optimal profit function in terms of the final states and final time. The optimality principle then has a dual form: <em>In a continuous or discrete process</em>, <em>which is described by an additive performance criterion</em>, <em>the optimal strategy and optimal profit are functions of the final state</em>, <em>final time and (in a discrete process) total number of stages</em>. A basic consequence of this property is that each initial segment of the optimal path (continuous or discrete) is optimal with respect to its final state, final time and (in a discrete process) the corresponding number of stages. This formulation refers to the so-called forward algorithm of the dynamic programming method. In this algorithm the recursive optimization procedure for solving the governing functional equation begins from the initial process state and terminates at its final state. With the forward DP algorithm, one makes local optimizations in the direction of real time.</p><p id="B9780080451411000020-p0060">It is the dual (forward) formulation of the optimality principle and the associated forward algorithm that we commonly apply to multistage processes considered later in this chapter. The state transformations used in this case have the form which describes input states in terms of output states and controls at a process stage. Transformations of this sort are directly obtained for multistage processes with an ideal mixing at the stage, otherwise the inverse transformations (applicable to the backward algorithm) might be difficult to obtain in an explicit form. Again, as in the case of the original form of the optimality principle, its dual form makes it possible to replace the simultaneous evaluation of all optimal controls by successive evaluations for evolving optimal subprocesses.</p><p id="B9780080451411000020-p0070">In the continuous case under the differentiability assumption the method of dynamic programming leads to a basic equation of optimal continuous processes called the Hamilton–Jacobi–Bellman equation which constitutes a control counterpart of the well-known Hamilton–Jacobi equation of classical mechanics (<span class="intra-refs"><span class="intra-ref">Rund, 1966; Landau and Lifshitz, 1971</span><span><span class="intra-ref">Rund, 1966</span></span><span><span class="intra-ref">Landau and Lifshitz, 1971</span></span></span>). Moreover, as we shall see later, a similar equation can be derived for special discrete processes: those with unconstrained time intervals <em>θ</em><sup><em>n</em></sup>.</p></section></div><p class="u-padding-s-top u-padding-xs-bottom read-full-chapter-link"><a href="/science/article/pii/B9780080451411000020" class="button-alternative button-alternative-primary" aria-describedby="tp-snippet-chp-title-B9780080451411000020" data-aa-region="aa-tp-snippet-read-full-chp" data-aa-name="" data-hack="#"><svg focusable="false" viewBox="0 0 54 128" width="32" height="32" class="icon icon-navigate-right button-alternative-icon"><path d="m1 99l38-38-38-38 7-7 45 45-45 45z"></path></svg><span class="button-alternative-text">Read full chapter</span></a></p></div><div class="u-padding-m-bottom"></div></article></div></div></section></main><div id="footer" role="contentinfo"><div class="hor-line-top u-padding-s-top u-bg-white u-clr-grey7" style="border-color:#e9711c"></div><a class="anchor u-padding-s-left move-left els-footer-elsevier" href="https://www.elsevier.com/" target="_blank" rel="nofollow" style="white-space:nowrap"><span class="anchor-text"><svg viewBox="-3345 3440.027 140.01 24.333" style="width:104px;height:30px"><title>Elsevier</title><path id="E" style="fill:#E9711C" d="M-3343.999,3461.698c2.24,0,3.026-0.473,3.026-2.892v-13.393c0-2.42-0.785-2.89-3.026-2.891v-0.59 h16.787l0.252,4.455h-0.56c-0.308-2.48-1.513-3.216-3.84-3.216h-5.325c-1.26,0-1.26,0.355-1.26,2.066v5.693h5.913 c1.934,0,2.522-0.826,2.718-2.803h0.56v6.844h-0.56c-0.168-1.946-0.813-2.802-2.718-2.802h-5.913v6.401 c0,1.858,0.11,2.476,1.4,2.476h5.914c2.522,0,4.092-1.62,4.82-3.952l0.532,0.207l-1.513,4.985H-3344L-3343.999,3461.698"></path><path style="fill:#E9711C" d="M-3325.448,3461.698c2.074-0.118,2.83-0.502,2.83-2.832v-13.511c0-2.33-0.757-2.715-2.83-2.832v-0.591h8.884 v0.591c-2.243,0-3.027,0.472-3.027,2.891v13.009c0,1.652,0.056,2.625,1.71,2.625h4.008c3,0,4.4-2,5.576-4.1l0.673,0.118 l-1.71,5.222h-16.114V3461.698"></path><path style="fill:#E9711C" d="M-3307.122,3456.27h0.561c1.12,2.596,2.886,5.4,5.94,5.4c2,0,3.672-1.3,3.672-3.334 c0-1.652-1.626-3.1-4.176-4.927c-3.28-2.36-5.41-3.746-5.41-6.43c0-3.422,2.55-5.517,5.633-5.517c2.214,0,3,0.944,4.204,0.944 c0.476,0,0.56-0.266,0.476-0.737h0.561l0.645,6.076h-0.561c-0.785-2.625-2.523-5.19-5.354-5.19c-1.737,0-3.138,1.356-3.138,3.185 c0,1.918,1.933,3.157,5.016,5.016c2.523,1.504,5,3.362,5,6.254c0,3.245-2.608,5.752-5.97,5.752c-2.02,0-4.148-0.855-4.68-0.855 c-0.336,0-0.7,0.207-0.756,0.649h-0.56l-1.094-6.282"></path><path style="fill:#E9711C" d="M-3293.999,3461.698c2.24,0,3.026-0.473,3.026-2.892v-13.393c0-2.42-0.785-2.89-3.026-2.891v-0.59 h16.787l0.252,4.455h-0.56c-0.308-2.48-1.513-3.216-3.84-3.216h-5.325c-1.26,0-1.26,0.355-1.26,2.066v5.693h5.913 c1.934,0,2.522-0.826,2.718-2.803h0.56v6.844h-0.56c-0.168-1.946-0.813-2.802-2.718-2.802h-5.913v6.401 c0,1.858,0.11,2.476,1.4,2.476h5.914c2.522,0,4.092-1.62,4.82-3.952l0.532,0.207l-1.513,4.985H-3294L-3293.999,3461.698"></path><path style="fill:#E9711C" d="M-3265.839,3462.524h-0.42l-5.41-12.538c-0.896-2.065-1.71-4.16-2.83-6.136 c-0.478-0.826-1.346-1.327-2.3-1.327v-0.591h8.323v0.591c-0.785,0-2.354,0-2.354,1.15c0,0.384,0.87,2.45,1.653,4.308l4.063,9.676 l4.877-11.359c0.588-1.356,0.757-2.094,0.757-2.713c0-0.618-0.673-0.974-2.13-1.062v-0.59h5.941v0.591 c-0.337,0.06-0.7,0.117-1.037,0.295c-1.066,0.56-2.13,3.57-2.635,4.749l-6.5,14.957"></path><path style="fill:#E9711C" d="M-3255.472,3461.698c2.24,0,3.025-0.473,3.025-2.892v-13.393c0-2.42-0.784-2.89-3.025-2.891v-0.59h9.078v0.591 c-2.24,0-3.025,0.472-3.025,2.891v13.393c0,2.42,0.784,2.892,3.025,2.892v0.59h-9.08v-0.59"></path><path id="E_2_" style="fill:#E9711C" d="M-3244.999,3461.698c2.24,0,3.026-0.473,3.026-2.892v-13.393c0-2.42-0.785-2.89-3.026-2.891v-0.59 h16.787l0.252,4.455h-0.56c-0.308-2.48-1.513-3.216-3.84-3.216h-5.325c-1.26,0-1.26,0.355-1.26,2.066v5.693h5.913 c1.934,0,2.522-0.826,2.718-2.803h0.56v6.844h-0.56c-0.168-1.946-0.813-2.802-2.718-2.802h-5.913v6.401 c0,1.858,0.11,2.476,1.4,2.476h5.914c2.522,0,4.092-1.62,4.82-3.952l0.532,0.207l-1.513,4.985H-3245L-3244.999,3461.698"></path><path style="fill:#E9711C" d="M-3206,3461.698c-1.26-0.354-1.71-0.68-2.466-1.623l-6.166-7.609c3.027-0.65,5.13-2.185,5.13-5.547 c0-4.75-4.26-4.986-7.764-4.986h-9.191v0.591c2.24,0,3.026,0.472,3.026,2.891v13.393c0,2.42-0.785,2.892-3.026,2.892v0.59h9.08 v-0.59c-2.242,0-3.027-0.473-3.027-2.892v-5.604h2.551l7.314,9.086h4.54L-3206,3461.698 M-3220.399,3444.499 c0-1.387,0.337-1.476,2.186-1.476c2.774,0,5.3,0.974,5.3,4.308c0,3.6-2.887,4.63-5.914,4.631h-1.569v-7.463H-3220.399z"></path></svg></span></a><div class="panel-s u-bg-white u-padding-s-hor-from-md u-padding-xs-ver text-xs u-clear-both-from-xs u-clear-none-from-md"><ul class="u-margin-xs-bottom" style="list-style:none"><li class="u-display-inline"><a class="anchor u-margin-xs-right u-margin-s-right-from-sm u-margin-l-right-from-md anchor-has-inherit-color" href="https://www.elsevier.com/solutions/sciencedirect" id="els-footer-about-science-direct" target="_blank" rel="nofollow" style="white-space:nowrap"><span class="anchor-text">About ScienceDirect</span></a><wbr /></li><li class="u-display-inline"><a class="anchor u-margin-xs-right u-margin-s-right-from-sm u-margin-l-right-from-md anchor-has-inherit-color" href="/customer/authenticate/manra" id="els-footer-remote-access" target="_blank" rel="nofollow" style="white-space:nowrap"><span class="anchor-text">Remote access</span></a><wbr /></li><li class="u-display-inline"><a class="anchor u-margin-xs-right u-margin-s-right-from-sm u-margin-l-right-from-md anchor-has-inherit-color" href="https://sd-cart.elsevier.com/?" id="els-footer-shopping-cart" target="_blank" rel="nofollow" style="white-space:nowrap"><span class="anchor-text">Shopping cart</span></a></li><li class="u-display-inline"><a class="anchor u-margin-xs-right u-margin-s-right-from-sm u-margin-l-right-from-md anchor-has-inherit-color" href="http://elsmediakits.com" id="els-footer-advertise" target="_blank" rel="nofollow" style="white-space:nowrap"><span class="anchor-text">Advertise</span></a><wbr /></li><li class="u-display-inline"><a class="anchor u-margin-xs-right u-margin-s-right-from-sm u-margin-l-right-from-md anchor-has-inherit-color" href="https://service.elsevier.com/app/contact/supporthub/sciencedirect/" id="els-footer-contact-support" target="_blank" rel="nofollow" style="white-space:nowrap"><span class="anchor-text">Contact and support</span></a><wbr /></li><li class="u-display-inline"><a class="anchor u-margin-xs-right u-margin-s-right-from-sm u-margin-l-right-from-md anchor-has-inherit-color" href="https://www.elsevier.com/legal/elsevier-website-terms-and-conditions" id="els-footer-terms-condition" target="_blank" rel="nofollow" style="white-space:nowrap"><span class="anchor-text">Terms and conditions</span></a><wbr /></li><li class="u-display-inline"><a class="anchor u-margin-xs-right u-margin-s-right-from-sm u-margin-l-right-from-md anchor-has-inherit-color" href="https://www.elsevier.com/legal/privacy-policy" id="els-footer-privacy-policy" target="_blank" rel="nofollow" style="white-space:nowrap"><span class="anchor-text">Privacy policy</span></a></li></ul><p id="els-footer-cookie-message">We use cookies to help provide and enhance our service and tailor content and ads. By continuing you agree to the <a class="anchor u-margin-0-right" href="https://www.sciencedirect.com/legal/use-of-cookies" target="_blank" rel="nofollow" style="white-space:nowrap"><span class="anchor-text">use of cookies</span></a>.</p><p id="els-footer-copyright">Copyright © 2019 Elsevier B.V. or its licensors or contributors. ScienceDirect ® is a registered trademark of Elsevier B.V.</p></div><a class="anchor u-padding-l-bottom u-padding-s-hor u-position-relative move-bottom u-float-left-from-xs u-float-right-from-md move-right u-padding-0-hor u-margin-top-xs els-footer-relx" href="https://www.relx.com/" aria-label="RELX home page (opens in a new tab)" id="els-footer-relx-group" target="_blank" rel="nofollow" style="white-space:nowrap"><span class="anchor-text"><svg xmlns="http://www.w3.org/2000/svg" width="78" height="30" version="1" viewBox="0 0 280 65" alt="RELX group home page"><g transform="matrix(.13333 0 0 -.13333 0 65)"><path fill="#f4741e" d="M207 251c110 0 242 26 242 131 0 75-77 103-146 103C196 485 0 425 0 215 0 110 80 49 208 49c135 0 232 87 262 205C391 118 291 75 209 75 107 75 68 151 68 216c0 185 144 248 235 248 61 0 97-40 97-83 0-119-172-116-250-116h-38l-16-17c36-5 85-15 139-42C347 149 453 0 592 0c51 0 64 15 74 29-69-44-183 32-245 90-51 48-96 103-214 132"></path><path fill="#666666" d="M886 310c0 33-22 53-55 53h-77c-2 0-3-1-3-3v-99c0-2 1-3 3-3h77c33 0 55 20 55 52m7-261c-5 0-7 2-8 6l-69 145h-62c-2 0-3-1-3-4V55c0-4-2-6-6-6h-51c-4 0-6 2-6 6v361c0 3 2 5 6 5h139c66 0 115-45 115-111 0-49-27-86-69-102l76-152c2-4 0-7-4-7h-58M1010 416c0 3 3 5 6 5h218c4 0 6-2 6-5v-47c0-3-2-6-6-6h-158c-2 0-3-1-3-3v-91c0-2 1-3 3-3h127c4 0 6-2 6-6v-47c0-3-2-5-6-5h-127c-2 0-3-1-3-3v-95c0-2 1-3 3-3h158c4 0 6-2 6-5V55c0-4-2-6-6-6h-218c-3 0-6 2-6 6v361M1298 416c0 3 2 5 5 5h52c3 0 6-2 6-5V110c0-2 1-3 3-3h147c3 0 5-2 5-5V55c0-4-2-6-5-6h-208c-3 0-5 2-5 6v361M1775 49c-4 0-6 1-8 5l-73 127h-1l-73-127c-2-4-4-5-8-5h-58c-3 0-5 3-3 7l108 185-100 173c-2 4 0 7 3 7h58c4 0 6-2 8-6l65-112h1l65 112c2 4 5 6 9 6h57c4 0 5-3 3-7l-99-173 107-185c2-4 1-7-3-7h-58M1912 295l-2 1v104l-1 1h-32l-2 2v16l2 2h87l2-2v-16l-2-2h-32l-1-1V296l-2-1h-17M1988 419l2 2h16c1 0 2 0 3-2l33-78h1l33 78c1 2 2 2 3 2h16l2-2V296l-2-1h-16l-1 1v78h-1l-26-60-3-2h-11l-3 2-26 60h-1v-78l-2-1h-15l-2 1v123"></path></g></svg></span></a></div></div><script id="store-json" type="2975f070f66ff17199d53d68-text/javascript">
                          var reduxData = {"config":{"useHtml2Pdf":true,"topicSlug":"principle-of-optimality","domainSlug":"engineering","topicIndexPageUrl":"","cdnAssetsHost":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com","assetsBaseUrl":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/726ce6de1d3d8212198e38c30b5dd31f20fa8fff","cachebusterQueryParam":"?_","baseEndpoint":"","authData":{"session":{"ssoKey":"7c98e9c526381049c458fa7834d79974ba70gxrqb|$|A5FB1768002D988C9F939D326C0BDAA6CAA9FF40A5839502456C71AFA8A66BC672520B6485C73D00AD12E67EE8FF9CD90090ADC0B89A33C10E9169905BBD791CAFE9C31A29ED2080B6DA1F7CB1786ABB","sdSessionId":"7c98e9c526381049c458fa7834d79974ba70gxrqb","usageInfo":"(870092,U|67027,D|46800,A|4,S|34,P|2,PL)(SDFE,CON|7c98e9c526381049c458fa7834d79974ba70gxrqb,SSO|ANON_IP,ACCESS_TYPE)","extraInfo":{"accessType":"IPRANGE","csasAssocType":"ONLINE_REGISTERED","customer":true,"userAnonymity":"ANON_IP"},"miamiSessionId":"e8b31718-1694-4376-ba4a-f9186507ce0a"},"hasMultipleOrganizations":false,"organization":{"department":"Library+Shibboleth","departmentId":"67027","account":"Sorbonne University Pierre and Marie Curie Campus","accountNumber":"C000046800","accountId":"46800","superAccounts":[{"id":"4","number":"S000000004","name":"COUPERIN Consortium"}],"libraryBanner":{"libraryBannerUrl":"http://www.jubil.upmc.fr/","libraryBannerImageUrl":"www.jubil.upmc.fr/modules/resources/download/bupmc/docs-bu/logos/logo-bupmc-vert-2.jpg","position":"RIGHT"}},"user":{"webUserId":"870092","type":"NORMAL","upc":"C99","settings":{"canActivatePersonalization":true,"canManageTopicAlerts":false,"canLinkToMendeley":false,"canViewPurchaseHistory":true,"canAccessRemotely":true,"canPurchase":false,"forceAbstractView":false,"blockFreeAbstracts":false,"canBypassConfirmScreen":false,"requireCostCode":false,"creditCardPurchaseAllowed":true,"preventTransactionalAccess":false,"preventDocumentDelivery":true,"blockFullTextForAnonymousAccess":false,"crawlerAvailable":false,"allowAnonTransaction":false,"disableWholeIssueDownload":false,"allowRestrictedHtml":false,"blockGateway":false}},"accessType":"IPRANGE","utt":"dd2-f59e27fac615a9ba391b9a185f9a6da4c66-9","idAbValue":"B:100:3","cookies":["has_multiple_organizations=false;Version=1;Domain=.sciencedirect.com;Path=/","MIAMISESSION=e8b31718-1694-4376-ba4a-f9186507ce0a:3743766372;Version=1;Domain=.sciencedirect.com;Path=/;HttpOnly","id_ab=B:100:3;Version=1;Domain=.sciencedirect.com;Path=/;Expires=Sat, 20 Aug 2039 15:06:12 GMT"],"isFallbackUser":false},"environment":"prod","enableGlobalHeader":true,"enableGlobalHeaderSearch":true,"cdnBaseUrl":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com","supportHubId":25793,"requestPath":"/topics/engineering/principle-of-optimality","arsCDN":"https://ars.els-cdn.com","enableAnnotations":true,"enableAnnotationsForIE11Users":true,"enableEntitlementChecks":false,"enablePdfDownload":true,"searchAlerts":{"enableDailyAlerts":false},"hasProtocolsPlusPage":false,"isProtocolsPlusParticipant":false},"topic":{"name":"Principle of Optimality","definition":null,"snippets":[{"body":{"#name":"section","$":{"view":"all","id":"cesec134","xmlns:ce":""},"$$":[{"#name":"section","$":{"view":"all","id":"cesec135"},"$$":[{"#name":"section-title","$":{"id":"cesectitle111"},"_":"Claim 22.1. (Bellman's principle (BP) of optimality) “Any tail of an optimal trajectory is optimal too.”"},{"#name":"para","$":{"view":"all","id":"para591"},"$$":[{"#name":"cross-ref","$":{"refid":"fn2"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"2"}]},{"#name":"footnote","$":{"id":"fn2"},"$$":[{"#name":"label","_":"2"},{"#name":"note-para","$":{"view":"all","id":"cenotep2"},"$$":[{"#name":"__text__","_":"Bellman's principle of optimality, formulated in "},{"#name":"intra-ref","$":{"id":"intraref290","xmlns:xlink":"","href":"pii:B978-0-08-044674-5.50027-4#bib11","type":"simple"},"_":"Bellman (1960)"},{"#name":"__text__","_":", is as follows: “An optimal policy has the property that whatever the initial state and the initial decisions it must constitute an optimal policy with regards to the state resulting from the first decision.”"}]}]}]},{"#name":"para","$":{"view":"all","id":"para592"},"$$":[{"#name":"__text__","_":"In other words, if some trajectory in the phase space connects the initial "},{"#name":"math","$":{"overflow":"scroll","altimg":"si686.gif","xmlns:mml":""},"$$":[{"#name":"mi","_":"x"},{"#name":"mrow","$$":[{"#name":"mo","_":"("},{"#name":"mn","_":"0"},{"#name":"mo","_":")"}]}]},{"#name":"__text__","_":" and terminal "},{"#name":"math","$":{"overflow":"scroll","altimg":"si687.gif"},"$$":[{"#name":"mi","_":"x"},{"#name":"mrow","$$":[{"#name":"mo","_":"("},{"#name":"mi","_":"T"},{"#name":"mo","_":")"}]}]},{"#name":"__text__","_":" points and is optimal in the sense of some cost functional, then the sub-trajectory, connecting any intermediate point "},{"#name":"math","$":{"overflow":"scroll","altimg":"si688.gif"},"$$":[{"#name":"mi","_":"x"},{"#name":"mrow","$$":[{"#name":"mo","_":"("},{"#name":"mrow","$$":[{"#name":"msup","$$":[{"#name":"mi","_":"t"},{"#name":"mo","_":"'"}]}]},{"#name":"mo","_":")"}]}]},{"#name":"__text__","_":" of the same trajectory with the same terminal point "},{"#name":"math","$":{"overflow":"scroll","altimg":"si689.gif"},"$$":[{"#name":"mi","_":"x"},{"#name":"mrow","$$":[{"#name":"mo","_":"("},{"#name":"mi","_":"T"},{"#name":"mo","_":")"}]}]},{"#name":"__text__","_":", should also be optimal (see "},{"#name":"cross-ref","$":{"refid":"f2"},"_":"Fig. 22.2"},{"#name":"float-anchor","$":{"refid":"f2"}},{"#name":"__text__","_":")."}]}]}]},"pii":"B9780080446745500250","isbn":"9780080446745","issn":null,"version":"S300.3","contentType":"BK","cid":"277140","title":"Variational Calculus and Optimal Control","displayName":"Advanced Mathematical Tools for Automatic Control Engineers: Deterministic Techniques, Volume 1","coverDateYear":"2008","authors":{"#name":"rootwrapper","$":{"xmlns:ce":""},"$$":[{"#name":"author-group","$":{"xfab-added":"true"},"$$":[{"#name":"author","$":{"id":"au1"},"$$":[{"#name":"given-name","_":"Alexander S."},{"#name":"surname","_":"Poznyak"}]}]}]},"floats":[{"#name":"figure","$":{"id":"f2"},"$$":[{"#name":"label","_":"Fig. 22.2"},{"#name":"caption","$":{"id":"cecap2"},"$$":[{"#name":"simple-para","$":{"view":"all","id":"spara2"},"_":"Illustration of Bellman's principle of optimality."}]},{"#name":"link","$":{"id":"celink2","locator":"f22-02-9780080446745"}}]}],"attachments":[{"attachment-eid":"3-s2.0-B9780080446745500250-f22-02-9780080446745.gif","file-basename":"f22-02-9780080446745","filename":"f22-02-9780080446745.gif","pixel-height":"255","attachment-type":"IMAGE-DOWNSAMPLED"},{"attachment-eid":"3-s2.0-B9780080446745500250-f22-02-9780080446745.sml","file-basename":"f22-02-9780080446745","filename":"f22-02-9780080446745.sml","pixel-height":"164","attachment-type":"IMAGE-THUMBNAIL"}],"snippetMetadata":{"identifier":"B9780080446745500250","xpath":"//ce:section[@id='cesec134']","version":"S300.3"}},{"body":{"#name":"section","$":{"view":"all","id":"s0010","xmlns:ce":""},"$$":[{"#name":"label","_":"4.1"},{"#name":"section-title","$":{"id":"st0010"},"$$":[{"#name":"anchor","$":{"id":"p55"}},{"#name":"__text__","_":"The principles of dynamic programming"}]},{"#name":"para","$":{"view":"all","id":"p0010"},"$$":[{"#name":"__text__","_":"Dynamic programming is an optimization method based on the principle of optimality defined by Bellman"},{"#name":"cross-ref","$":{"id":"cf0010","refid":"fn0010"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"1"}]},{"#name":"footnote","$":{"id":"fn0010"},"$$":[{"#name":"label","_":"1"},{"#name":"note-para","$":{"view":"all","id":"np0010"},"_":"Richard Bellman, 1920–1984 was an American mathematician. He is considered to be the inventor of dynamic programming."}]},{"#name":"__text__","_":" in the 1950s: “"},{"#name":"italic","_":"An optimal policy has the property that whatever the initial state and initial decision are, the remaining decisions must constitute an optimal policy with regard to the state resulting from the first decision"},{"#name":"__text__","_":"."},{"#name":"italic","_":"”"}]},{"#name":"para","$":{"view":"all","id":"p0015"},"$$":[{"#name":"italic","_":"It can be summarized simply as follows: “every optimal policy consists only of optimal sub policies.”"}]},{"#name":"para","$":{"view":"all","id":"p0020"},"_":"It is a very powerful technique, but its application framework is limited. Nevertheless, numerous variants exist to best meet the different problems encountered."},{"#name":"para","$":{"view":"all","id":"p0025"},"$$":[{"#name":"__text__","_":"This method is a variant of the “divide and conquer” method given that a solution to a problem depends on the previous solutions obtained from subproblems. The main and major difference between these two methods relates to the superimposition of subproblems in dynamic programming. A subproblem can be used to solve a number of different subproblems. In the “divide and conquer” approach, subproblems are entirely independent and can be solved separately. Moreover, recursion is used, unlike in dynamic "},{"#name":"anchor","$":{"id":"p56"}},{"#name":"__text__","_":"programming where a combination of small subproblems is used to obtain increasingly larger subproblems."}]},{"#name":"para","$":{"view":"all","id":"p0030"},"_":"To sum up, it can be said that the “divide and conquer” method works by following a top-down approach whereas dynamic programming follows a bottom-up approach."},{"#name":"para","$":{"view":"all","id":"p0035"},"$$":[{"#name":"__text__","_":"How these two methods function can be illustrated and compared in two arborescent graphs."},{"#name":"display","$$":[{"#name":"figure","$":{"id":"f0025"},"$$":[{"#name":"label","_":"Figure 4.1"},{"#name":"caption","$":{"id":"ca0030"},"$$":[{"#name":"simple-para","$":{"view":"all","id":"sp0030"},"_":"The methods: dynamic programming (left) and divide and conquer (right)"}]},{"#name":"link","$":{"id":"lk0025","locator":"u04-01-9781785480492"}}]}]}]},{"#name":"para","$":{"view":"all","id":"p0040"},"_":"Problems concerning manufacturing management and regulation, stock management, investment strategy, macro planning, training, game theory, computer theory, systems control and so on result in decision-making that is regular and based on sequential processes which are perfectly in line with dynamic programming techniques."}]},"pii":"B9781785480492500049","isbn":"9781785480492","issn":null,"version":"S300.1","contentType":"BK","cid":"313499","title":"Dynamic Programming","displayName":"Optimization Tools for Logistics","coverDateYear":"2015","authors":{"#name":"rootwrapper","$":{"xmlns:ce":""},"$$":[{"#name":"author-group","$":{"xfab-added":"true"},"$$":[{"#name":"author","$":{"id":"au0010"},"$$":[{"#name":"given-name","_":"Jean-Michel"},{"#name":"surname","_":"Réveillac"}]}]}]},"floats":[],"attachments":[{"attachment-eid":"3-s2.0-B9781785480492500049-u04-01-9781785480492.jpg","file-basename":"u04-01-9781785480492","filename":"u04-01-9781785480492.jpg","pixel-height":"145","attachment-type":"IMAGE-DOWNSAMPLED"},{"attachment-eid":"3-s2.0-B9781785480492500049-u04-01-9781785480492.sml","file-basename":"u04-01-9781785480492","filename":"u04-01-9781785480492.sml","pixel-height":"66","attachment-type":"IMAGE-THUMBNAIL"}],"snippetMetadata":{"identifier":"B9781785480492500049","xpath":"//ce:section[@id='s0010']","version":"S300.1"}},{"body":{"#name":"section","$":{"view":"all","id":"s0025","xmlns:ce":""},"$$":[{"#name":"label","_":"4"},{"#name":"section-title","$":{"id":"st0035"},"_":"Iterative Dynamic Programming Algorithm"},{"#name":"para","$":{"view":"all","id":"p0060"},"$$":[{"#name":"__text__","_":"IDPA is a dynamic optimization numerical tool developed by "},{"#name":"cross-ref","$":{"id":"cr0090","refid":"bb0060"},"_":"Luus (1990)"},{"#name":"__text__","_":" and it is based on the principle of optimality of Bellman and Hamilton-Jacobi-Bellman formulation (HJB) ["},{"#name":"cross-ref","$":{"id":"cr0095","refid":"bb0010"},"_":"Bellman, 1957"},{"#name":"__text__","_":"]. In this formulation, the objective function "},{"#name":"italic","_":"J"},{"#name":"__text__","_":" of "},{"#name":"cross-refs","$":{"id":"crs0045","refid":"fo0025 fo0030 fo0035"},"_":"Equations 4-6"},{"#name":"__text__","_":" becomes the partial differential equation:"},{"#name":"display","$$":[{"#name":"formula","$":{"id":"fo0040"},"$$":[{"#name":"label","_":"(7)"},{"#name":"math","$":{"overflow":"scroll","altimg":"si7.gif","xmlns:mml":""},"$$":[{"#name":"mrow","$$":[{"#name":"mfrac","$$":[{"#name":"mrow","$$":[{"#name":"mo","_":"∂"},{"#name":"mi","_":"V"},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"true"},"_":"("},{"#name":"mrow","$$":[{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"x"}]},{"#name":"mo","_":","},{"#name":"mi","_":"t"}]},{"#name":"mo","$":{"stretchy":"true"},"_":")"}]}]},{"#name":"mrow","$$":[{"#name":"mo","_":"∂"},{"#name":"mi","_":"t"}]}]},{"#name":"mo","_":"+"},{"#name":"mtext","_":"min"},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"true"},"_":"("},{"#name":"mrow","$$":[{"#name":"mfrac","$$":[{"#name":"mrow","$$":[{"#name":"mo","_":"∂"},{"#name":"mi","_":"V"},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"true"},"_":"("},{"#name":"mrow","$$":[{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"x"}]},{"#name":"mo","_":","},{"#name":"mi","_":"t"}]},{"#name":"mo","$":{"stretchy":"true"},"_":")"}]}]},{"#name":"mrow","$$":[{"#name":"mo","_":"∂"},{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"x"}]}]}]},{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"F"}]},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"true"},"_":"("},{"#name":"mrow","$$":[{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"x"}]},{"#name":"mo","_":","},{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"u"}]}]},{"#name":"mo","$":{"stretchy":"true"},"_":")"}]},{"#name":"mo","_":"+"},{"#name":"msup","$$":[{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"μ"}]},{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"T"}]}]},{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"S"}]},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"true"},"_":"("},{"#name":"mrow","$$":[{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"x"}]},{"#name":"mo","_":","},{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"u"}]}]},{"#name":"mo","$":{"stretchy":"true"},"_":")"}]}]},{"#name":"mo","$":{"stretchy":"true"},"_":")"}]},{"#name":"mo","_":"="},{"#name":"mn","_":"0"}]}]}]}]}]},{"#name":"para","$":{"view":"all","id":"p0065"},"$$":[{"#name":"__text__","_":"With boundary conditions:"},{"#name":"display","$$":[{"#name":"formula","$":{"id":"fo0045"},"$$":[{"#name":"label","_":"(8)"},{"#name":"math","$":{"overflow":"scroll","altimg":"si8.gif"},"$$":[{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mrow","$$":[{"#name":"mrow","$$":[{"#name":"mfrac","$$":[{"#name":"mrow","$$":[{"#name":"mo","_":"∂"},{"#name":"mi","_":"V"},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"true"},"_":"("},{"#name":"mrow","$$":[{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"x"}]},{"#name":"mo","_":","},{"#name":"mi","_":"t"}]},{"#name":"mo","$":{"stretchy":"true"},"_":")"}]}]},{"#name":"mrow","$$":[{"#name":"mo","_":"∂"},{"#name":"mi","_":"t"}]}]}]},{"#name":"mo","$":{"stretchy":"true"},"_":"|"}]}]},{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mi","_":"t"},{"#name":"mi","_":"f"}]}]}]},{"#name":"mo","_":"="},{"#name":"mn","_":"0"}]}]}]}]},{"#name":"display","$$":[{"#name":"formula","$":{"id":"fo0050"},"$$":[{"#name":"label","_":"(9)"},{"#name":"math","$":{"overflow":"scroll","altimg":"si9.gif"},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"V"},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"true"},"_":"("},{"#name":"mrow","$$":[{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"x"}]},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"true"},"_":"("},{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mi","_":"t"},{"#name":"mi","_":"f"}]}]},{"#name":"mo","$":{"stretchy":"true"},"_":")"}]},{"#name":"mo","_":","},{"#name":"msub","$$":[{"#name":"mi","_":"t"},{"#name":"mi","_":"f"}]}]},{"#name":"mo","$":{"stretchy":"true"},"_":")"}]},{"#name":"mo","_":"="},{"#name":"mi","_":"φ"},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"true"},"_":"("},{"#name":"mrow","$$":[{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"x"}]},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"true"},"_":"("},{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mi","_":"t"},{"#name":"mi","_":"f"}]}]},{"#name":"mo","$":{"stretchy":"true"},"_":")"}]}]},{"#name":"mo","$":{"stretchy":"true"},"_":")"}]},{"#name":"mo","_":"+"},{"#name":"msup","$$":[{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"v"}]},{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"T"}]}]},{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"T"}]},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"true"},"_":"("},{"#name":"mrow","$$":[{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"x"}]},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"true"},"_":"("},{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mi","_":"t"},{"#name":"mi","_":"f"}]}]},{"#name":"mo","$":{"stretchy":"true"},"_":")"}]}]},{"#name":"mo","$":{"stretchy":"true"},"_":")"}]}]}]}]}]}]},{"#name":"para","$":{"view":"all","id":"p0070"},"$$":[{"#name":"__text__","_":"Where "},{"#name":"italic","_":"V"},{"#name":"__text__","_":" ("},{"#name":"bold","_":"x"},{"#name":"__text__","_":","},{"#name":"italic","_":"t"},{"#name":"__text__","_":") is called back function, and represents a minimal cost if the system is in state "},{"#name":"bold","_":"x"},{"#name":"__text__","_":" at time "},{"#name":"italic","_":"t"},{"#name":"__text__","_":" ≤ "},{"#name":"italic","$$":[{"#name":"__text__","_":"t"},{"#name":"inf","$":{"loc":"post"},"_":"f"}]},{"#name":"__text__","_":". The "},{"#name":"cross-ref","$":{"id":"cr0100","refid":"fo0050"},"_":"Equation 9"},{"#name":"__text__","_":" is a transversally condition. IDPA estimates the value of "},{"#name":"italic","_":"V"},{"#name":"__text__","_":" ("},{"#name":"bold","_":"x"},{"#name":"__text__","_":","},{"#name":"italic","_":"t"},{"#name":"__text__","_":") of the "},{"#name":"cross-ref","$":{"id":"cr0105","refid":"fo0040"},"_":"Equation 7"},{"#name":"__text__","_":" with the discretization of the state variables and control variables. The minimization is carried out through an exhaustive search procedure within a feasible region. The time interval ("},{"#name":"italic","$$":[{"#name":"__text__","_":"t"},{"#name":"inf","$":{"loc":"post"},"_":"0"}]},{"#name":"__text__","_":", "},{"#name":"italic","$$":[{"#name":"__text__","_":"t"},{"#name":"inf","$":{"loc":"post"},"_":"f"}]},{"#name":"__text__","_":") is divided into "},{"#name":"italic","_":"P"},{"#name":"__text__","_":" stages where the last one corresponds to the interval ("},{"#name":"italic","$$":[{"#name":"__text__","_":"t"},{"#name":"inf","$":{"loc":"post"},"_":"P-1"}]},{"#name":"__text__","_":", "},{"#name":"italic","$$":[{"#name":"__text__","_":"t"},{"#name":"inf","$":{"loc":"post"},"_":"P"}]},{"#name":"__text__","_":"). Considering the fact that:"},{"#name":"display","$$":[{"#name":"formula","$":{"id":"fo0055"},"$$":[{"#name":"label","_":"(10)"},{"#name":"math","$":{"overflow":"scroll","altimg":"si10.gif"},"$$":[{"#name":"mrow","$$":[{"#name":"mfrac","$$":[{"#name":"mrow","$$":[{"#name":"mo","_":"∂"},{"#name":"mi","_":"V"},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"true"},"_":"("},{"#name":"mrow","$$":[{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"x"}]},{"#name":"mo","_":","},{"#name":"mi","_":"t"}]},{"#name":"mo","$":{"stretchy":"true"},"_":")"}]}]},{"#name":"mrow","$$":[{"#name":"mo","_":"∂"},{"#name":"mi","_":"t"}]}]},{"#name":"mi","_":"Δ"},{"#name":"mi","_":"t"},{"#name":"mo","_":"+"},{"#name":"mfrac","$$":[{"#name":"mrow","$$":[{"#name":"mo","_":"∂"},{"#name":"mi","_":"V"},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"true"},"_":"("},{"#name":"mrow","$$":[{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"x"}]},{"#name":"mo","_":","},{"#name":"mi","_":"t"}]},{"#name":"mo","$":{"stretchy":"true"},"_":")"}]}]},{"#name":"mrow","$$":[{"#name":"mo","_":"∂"},{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"x"}]}]}]},{"#name":"mfrac","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"d"},{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"x"}]}]},{"#name":"mrow","$$":[{"#name":"mi","_":"d"},{"#name":"mi","_":"t"}]}]},{"#name":"mi","_":"Δ"},{"#name":"mi","_":"t"},{"#name":"mo","_":"="},{"#name":"mi","_":"V"},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"true"},"_":"("},{"#name":"mrow","$$":[{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"x"}]},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"true"},"_":"("},{"#name":"mrow","$$":[{"#name":"mi","_":"t"},{"#name":"mo","_":"+"},{"#name":"mi","_":"Δ"},{"#name":"mi","_":"t"}]},{"#name":"mo","$":{"stretchy":"true"},"_":")"}]},{"#name":"mo","_":","},{"#name":"mi","_":"t"},{"#name":"mo","_":"+"},{"#name":"mi","_":"Δ"},{"#name":"mi","_":"t"}]},{"#name":"mo","$":{"stretchy":"true"},"_":")"}]},{"#name":"mo","_":"-"},{"#name":"mi","_":"V"},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"true"},"_":"("},{"#name":"mrow","$$":[{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"x"}]},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"true"},"_":"("},{"#name":"mi","_":"t"},{"#name":"mo","$":{"stretchy":"true"},"_":")"}]},{"#name":"mo","_":","},{"#name":"mi","_":"t"}]},{"#name":"mo","$":{"stretchy":"true"},"_":")"}]}]}]}]}]}]},{"#name":"para","$":{"view":"all","id":"p0075"},"$$":[{"#name":"__text__","_":"The "},{"#name":"cross-ref","$":{"id":"cr0110","refid":"fo0040"},"_":"Equation 7"},{"#name":"__text__","_":" can be integrated over the interval ("},{"#name":"italic","$$":[{"#name":"__text__","_":"t"},{"#name":"inf","$":{"loc":"post"},"_":"P-1"}]},{"#name":"__text__","_":", "},{"#name":"italic","$$":[{"#name":"__text__","_":"t"},{"#name":"inf","$":{"loc":"post"},"_":"P"}]},{"#name":"__text__","_":"). Then the back function at time "},{"#name":"italic","$$":[{"#name":"__text__","_":"t"},{"#name":"inf","$":{"loc":"post"},"_":"P-1"}]},{"#name":"__text__","_":" can be written as:"},{"#name":"display","$$":[{"#name":"formula","$":{"id":"fo0060"},"$$":[{"#name":"label","_":"(11)"},{"#name":"math","$":{"overflow":"scroll","altimg":"si11.gif"},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"V"},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"true"},"_":"("},{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"x"}]},{"#name":"mrow","$$":[{"#name":"mi","_":"P"},{"#name":"mo","_":"-"},{"#name":"mn","_":"1"}]}]},{"#name":"mo","_":","},{"#name":"msub","$$":[{"#name":"mi","_":"t"},{"#name":"mrow","$$":[{"#name":"mi","_":"P"},{"#name":"mo","_":"-"},{"#name":"mn","_":"1"}]}]}]},{"#name":"mo","$":{"stretchy":"true"},"_":")"}]},{"#name":"mo","_":"="},{"#name":"mtext","_":"min"},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"true"},"_":"("},{"#name":"mrow","$$":[{"#name":"mi","_":"V"},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"true"},"_":"("},{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"x"}]},{"#name":"mi","_":"P"}]},{"#name":"mo","_":","},{"#name":"msub","$$":[{"#name":"mi","_":"t"},{"#name":"mi","_":"P"}]}]},{"#name":"mo","$":{"stretchy":"true"},"_":")"}]},{"#name":"mo","_":"+"},{"#name":"mstyle","$":{"displaystyle":"true"},"$$":[{"#name":"mrow","$$":[{"#name":"msubsup","$$":[{"#name":"mo","_":"∫"},{"#name":"mrow","$$":[{"#name":"mi","_":"P"},{"#name":"mo","_":"-"},{"#name":"mn","_":"1"}]},{"#name":"mi","_":"P"}]},{"#name":"mrow","$$":[{"#name":"msup","$$":[{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"μ"}]},{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"T"}]}]},{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"S"}]},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"true"},"_":"("},{"#name":"mrow","$$":[{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"x"}]},{"#name":"mo","_":","},{"#name":"mstyle","$":{"mathvariant":"bold"},"$$":[{"#name":"mi","_":"u"}]}]},{"#name":"mo","$":{"stretchy":"true"},"_":")"}]},{"#name":"mi","_":"d"},{"#name":"mi","_":"t"}]}]}]}]},{"#name":"mo","$":{"stretchy":"true"},"_":")"}]}]}]}]}]}]},{"#name":"para","$":{"view":"all","id":"p0080"},"$$":[{"#name":"__text__","_":"Where "},{"#name":"bold","_":"x"},{"#name":"italic","$$":[{"#name":"inf","$":{"loc":"post"},"_":"P"}]},{"#name":"__text__","_":" is the state "},{"#name":"italic","$$":[{"#name":"__text__","_":"t"},{"#name":"inf","$":{"loc":"post"},"_":"P"}]},{"#name":"__text__","_":" obtained from the integration of the system with control variables "},{"#name":"bold","_":"u"},{"#name":"__text__","_":" and initial conditions "},{"#name":"bold","_":"x"},{"#name":"__text__","_":" ("},{"#name":"italic","$$":[{"#name":"__text__","_":"t"},{"#name":"inf","$":{"loc":"post"},"_":"P-1"}]},{"#name":"__text__","_":") = "},{"#name":"bold","_":"x"},{"#name":"inf","$":{"loc":"post"},"_":"P-1"},{"#name":"__text__","_":" on the interval ("},{"#name":"italic","$$":[{"#name":"__text__","_":"t"},{"#name":"inf","$":{"loc":"post"},"_":"P-1"}]},{"#name":"__text__","_":","},{"#name":"italic","$$":[{"#name":"__text__","_":"t"},{"#name":"inf","$":{"loc":"post"},"_":"P"}]},{"#name":"__text__","_":"). Since the boundary condition "},{"#name":"italic","_":"V"},{"#name":"__text__","_":" is known at final time according to "},{"#name":"cross-ref","$":{"id":"cr0115","refid":"fo0050"},"_":"Equation 9"},{"#name":"__text__","_":", the "},{"#name":"cross-ref","$":{"id":"cr0120","refid":"fo0060"},"_":"Equation 11"},{"#name":"__text__","_":" is solved iteratively for decreasing values of "},{"#name":"italic","_":"P"},{"#name":"__text__","_":". One of the main advantages of IDPA over other methods of dynamic optimization is that it is one of the few tools available to calculate global optima. Also unlike the algorithms of Optimal Control Theory, it does not require complex mathematics ["},{"#name":"cross-ref","$":{"id":"cr0125","refid":"bb0075"},"_":"Srinivasan et al., 2003"},{"#name":"__text__","_":"]. The implementation of this tool is immediately made in the determination of a therapeutic regimen for the improvement of a biological system."}]}]},"pii":"B9780444632340500294","isbn":"9780444632340","issn":"15707946","version":"S300.2","contentType":"BS","cid":"276008","title":"23<ce:sup loc=\"post\">rd</ce:sup> European Symposium on Computer Aided Process Engineering","displayName":"Computer Aided Chemical Engineering","coverDateYear":"2013","authors":{"#name":"rootwrapper","$":{"xmlns:ce":""},"$$":[{"#name":"author-group","$":{"id":"ag0010"},"$$":[{"#name":"author","$":{"id":"au0010"},"$$":[{"#name":"given-name","_":"Carlos E."},{"#name":"surname","_":"Lopez-Landeros"},{"#name":"cross-ref","$":{"id":"cr0010","refid":"af0010"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]}]},{"#name":"author","$":{"id":"au0015"},"$$":[{"#name":"given-name","_":"Nilton J."},{"#name":"surname","_":"Carbajal-Palacios"},{"#name":"cross-ref","$":{"id":"cr0015","refid":"af0010"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]}]},{"#name":"author","$":{"id":"au0020"},"$$":[{"#name":"given-name","_":"Julissa E."},{"#name":"surname","_":"Cosme-Castorena"},{"#name":"cross-ref","$":{"id":"cr0020","refid":"af0010"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]}]},{"#name":"author","$":{"id":"au0025"},"$$":[{"#name":"given-name","_":"Sergio"},{"#name":"surname","_":"Frausto-Hernandez"},{"#name":"cross-ref","$":{"id":"cr0025","refid":"af0015"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]}]},{"#name":"affiliation","$":{"id":"af0010"},"$$":[{"#name":"label","_":"a"},{"#name":"textfn","$":{"id":"tn0010"},"_":"Instituto Tecnológico de Pabellón de Arteaga, Departamento de Ciencias Básicas, Carretera a la Estación de Rincón Km. 1, Pabellón de Arteaga, Ags., 20670, México"}]},{"#name":"affiliation","$":{"id":"af0015"},"$$":[{"#name":"label","_":"b"},{"#name":"textfn","$":{"id":"tn0015"},"_":"Instituto Tecnológico de Aguascalientes, Departamento de Ingeniería Química y Bioquímica, Av. Adolfo López Mateos 1801 ote., Aguascalientes, Ags., 20256, México"}]}]}]},"floats":[],"attachments":[],"snippetMetadata":{"identifier":"B9780444632340500294","xpath":"//ce:section[@id='s0025']","version":"S300.2"}},{"body":{"#name":"section","$":{"view":"all","id":"s0010","xmlns:ce":""},"$$":[{"#name":"label","_":"1"},{"#name":"section-title","$":{"id":"st0020"},"_":"Introduction"},{"#name":"para","$":{"view":"all","id":"p0085"},"$$":[{"#name":"__text__","_":"Dynamic programming (DP) ["},{"#name":"cross-ref","$":{"refid":"bb0010","id":"cf0085"},"_":"1"},{"#name":"__text__","_":"] aims at solving the optimal control problem for dynamic systems using Bellman’s principle of optimality. However, the direct implementation of DP in real-world applications is usually prohibited by the “curse of dimensionality” ["},{"#name":"cross-ref","$":{"refid":"bb0015","id":"cf0090"},"_":"2"},{"#name":"__text__","_":"] and the “curse of modeling” ["},{"#name":"cross-ref","$":{"refid":"bb0020","id":"cf0095"},"_":"3"},{"#name":"__text__","_":"]. One way of solving these two shortcomings is to use approximate DP, which was proposed by Werbos ["},{"#name":"cross-ref","$":{"refid":"bb0025","id":"cf0100"},"_":"4"},{"#name":"__text__","_":", "},{"#name":"cross-ref","$":{"refid":"bb0030","id":"cf0105"},"_":"5"},{"#name":"__text__","_":"] to bring reinforcement learning and DP together to approximate the (generally intractable) solution to Bellman’s equation via online learning. Inspired by Werbos’s original work, numerous approximate DP methods, such as Q-learning ["},{"#name":"cross-ref","$":{"refid":"bb0035","id":"cf0110"},"_":"6"},{"#name":"__text__","_":", "},{"#name":"cross-ref","$":{"refid":"bb0040","id":"cf0115"},"_":"7"},{"#name":"__text__","_":"], temporal-difference learning ["},{"#name":"cross-ref","$":{"refid":"bb0045","id":"cf0120"},"_":"8"},{"#name":"__text__","_":", "},{"#name":"cross-ref","$":{"refid":"bb0050","id":"cf0125"},"_":"9"},{"#name":"__text__","_":"], and actor-critic algorithms ["},{"#name":"cross-refs","$":{"refid":"bb0055 bb0060 bb0065","id":"cf0130"},"_":"10–12"},{"#name":"__text__","_":"], have been widely adopted to solve the optimal control problem for Markov decision processes (MDPs) in the past two decades. Similar ideas have been proposed by Bertsekas and Tsitsiklis under the name of "},{"#name":"italic","_":"neuro-DP"},{"#name":"__text__","_":" ["},{"#name":"cross-ref","$":{"refid":"bb0020","id":"cf0135"},"_":"3"},{"#name":"__text__","_":"]. The interested reader can consult ["},{"#name":"cross-ref","$":{"refid":"bb0020","id":"cf0140"},"_":"3"},{"#name":"__text__","_":", "},{"#name":"cross-ref","$":{"refid":"bb0070","id":"cf0145"},"_":"13"},{"#name":"__text__","_":", "},{"#name":"cross-ref","$":{"refid":"bb0075","id":"cf0150"},"_":"14"},{"#name":"__text__","_":"] for a nice tutorial. Despite their popularity in real-world applications, the above-mentioned methods usually overlooked the stability issue. Moreover, the underlying state and action spaces are assumed to be either finite or countable, which is restrictive for many real-world applications."}]},{"#name":"para","$":{"view":"all","id":"p0090"},"$$":[{"#name":"__text__","_":"Different from the early approximate DP methods, adaptive dynamic programming (ADP) was introduced to find a stabilizing optimal controller for continuous-state space control systems. Over the past decade, ADP-based control design has been extensively studied by several research groups for both continuous-time systems ["},{"#name":"cross-refs","$":{"refid":"bb0080 bb0085 bb0090 bb0095 bb0100 bb0105 bb0110 bb0115 bb0120 bb0125 bb0130 bb0135","id":"cf0155"},"_":"15–26"},{"#name":"__text__","_":"] and discrete-time ["},{"#name":"cross-refs","$":{"refid":"bb0140 bb0145 bb0150 bb0155 bb0160 bb0165","id":"cf0160"},"_":"27–32"},{"#name":"__text__","_":"] systems. See also ["},{"#name":"cross-refs","$":{"refid":"bb0170 bb0175 bb0180","id":"cf0165"},"_":"33–35"},{"#name":"__text__","_":"] for three review papers, and ["},{"#name":"cross-ref","$":{"refid":"bb0185","id":"cf0170"},"_":"36"},{"#name":"__text__","_":"] for a recent book. Unfortunately, most existing ADP methods are devised for deterministic systems. Although preliminary results ["},{"#name":"cross-ref","$":{"refid":"bb0190","id":"cf0175"},"_":"37"},{"#name":"__text__","_":", "},{"#name":"cross-ref","$":{"refid":"bb0195","id":"cf0180"},"_":"38"},{"#name":"__text__","_":"] have been obtained for a class of continuous-time stochastic systems, additive noise is excluded from the model in question. Since the quadratic cost in the classic linear-quadratic regulator problem may become ill-posed because of the presence of the additive noise, we need to consider new types of cost functionals for stochastic optimal control problems in the presence of additive noise. In the first part of this chapter "},{"#name":"cross-refs","$":{"refid":"s0015 s0030 s0035 s0040","id":"cf0185"},"_":"(Sections 2–5)"},{"#name":"__text__","_":" we investigate the optimal control problem for linear stochastic systems subject to both multiplicative noise and additive noise. In "},{"#name":"cross-ref","$":{"refid":"s0015","id":"cf0190"},"_":"Section 2"},{"#name":"__text__","_":", two cost functionals—the discounted cost and the biased cost—are presented. The optimal control problems corresponding to these two types of cost functionals are solved in "},{"#name":"cross-ref","$":{"refid":"s0030","id":"cf0195"},"_":"Sections 3"},{"#name":"__text__","_":" and "},{"#name":"cross-ref","$":{"refid":"s0035","id":"cf0200"},"_":"4"},{"#name":"__text__","_":", respectively, with rigorous convergence and stability analysis provided. In "},{"#name":"cross-ref","$":{"refid":"s0040","id":"cf0205"},"_":"Section 5"},{"#name":"__text__","_":", ADP techniques are developed to design stochastic adaptive optimal controllers through online successive approximations."}]},{"#name":"para","$":{"view":"all","id":"p0095"},"$$":[{"#name":"__text__","_":"In the second part of this chapter ("},{"#name":"cross-ref","$":{"refid":"s0065","id":"cf0210"},"_":"Sections 6"},{"#name":"__text__","_":" and "},{"#name":"cross-ref","$":{"refid":"s0080","id":"cf0215"},"_":"7"},{"#name":"__text__","_":") we further develop a stochastic robust ADP (RADP) method to solve the stochastic robust optimal control problem for continuous-time linear stochastic systems subject to nonlinear dynamic uncertainties. Different from the traditional ADP, RADP can address the presence of dynamic uncertainties caused by the modeling error in linear and nonlinear dynamic systems (see, eg, ["},{"#name":"cross-ref","$":{"refid":"bb0180","id":"cf0220"},"_":"35"},{"#name":"__text__","_":", "},{"#name":"cross-refs","$":{"refid":"bb0200 bb0205 bb0210 bb0215","id":"cf0225"},"_":"39–42"},{"#name":"__text__","_":"], and references therein). By use of the RADP algorithm, precise information on the system dynamics and order is no longer required, and robust optimal control laws are designed directly on the basis of the real-time data. In "},{"#name":"cross-ref","$":{"refid":"s0065","id":"cf0230"},"_":"Section 6"},{"#name":"__text__","_":" we conduct robust optimality and stability analysis for a class of continuous-time partially linear stochastic systems, by employing the stochastic "},{"#name":"math","$":{"overflow":"scroll","altimg":"si1.gif","xmlns:mml":""},"$$":[{"#name":"msup","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"H"}]},{"#name":"mrow","$$":[{"#name":"mi","_":"∞"}]}]}]},{"#name":"__text__","_":" theory ["},{"#name":"cross-ref","$":{"refid":"bb0220","id":"cf0235"},"_":"43"},{"#name":"__text__","_":", "},{"#name":"cross-ref","$":{"refid":"bb0225","id":"cf0240"},"_":"44"},{"#name":"__text__","_":"] and the small-gain theory ["},{"#name":"cross-refs","$":{"refid":"bb0230 bb0235 bb0240","id":"cf0245"},"_":"45–47"},{"#name":"__text__","_":"]. It can be shown that if the input-dependent noise is small enough, then the robust stability of the closed-loop system under the optimal control policy is guaranteed by tuning "},{"#name":"italic","_":"Q"},{"#name":"__text__","_":" and "},{"#name":"italic","_":"R"},{"#name":"__text__","_":" matrices properly. On the basis of the robust optimality results obtained, a stochastic RADP algorithm with convergence and stability analysis is given in "},{"#name":"cross-ref","$":{"refid":"s0080","id":"cf0250"},"_":"Section 7"},{"#name":"__text__","_":"."}]},{"#name":"para","$":{"view":"all","id":"p0100"},"$$":[{"#name":"__text__","_":"To illustrate the results obtained, we present three practical examples from the engineering and computational neuroscience fields in "},{"#name":"cross-ref","$":{"refid":"s0095","id":"cf0255"},"_":"Section 8"},{"#name":"__text__","_":". In the first example the two-joint human arm movement in a divergent force field ["},{"#name":"cross-ref","$":{"refid":"bb0245","id":"cf0260"},"_":"48"},{"#name":"__text__","_":"] is considered, where an undiscounted cost is used. This example shows that our stochastic ADP method appears to be a suitable candidate for a computational learning mechanism in the central nervous system to coordinate movements. Then we apply the stochastic ADP algorithms to solve a vehicle suspension control problem, where stochastic additive noise is involved. Both discount-optimal control and bias-optimal control are derived. Finally, to illustrate the stochastic RADP algorithm, a partially linear single-joint human arm movement model is presented in the third example. These three examples demonstrate that the stochastic ADP method presented in this chapter serves as a powerful tool to solve data-driven, non-model-based robust optimal control problems for stochastic systems."}]},{"#name":"para","$":{"view":"all","id":"p0105"},"$$":[{"#name":"__text__","_":"Throughout this chapter we use "},{"#name":"math","$":{"overflow":"scroll","altimg":"si2.gif"},"$$":[{"#name":"mi","$":{"mathvariant":"double-struck"},"_":"R"}]},{"#name":"__text__","_":" to denote the set of real numbers. "},{"#name":"italic","_":"I"},{"#name":"inf","$":{"loc":"post"},"$$":[{"#name":"italic","_":"n"}]},{"#name":"__text__","_":" denotes the identity matrix of dimension "},{"#name":"italic","_":"n"},{"#name":"__text__","_":". |⋅| denotes the Euclidean norm for vectors, or the induced matrix norm for matrices. For a matrix "},{"#name":"math","$":{"overflow":"scroll","altimg":"si3.gif"},"$$":[{"#name":"mi","_":"A"},{"#name":"mo","_":"∈"},{"#name":"msup","$$":[{"#name":"mrow","$$":[{"#name":"mi","$":{"mathvariant":"double-struck"},"_":"R"}]},{"#name":"mrow","$$":[{"#name":"mi","_":"n"},{"#name":"mo","_":"×"},{"#name":"mi","_":"m"}]}]}]},{"#name":"__text__","_":", "},{"#name":"math","$":{"overflow":"scroll","altimg":"si4.gif"},"$$":[{"#name":"mtext","_":"vec"},{"#name":"mo","$":{"stretchy":"false"},"_":"("},{"#name":"mi","_":"A"},{"#name":"mo","$":{"stretchy":"false"},"_":")"},{"#name":"mo","_":"="},{"#name":"msup","$$":[{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"false"},"_":"["},{"#name":"msubsup","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"a"}]},{"#name":"mrow","$$":[{"#name":"mn","_":"1"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"T"}]}]},{"#name":"mspace","$":{"width":"1em"}},{"#name":"msubsup","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"a"}]},{"#name":"mrow","$$":[{"#name":"mn","_":"2"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"T"}]}]},{"#name":"mspace","$":{"width":"1em"}},{"#name":"mo","_":"⋯"},{"#name":"mspace","$":{"width":"1em"}},{"#name":"msubsup","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"a"}]},{"#name":"mrow","$$":[{"#name":"mi","_":"m"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"T"}]}]},{"#name":"mo","$":{"stretchy":"false"},"_":"]"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"T"}]}]}]},{"#name":"__text__","_":", where "},{"#name":"math","$":{"overflow":"scroll","altimg":"si5.gif"},"$$":[{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"a"}]},{"#name":"mrow","$$":[{"#name":"mi","_":"i"}]}]},{"#name":"mo","_":"∈"},{"#name":"msup","$$":[{"#name":"mrow","$$":[{"#name":"mi","$":{"mathvariant":"double-struck"},"_":"R"}]},{"#name":"mrow","$$":[{"#name":"mi","_":"n"}]}]}]},{"#name":"__text__","_":" is the "},{"#name":"italic","_":"i"},{"#name":"__text__","_":"th column of "},{"#name":"italic","_":"A"},{"#name":"__text__","_":". ⊗ indicates the Kronecker product. We denote by "},{"#name":"math","$":{"overflow":"scroll","altimg":"si6.gif"},"$$":[{"#name":"mo","$":{"stretchy":"false"},"_":"("},{"#name":"mi","_":"Ω"},{"#name":"mo","_":","},{"#name":"mi","$":{"mathvariant":"script"},"_":"F"},{"#name":"mo","_":","},{"#name":"mi","_":"P"},{"#name":"mo","$":{"stretchy":"false"},"_":")"}]},{"#name":"__text__","_":" the underlying probability space ["},{"#name":"cross-ref","$":{"refid":"bb0250","id":"cf0265"},"_":"49"},{"#name":"__text__","_":", Chapter 5.2], where "},{"#name":"italic","_":"Ω"},{"#name":"__text__","_":" is a sample space, "},{"#name":"italic","_":"P"},{"#name":"__text__","_":" is a probability measure, and "},{"#name":"math","$":{"overflow":"scroll","altimg":"si7.gif"},"$$":[{"#name":"mi","$":{"mathvariant":"script"},"_":"F"}]},{"#name":"__text__","_":" is a "},{"#name":"italic","_":"σ"},{"#name":"__text__","_":"-field of Borel sets equipped with a nature filtration "},{"#name":"math","$":{"overflow":"scroll","altimg":"si8.gif"},"$$":[{"#name":"mo","$":{"stretchy":"false"},"_":"{"},{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","$":{"mathvariant":"script"},"_":"F"}]},{"#name":"mrow","$$":[{"#name":"mi","_":"t"}]}]},{"#name":"mo","$":{"stretchy":"false"},"_":"}"}]},{"#name":"__text__","_":", "},{"#name":"math","$":{"overflow":"scroll","altimg":"si9.gif"},"$$":[{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","$":{"mathvariant":"script"},"_":"F"}]},{"#name":"mrow","$$":[{"#name":"mi","_":"s"}]}]},{"#name":"mo","_":"⊆"},{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","$":{"mathvariant":"script"},"_":"F"}]},{"#name":"mrow","$$":[{"#name":"mi","_":"t"}]}]},{"#name":"mo","_":"⊆"},{"#name":"mi","$":{"mathvariant":"script"},"_":"F"}]},{"#name":"__text__","_":" for 0 ≤ "},{"#name":"italic","_":"s"},{"#name":"__text__","_":" ≤ "},{"#name":"italic","_":"t"},{"#name":"__text__","_":". "},{"#name":"math","$":{"overflow":"scroll","altimg":"si10.gif"},"$$":[{"#name":"mi","$":{"mathvariant":"script"},"_":"E"}]},{"#name":"__text__","_":" and "},{"#name":"math","$":{"overflow":"scroll","altimg":"si11.gif"},"$$":[{"#name":"mi","$":{"mathvariant":"script"},"_":"L"}]},{"#name":"__text__","_":" denote the expectation operator and the differential generator, respectively."}]}]},"pii":"B9780128052464000070","isbn":"9780128052464","issn":null,"version":"S300.1","contentType":"BK","cid":"315375","title":"Stochastic Adaptive Dynamic Programming for Robust Optimal Control Design","displayName":"Control of Complex Systems","coverDateYear":"2016","authors":{"#name":"rootwrapper","$":{"xmlns:ce":""},"$$":[{"#name":"author-group","$":{"id":"ag0010"},"$$":[{"#name":"author","$":{"id":"au0010"},"$$":[{"#name":"given-name","_":"T."},{"#name":"surname","_":"Bian"}]},{"#name":"author","$":{"id":"au0015"},"$$":[{"#name":"given-name","_":"Z.-P."},{"#name":"surname","_":"Jiang"}]},{"#name":"affiliation","$":{"id":"af0010"},"$$":[{"#name":"textfn","$":{"id":"tn0010"},"_":"New York University, Brooklyn, NY, United States"},{"#name":"affiliation","$":{"xmlns:sa":"http://www.elsevier.com/xml/common/struct-aff/dtd"},"$$":[{"#name":"organization","_":"New York University"},{"#name":"city","_":"Brooklyn"},{"#name":"state","_":"NY"},{"#name":"country","_":"United States"}]}]}]}]},"floats":[],"attachments":[],"snippetMetadata":{"identifier":"B9780128052464000070","xpath":"//ce:section[@id='s0010']","version":"S300.1"}},{"body":{"#name":"section","$":{"view":"all","id":"cesec11","xmlns:ce":""},"$$":[{"#name":"section-title","$":{"id":"cesectitle11"},"$$":[{"#name":"anchor","$":{"id":"p103"}},{"#name":"__text__","_":"APPLICATION OF DYNAMIC PROGRAMMING"}]},{"#name":"para","$":{"view":"all","id":"para31"},"$$":[{"#name":"__text__","_":"The algorithm outlined in "},{"#name":"cross-ref","$":{"refid":"f1"},"_":"Fig. 8.1"},{"#name":"__text__","_":" involves a multistage optimization procedure where decisions on preferred plant types are taken during each round. A wide class of corresponding problems are handled by means of dynamic programming. This method exploits the principle of optimality; at any state of the optimal policy the sequence of remaing decisions must constitute an optimal policy with regard to the state resulting from the previous decisions. The approach, originally proposed by Bellman, is widely elaborated on in the literature, e.g. by "},{"#name":"intra-ref","$":{"id":"intraref9","xmlns:xlink":"","href":"pii:B978-0-08-027310-5.50016-3#bib17","type":"simple"},"_":"Intriligator (1971)"},{"#name":"__text__","_":"."}]},{"#name":"para","$":{"view":"all","id":"para32"},"_":"The principal reason for abandoning the simple simulation procedure presented in the preceding sections is the fact that long planning horizons and the inclusion of three to four different reactor types lead to long running times on a computer. Using the optimality criterion one is able to delete a number of feasible plant combinations and the algorithm becomes more efficient."},{"#name":"para","$":{"view":"all","id":"para33"},"$$":[{"#name":"__text__","_":"Realizing that dynamic programming is a well established approach it is natural to employ the conventional nomenclature. The problem embodied in "},{"#name":"cross-ref","$":{"refid":"f1"},"_":"Fig. 8.1"},{"#name":"__text__","_":" is transformed to dynamic programming as follows. Deriving the optimal reactor strategy for the planning period is tantamount to splitting the process into stages each of which corresponds to a given time step T, or equivalently, to one cycle in the algorithm of "},{"#name":"cross-ref","$":{"refid":"f1"},"_":"Fig. 8.1"},{"#name":"__text__","_":". At the stage n, i.e. during the nth time interval, one is asked to define the value of a decision variable d"},{"#name":"inf","$":{"loc":"post"},"_":"n"},{"#name":"__text__","_":". The values of the variable d"},{"#name":"inf","$":{"loc":"post"},"_":"n"},{"#name":"__text__","_":" refer to the reactor and fuel cycle strategies available at the stage n. A relevant example might be as follows: d"},{"#name":"inf","$":{"loc":"post"},"_":"1"},{"#name":"__text__","_":" = use LWR, d"},{"#name":"inf","$":{"loc":"post"},"_":"2"},{"#name":"__text__","_":" = initiate reprocessing and LWR recycle, d"},{"#name":"inf","$":{"loc":"post"},"_":"3"},{"#name":"__text__","_":" = bring in FBR."}]},{"#name":"para","$":{"view":"all","id":"para34"},"$$":[{"#name":"__text__","_":"The information on the earlier decisions, i.e. on the current fuel cycle status and material inventories, is contained in a state vector x"},{"#name":"inf","$":{"loc":"post"},"_":"n"},{"#name":"__text__","_":" whose components are stored throughout the computation. The initial state X"},{"#name":"inf","$":{"loc":"post"},"_":"1"},{"#name":"__text__","_":" is known as it contains the description of the power generation system at the beginning of the planning horizon."}]},{"#name":"para","$":{"view":"all","id":"para35"},"$$":[{"#name":"__text__","_":"An arbitrary stage n is described in "},{"#name":"cross-ref","$":{"refid":"f2"},"_":"Fig. 8.2"},{"#name":"float-anchor","$":{"refid":"f2"}},{"#name":"__text__","_":"."}]},{"#name":"para","$":{"view":"all","id":"para36"},"$$":[{"#name":"__text__","_":"The state x"},{"#name":"inf","$":{"loc":"post"},"_":"n"},{"#name":"__text__","_":" is known as it is determined from the initial state X"},{"#name":"inf","$":{"loc":"post"},"_":"1"},{"#name":"__text__","_":" by the decisions d"},{"#name":"inf","$":{"loc":"post"},"_":"1"},{"#name":"__text__","_":",d"},{"#name":"inf","$":{"loc":"post"},"_":"2"},{"#name":"__text__","_":", … d"},{"#name":"inf","$":{"loc":"post"},"_":"n-1"},{"#name":"__text__","_":". The decision d"},{"#name":"inf","$":{"loc":"post"},"_":"n"},{"#name":"__text__","_":" leads to a new system state x"},{"#name":"inf","$":{"loc":"post"},"_":"n+1"},{"#name":"__text__","_":". If a transfer operator T describes the implications of the decision, one may write formally"},{"#name":"display","$$":[{"#name":"formula","$":{"id":"formula10"},"$$":[{"#name":"label","_":"(8.10)"},{"#name":"math","$":{"overflow":"scroll","altimg":"si10.gif","xmlns:mml":""},"$$":[{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mtext","_":"x"},{"#name":"mrow","$$":[{"#name":"mtext","_":"n"},{"#name":"mo","_":"+"},{"#name":"mtext","_":"1"}]}]},{"#name":"mo","_":"="},{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mtext","_":"T(x"}]},{"#name":"mtext","_":"n"}]},{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mtext","_":",d"}]},{"#name":"mtext","_":"n"}]},{"#name":"mtext","_":")"},{"#name":"mtext","_":"."}]}]}]}]}]},{"#name":"para","$":{"view":"all","id":"para37"},"$$":[{"#name":"anchor","$":{"id":"p104"}},{"#name":"__text__","_":"From the standpoint of optimizing the reactor strategy decisions, it is relevant to calculate the revenue requirements R"},{"#name":"inf","$":{"loc":"post"},"_":"n"},{"#name":"__text__","_":" for the plant decided on at the stage n."}]},{"#name":"para","$":{"view":"all","id":"para38"},"$$":[{"#name":"__text__","_":"The total lifetime costs for one plant and the associated fuel cycle operations were discussed in the preceding sections and, in fact, "},{"#name":"cross-ref","$":{"refid":"formula4"},"_":"Eq. (8.4)"},{"#name":"__text__","_":" provides a general formula. The revenue requirement R"},{"#name":"inf","$":{"loc":"post"},"_":"n"},{"#name":"__text__","_":" represents an incremental step in calculating the cumulative revenue requirements of the entire reactor strategy. The expression of R"},{"#name":"inf","$":{"loc":"post"},"_":"n"},{"#name":"__text__","_":" is simply the value of TRR for the particular reactor type chosen by the decision d"},{"#name":"inf","$":{"loc":"post"},"_":"n"},{"#name":"__text__","_":". Discounting the cost TRR(d"},{"#name":"inf","$":{"loc":"post"},"_":"n"},{"#name":"__text__","_":") to the beginning of the planning period one has"},{"#name":"display","$$":[{"#name":"formula","$":{"id":"formula11"},"$$":[{"#name":"label","_":"(8.11)"},{"#name":"math","$":{"overflow":"scroll","altimg":"si11.gif"},"$$":[{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mtext","_":"R"},{"#name":"mtext","_":"n"}]},{"#name":"mo","_":"="},{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mtext","_":"TRR(d"}]},{"#name":"mtext","_":"n"}]},{"#name":"mo","$":{"stretchy":"false"},"_":")"},{"#name":"msup","$$":[{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"false"},"_":"("},{"#name":"mn","_":"1"},{"#name":"mo","_":"+"},{"#name":"mtext","_":"r"},{"#name":"mo","$":{"stretchy":"false"},"_":")"}]},{"#name":"mrow","$$":[{"#name":"mo","_":"−"},{"#name":"msub","$$":[{"#name":"mtext","_":"T"},{"#name":"mtext","_":"n"}]}]}]}]}]}]}]}]},{"#name":"para","$":{"view":"all","id":"para39"},"$$":[{"#name":"__text__","_":"where T"},{"#name":"inf","$":{"loc":"post"},"_":"n"},{"#name":"__text__","_":" denotes the timing of the decision stage n. Clearly, the costs can be referenced to any other date agreed on."}]},{"#name":"para","$":{"view":"all","id":"para40"},"$$":[{"#name":"__text__","_":"The cumulative revenue requirements CRR"},{"#name":"inf","$":{"loc":"post"},"_":"n"},{"#name":"__text__","_":" consist of the discounted cost of all the reactor plants installed by and at the stage n and include the respective fuel cycle and operation costs over the plant lifetimes. Up to the stage n the cost CRR"},{"#name":"inf","$":{"loc":"post"},"_":"n"},{"#name":"__text__","_":" is defined by"},{"#name":"display","$$":[{"#name":"formula","$":{"id":"formula12"},"$$":[{"#name":"label","_":"(8.12)"},{"#name":"math","$":{"overflow":"scroll","altimg":"si12.gif"},"$$":[{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mtext","_":"CRR"}]},{"#name":"mtext","_":"n"}]},{"#name":"mo","_":"="},{"#name":"mstyle","$":{"displaystyle":"true"},"$$":[{"#name":"munderover","$$":[{"#name":"mo","_":"∑"},{"#name":"mrow","$$":[{"#name":"mtext","_":"i"},{"#name":"mo","_":"="},{"#name":"mn","_":"1"}]},{"#name":"mtext","_":"n"}]},{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mtext","_":"R"},{"#name":"mtext","_":"i"}]},{"#name":"mo","$":{"stretchy":"false"},"_":"("},{"#name":"msub","$$":[{"#name":"mtext","_":"x"},{"#name":"mtext","_":"i"}]},{"#name":"mo","_":","},{"#name":"msub","$$":[{"#name":"mtext","_":"d"},{"#name":"mtext","_":"i"}]},{"#name":"mo","$":{"stretchy":"false"},"_":")"}]}]},{"#name":"mo","_":"."}]}]}]}]}]},{"#name":"para","$":{"view":"all","id":"para41"},"$$":[{"#name":"__text__","_":"If there are N+1 stages, then CRR"},{"#name":"inf","$":{"loc":"post"},"_":"N"},{"#name":"__text__","_":" gives the total discounted costs of the reactor strategy. The expression of CRR"},{"#name":"inf","$":{"loc":"post"},"_":"N"},{"#name":"__text__","_":" being separable is an adequate condition for the application of the optimality principle."}]},{"#name":"para","$":{"view":"all","id":"para42"},"$$":[{"#name":"__text__","_":"According to the optimality principle the decision d"},{"#name":"inf","$":{"loc":"post"},"_":"n"},{"#name":"__text__","_":" shall be taken such as to minimize the total revenue requirements from the state x"},{"#name":"inf","$":{"loc":"post"},"_":"n"},{"#name":"__text__","_":" to x"},{"#name":"inf","$":{"loc":"post"},"_":"N"},{"#name":"__text__","_":". Denoting the minimum by MC(x"},{"#name":"inf","$":{"loc":"post"},"_":"n"},{"#name":"__text__","_":") one has the objective function"},{"#name":"display","$$":[{"#name":"formula","$":{"id":"formula13"},"$$":[{"#name":"label","_":"(8.13)"},{"#name":"math","$":{"overflow":"scroll","altimg":"si13.gif"},"$$":[{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mtext","_":"MC(x"}]},{"#name":"mtext","_":"n"}]},{"#name":"mo","$":{"stretchy":"false"},"_":")"},{"#name":"mo","_":"="},{"#name":"mi","_":"min"},{"#name":"mstyle","$":{"displaystyle":"true"},"$$":[{"#name":"munderover","$$":[{"#name":"mo","_":"∑"},{"#name":"mrow","$$":[{"#name":"mtext","_":"i"},{"#name":"mo","_":"="},{"#name":"mtext","_":"n"}]},{"#name":"mtext","_":"N"}]},{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mtext","_":"R"},{"#name":"mtext","_":"i"}]},{"#name":"mo","$":{"stretchy":"false"},"_":"("},{"#name":"msub","$$":[{"#name":"mtext","_":"x"},{"#name":"mtext","_":"i"}]},{"#name":"mo","_":","},{"#name":"msub","$$":[{"#name":"mtext","_":"d"},{"#name":"mtext","_":"i"}]},{"#name":"mo","$":{"stretchy":"false"},"_":")"}]}]}]}]}]}]}]},{"#name":"para","$":{"view":"all","id":"para43"},"$$":[{"#name":"cross-ref","$":{"refid":"formula13"},"_":"Equation (8.13)"},{"#name":"__text__","_":" is now split by separating the term i=n and the expression obtains the form"},{"#name":"display","$$":[{"#name":"formula","$":{"id":"formula14"},"$$":[{"#name":"label","_":"(8.14)"},{"#name":"math","$":{"overflow":"scroll","altimg":"si14.gif"},"$$":[{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mtext","_":"MC(x"}]},{"#name":"mtext","_":"n"}]},{"#name":"mo","$":{"stretchy":"false"},"_":")"},{"#name":"mo","_":"="},{"#name":"munder","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"min"}]},{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mtext","_":"d"},{"#name":"mtext","_":"n"}]}]}]},{"#name":"mo","$":{"stretchy":"false"},"_":"["},{"#name":"msub","$$":[{"#name":"mtext","_":"R"},{"#name":"mtext","_":"n"}]},{"#name":"mo","$":{"stretchy":"false"},"_":"("},{"#name":"msub","$$":[{"#name":"mtext","_":"x"},{"#name":"mtext","_":"n"}]},{"#name":"mo","_":","},{"#name":"msub","$$":[{"#name":"mtext","_":"d"},{"#name":"mtext","_":"n"}]},{"#name":"mo","$":{"stretchy":"false"},"_":")"},{"#name":"mo","_":"+"},{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mtext","_":"MC(T"}]},{"#name":"mtext","_":"n"}]},{"#name":"mo","$":{"stretchy":"false"},"_":"("},{"#name":"msub","$$":[{"#name":"mtext","_":"x"},{"#name":"mtext","_":"n"}]},{"#name":"mo","_":","},{"#name":"msub","$$":[{"#name":"mtext","_":"d"},{"#name":"mtext","_":"n"}]},{"#name":"mo","$":{"stretchy":"false"},"_":")"},{"#name":"mo","$":{"stretchy":"false"},"_":")"},{"#name":"mo","$":{"stretchy":"false"},"_":"]"},{"#name":"mo","_":"."}]}]}]}]}]},{"#name":"para","$":{"view":"all","id":"para44"},"$$":[{"#name":"__text__","_":"Because T(x"},{"#name":"inf","$":{"loc":"post"},"_":"n"},{"#name":"__text__","_":",d"},{"#name":"inf","$":{"loc":"post"},"_":"n"},{"#name":"__text__","_":") refers to the state x"},{"#name":"inf","$":{"loc":"post"},"_":"n+1"},{"#name":"__text__","_":", "},{"#name":"cross-ref","$":{"refid":"formula14"},"_":"Eq. (8.14)"},{"#name":"__text__","_":" constitutes a recursive relation."}]},{"#name":"para","$":{"view":"all","id":"para45"},"$$":[{"#name":"__text__","_":"The calculation of the minimum cost policy is commenced at the final state X"},{"#name":"inf","$":{"loc":"post"},"_":"N+1"},{"#name":"__text__","_":". For n = N in "},{"#name":"cross-ref","$":{"refid":"formula14"},"_":"Eq. (8.14)"},{"#name":"__text__","_":", the second term in the brackets, i.e. MC(X"},{"#name":"inf","$":{"loc":"post"},"_":"N+1"},{"#name":"__text__","_":"), disappears by definition because this stage was arrived at by the decision d"},{"#name":"inf","$":{"loc":"post"},"_":"n"},{"#name":"__text__","_":". Proceeding backwards with n ≤ N, "},{"#name":"cross-ref","$":{"refid":"formula14"},"_":"Eq. (8.14)"},{"#name":"__text__","_":" gives the minimum cost for each stage and fixes the decision on where to go."}]},{"#name":"para","$":{"view":"all","id":"para46"},"$$":[{"#name":"__text__","_":"When the stage n=1 is reached, the optimum policy has been solved for. Comparing "},{"#name":"cross-ref","$":{"refid":"formula12"},"_":"Eqs. (8.12)"},{"#name":"__text__","_":" and "},{"#name":"cross-ref","$":{"refid":"formula13"},"_":"(8.13)"},{"#name":"__text__","_":" it is seen that MC(x"},{"#name":"inf","$":{"loc":"post"},"_":"1"},{"#name":"__text__","_":") gives the minimum value of the cumulative revenue requirements CRR for the strategy."}]},{"#name":"para","$":{"view":"all","id":"para47"},"$$":[{"#name":"anchor","$":{"id":"p105"}},{"#name":"__text__","_":"The basic algorithm outlined above is extended in the following section. An application to a reactor strategy study will be presented there as well."}]}]},"pii":"B9780080273105500138","isbn":"9780080273105","issn":null,"version":"S300.2","contentType":"BK","cid":"289776","title":"Reactor Strategy Calculations","displayName":"Nuclear Fuel Cycle Optimization","coverDateYear":"1982","authors":{"#name":"rootwrapper","$":{"xmlns:ce":""},"$$":[{"#name":"author-group","$":{"xfab-added":"true"},"$$":[{"#name":"author","$":{"id":"au1"},"$$":[{"#name":"given-name","_":"P."},{"#name":"surname","_":"SILVENNOINEN"}]},{"#name":"affiliation","$":{"id":"aff1"},"$$":[{"#name":"textfn","$":{"id":"cetextfn1"},"_":"Technical Research Centre of Finland, Helsinki, Finland"}]}]}]},"floats":[{"#name":"figure","$":{"id":"f2"},"$$":[{"#name":"label","_":"Fig. 8.2"},{"#name":"caption","$":{"id":"cecap2"},"$$":[{"#name":"simple-para","$":{"view":"all","id":"spara2"},"_":"Decision stage n."}]},{"#name":"link","$":{"id":"celink2","locator":"f08-02-9780080273105"}}]}],"attachments":[{"attachment-eid":"3-s2.0-B9780080273105500138-f08-02-9780080273105.gif","file-basename":"f08-02-9780080273105","filename":"f08-02-9780080273105.gif","pixel-height":"138","attachment-type":"IMAGE-DOWNSAMPLED"},{"attachment-eid":"3-s2.0-B9780080273105500138-f08-02-9780080273105.sml","file-basename":"f08-02-9780080273105","filename":"f08-02-9780080273105.sml","pixel-height":"138","attachment-type":"IMAGE-THUMBNAIL"}],"snippetMetadata":{"identifier":"B9780080273105500138","xpath":"//ce:section[@id='cesec11']","version":"S300.2"}},{"body":{"#name":"section","$":{"view":"all","id":"s0065","xmlns:ce":""},"$$":[{"#name":"section-title","$":{"id":"st0075"},"_":"Critic Network"},{"#name":"para","$":{"view":"all","id":"p0155"},"$$":[{"#name":"__text__","_":"From the discussion of the optimization principles of human gait in "},{"#name":"cross-ref","$":{"refid":"s0050","id":"cf0405"},"_":"Section 3.1"},{"#name":"__text__","_":" it can be hypothesized that there is a finite optimizable index which indicates the long-term performance of the prosthetic ankle joint in tracking of the desired gait-based trajectory. According to Bellman’s principle of optimality, such a long-term performance index is expressed as the weighted sum of the short-term (instantaneous) cost at the subsequent iterations as follows: "},{"#name":"display","$$":[{"#name":"formula","$":{"id":"fo0040"},"$$":[{"#name":"label","_":"(7)"},{"#name":"math","$":{"overflow":"scroll","altimg":"si22.gif","xmlns:mml":""},"$$":[{"#name":"mtable","$":{"columnalign":"left"},"$$":[{"#name":"mtr","$$":[{"#name":"mtd","$":{"columnalign":"right"},"$$":[{"#name":"mfenced","$":{"close":"|","open":""},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"L"}]}]},{"#name":"msub","$$":[{"#name":"mrow"},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"false"},"_":"["},{"#name":"mi","_":"k"},{"#name":"mo","_":"−"},{"#name":"mn","_":"1"},{"#name":"mo","$":{"stretchy":"false"},"_":"]"}]}]}]},{"#name":"mtd","$":{"columnalign":"left"},"$$":[{"#name":"mo","_":"="},{"#name":"mfenced","$":{"close":"|","open":""},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"S"}]}]},{"#name":"msub","$$":[{"#name":"mrow"},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"false"},"_":"["},{"#name":"mi","_":"k"},{"#name":"mo","$":{"stretchy":"false"},"_":"]"}]}]},{"#name":"mo","_":"+"},{"#name":"mi","_":"α"},{"#name":"mfenced","$":{"close":"|","open":""},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"S"}]}]},{"#name":"msub","$$":[{"#name":"mrow"},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"false"},"_":"["},{"#name":"mi","_":"k"},{"#name":"mo","_":"+"},{"#name":"mn","_":"1"},{"#name":"mo","$":{"stretchy":"false"},"_":"]"}]}]},{"#name":"mo","_":"+"},{"#name":"msup","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"α"}]},{"#name":"mrow","$$":[{"#name":"mn","_":"2"}]}]},{"#name":"mfenced","$":{"close":"|","open":""},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"S"}]}]},{"#name":"msub","$$":[{"#name":"mrow"},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"false"},"_":"["},{"#name":"mi","_":"k"},{"#name":"mo","_":"+"},{"#name":"mn","_":"2"},{"#name":"mo","$":{"stretchy":"false"},"_":"]"}]}]},{"#name":"mo","_":"+"},{"#name":"mo","_":"⋯"}]}]},{"#name":"mtr","$$":[{"#name":"mtd","$":{"columnalign":"right"}},{"#name":"mtd","$":{"columnalign":"left"},"$$":[{"#name":"mo","_":"="},{"#name":"mfenced","$":{"close":"|","open":""},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"S"}]}]},{"#name":"msub","$$":[{"#name":"mrow"},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"false"},"_":"["},{"#name":"mi","_":"k"},{"#name":"mo","$":{"stretchy":"false"},"_":"]"}]}]},{"#name":"mo","_":"+"},{"#name":"mi","_":"α"},{"#name":"mfenced","$":{"close":"|","open":""},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"L"}]}]},{"#name":"msub","$$":[{"#name":"mrow"},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"false"},"_":"["},{"#name":"mi","_":"k"},{"#name":"mo","$":{"stretchy":"false"},"_":"]"}]}]},{"#name":"mo","_":","}]}]}]}]}]}]},{"#name":"__text__","_":"in which "},{"#name":"math","$":{"overflow":"scroll","altimg":"si23.gif"},"$$":[{"#name":"mfenced","$":{"close":"|","open":""},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"L"}]}]},{"#name":"msub","$$":[{"#name":"mrow"},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"false"},"_":"["},{"#name":"mi","_":"k"},{"#name":"mo","_":"−"},{"#name":"mn","_":"1"},{"#name":"mo","$":{"stretchy":"false"},"_":"]"}]}]}]},{"#name":"__text__","_":" is the long-term performance index at iteration "},{"#name":"italic","_":"k"},{"#name":"__text__","_":" − 1, "},{"#name":"math","$":{"overflow":"scroll","altimg":"si24.gif"},"$$":[{"#name":"mi","_":"S"},{"#name":"mfenced","$":{"close":"","open":"|"},"$$":[{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mrow"},{"#name":"mrow","$$":[{"#name":"mo","$":{"stretchy":"false"},"_":"["},{"#name":"mi","_":"k"},{"#name":"mo","$":{"stretchy":"false"},"_":"]"}]}]}]}]}]},{"#name":"__text__","_":" is the instantaneous cost at iteration "},{"#name":"math","$":{"overflow":"scroll","altimg":"si25.gif"},"$$":[{"#name":"mfenced","$":{"close":"]","open":"["},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"k"}]}]}]},{"#name":"__text__","_":", and so on, and 0 &lt; "},{"#name":"italic","_":"α"},{"#name":"__text__","_":" &lt; 1 is the discount factor."}]},{"#name":"para","$":{"view":"all","id":"p0160"},"$$":[{"#name":"__text__","_":"In the DNDP approach, that performance index is approximated by a multilayer neural network (critic network) with ideal weights "},{"#name":"math","$":{"overflow":"scroll","altimg":"si26.gif"},"$$":[{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"W"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]}]},{"#name":"mo","_":"∈"},{"#name":"msup","$$":[{"#name":"mrow","$$":[{"#name":"mi","$":{"mathvariant":"double-struck"},"_":"R"}]},{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"N"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"hC"}]}]},{"#name":"mo","_":"×"},{"#name":"mn","_":"1"}]}]}]},{"#name":"__text__","_":" and "},{"#name":"math","$":{"overflow":"scroll","altimg":"si27.gif"},"$$":[{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"V"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]}]},{"#name":"mo","_":"∈"},{"#name":"msup","$$":[{"#name":"mrow","$$":[{"#name":"mi","$":{"mathvariant":"double-struck"},"_":"R"}]},{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"N"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"xC"}]}]},{"#name":"mo","_":"×"},{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"N"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"hC"}]}]}]}]}]},{"#name":"__text__","_":" as "},{"#name":"display","$$":[{"#name":"formula","$":{"id":"fo0045"},"$$":[{"#name":"label","_":"(8)"},{"#name":"math","$":{"overflow":"scroll","altimg":"si28.gif"},"$$":[{"#name":"mtable","$":{"columnalign":"left"},"$$":[{"#name":"mtr","$$":[{"#name":"mtd","$":{"columnalign":"right"},"$$":[{"#name":"mfenced","$":{"close":"|","open":""},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"L"},{"#name":"mfenced","$":{"close":")","open":"("},"$$":[{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"x"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]}]}]}]}]}]},{"#name":"msub","$$":[{"#name":"mrow"},{"#name":"mrow","$$":[{"#name":"mfenced","$":{"close":"]","open":"["},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"k"}]}]}]}]},{"#name":"mo","_":"="},{"#name":"mfenced","$":{"close":"|","open":""},"$$":[{"#name":"mrow","$$":[{"#name":"mfenced","$":{"close":"]","open":"["},"$$":[{"#name":"mrow","$$":[{"#name":"msubsup","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"W"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"T"}]}]},{"#name":"mi","_":"σ"},{"#name":"mfenced","$":{"close":")","open":"("},"$$":[{"#name":"mrow","$$":[{"#name":"msubsup","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"V"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"T"}]}]},{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"x"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]}]}]}]},{"#name":"mo","_":"+"},{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"ε"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]}]}]}]}]}]},{"#name":"msub","$$":[{"#name":"mrow"},{"#name":"mrow","$$":[{"#name":"mfenced","$":{"close":"]","open":"["},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"k"}]}]}]}]},{"#name":"mo","_":","}]}]}]}]}]}]},{"#name":"__text__","_":"in which "},{"#name":"math","$":{"overflow":"scroll","altimg":"si29.gif"},"$$":[{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"x"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]}]},{"#name":"mo","_":"∈"},{"#name":"msup","$$":[{"#name":"mrow","$$":[{"#name":"mi","$":{"mathvariant":"double-struck"},"_":"R"}]},{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"N"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"xC"}]}]},{"#name":"mo","_":"×"},{"#name":"mn","_":"1"}]}]}]},{"#name":"__text__","_":" is the vector of the neural network inputs, "},{"#name":"italic","_":"ε"},{"#name":"inf","$":{"loc":"post"},"_":"C"},{"#name":"__text__","_":" is the bounded approximation error (ie, "},{"#name":"math","$":{"overflow":"scroll","altimg":"si30.gif"},"$$":[{"#name":"mfenced","$":{"close":"‖","open":"‖"},"$$":[{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"ε"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]}]}]}]},{"#name":"mo","_":"&lt;"},{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"ε"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"BC"}]}]},{"#name":"mo","_":"∈"},{"#name":"mi","$":{"mathvariant":"double-struck"},"_":"R"}]},{"#name":"__text__","_":"), "},{"#name":"math","$":{"overflow":"scroll","altimg":"si31.gif"},"$$":[{"#name":"mi","_":"σ"},{"#name":"mfenced","$":{"close":")","open":"("},"$$":[{"#name":"mrow","$$":[{"#name":"mo","_":"."}]}]}]},{"#name":"__text__","_":" is a sigmoidal activation function, and "},{"#name":"italic","_":"N"},{"#name":"inf","$":{"loc":"post"},"_":"hC"},{"#name":"__text__","_":" is the number of nodes in the hidden layer. For simplifying purposes, the notation of the iteration "},{"#name":"math","$":{"overflow":"scroll","altimg":"si32.gif"},"$$":[{"#name":"mfenced","$":{"close":"|","open":""},"$$":[{"#name":"mrow"}]},{"#name":"msub","$$":[{"#name":"mrow"},{"#name":"mrow","$$":[{"#name":"mfenced","$":{"close":"]","open":"["},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"k"}]}]}]}]}]},{"#name":"__text__","_":" will be presented only when needed. The ideal weights "},{"#name":"italic","_":"W"},{"#name":"inf","$":{"loc":"post"},"_":"C"},{"#name":"__text__","_":" and "},{"#name":"italic","_":"V"},{"#name":"inf","$":{"loc":"post"},"_":"C"},{"#name":"__text__","_":" in Eq. ("},{"#name":"cross-ref","$":{"refid":"fo0045","id":"cf0410"},"_":"8"},{"#name":"__text__","_":") are unknown but they can be approximated by adjustable weights "},{"#name":"math","$":{"overflow":"scroll","altimg":"si33.gif"},"$$":[{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"Ŵ"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]}]},{"#name":"mo","_":"∈"},{"#name":"msup","$$":[{"#name":"mrow","$$":[{"#name":"mi","$":{"mathvariant":"double-struck"},"_":"R"}]},{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"N"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"hC"}]}]},{"#name":"mo","_":"×"},{"#name":"mn","_":"1"}]}]}]},{"#name":"__text__","_":" and "},{"#name":"math","$":{"overflow":"scroll","altimg":"si34.gif"},"$$":[{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mover","$":{"accent":"true"},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"V"}]},{"#name":"mo","_":"^"}]}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]}]},{"#name":"mo","_":"∈"},{"#name":"msup","$$":[{"#name":"mrow","$$":[{"#name":"mi","$":{"mathvariant":"double-struck"},"_":"R"}]},{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"N"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"xC"}]}]},{"#name":"mo","_":"×"},{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"N"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"hC"}]}]}]}]}]},{"#name":"__text__","_":" with the network weight errors "},{"#name":"display","$$":[{"#name":"formula","$":{"id":"fo0050"},"$$":[{"#name":"label","_":"(9)"},{"#name":"math","$":{"overflow":"scroll","altimg":"si35.gif"},"$$":[{"#name":"mtable","$":{"columnalign":"left"},"$$":[{"#name":"mtr","$$":[{"#name":"mtd","$":{"columnalign":"right"},"$$":[{"#name":"mtable","$$":[{"#name":"mtr","$$":[{"#name":"mtd","$$":[{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mover","$":{"accent":"true"},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"W"}]},{"#name":"mo","_":"~"}]}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]}]}]},{"#name":"mtd","$$":[{"#name":"mo","_":"="},{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"W"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]}]},{"#name":"mo","_":"−"},{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"Ŵ"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]}]},{"#name":"mo","_":","}]}]},{"#name":"mtr","$$":[{"#name":"mtd","$$":[{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mover","$":{"accent":"true"},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"V"}]},{"#name":"mo","_":"~"}]}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]}]}]},{"#name":"mtd","$$":[{"#name":"mo","_":"="},{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"V"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]}]},{"#name":"mo","_":"−"},{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mover","$":{"accent":"true"},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"V"}]},{"#name":"mo","_":"^"}]}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]}]},{"#name":"mo","_":"."}]}]},{"#name":"mtr","$$":[{"#name":"mtd"}]}]}]}]}]}]}]}]},{"#name":"__text__","_":"As a result, the critic network will generate "},{"#name":"math","$":{"overflow":"scroll","altimg":"si36.gif"},"$$":[{"#name":"mi","_":"J"},{"#name":"mfenced","$":{"close":")","open":"("},"$$":[{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"x"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]}]}]}]}]},{"#name":"__text__","_":", which is the approximation of the cost function defined in Eq. ("},{"#name":"cross-ref","$":{"refid":"fo0045","id":"cf0415"},"_":"8"},{"#name":"__text__","_":"): "},{"#name":"display","$$":[{"#name":"formula","$":{"id":"fo0055"},"$$":[{"#name":"label","_":"(10)"},{"#name":"math","$":{"overflow":"scroll","altimg":"si37.gif"},"$$":[{"#name":"mtable","$":{"columnalign":"left"},"$$":[{"#name":"mtr","$$":[{"#name":"mtd","$":{"columnalign":"right"},"$$":[{"#name":"mi","_":"J"},{"#name":"mfenced","$":{"close":")","open":"("},"$$":[{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"x"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]}]}]}]},{"#name":"mo","_":"="},{"#name":"msubsup","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"Ŵ"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"T"}]}]},{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mover","$":{"accent":"true"},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"σ"}]},{"#name":"mo","_":"^"}]}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]}]},{"#name":"mfenced","$":{"close":")","open":"("},"$$":[{"#name":"mrow","$$":[{"#name":"msubsup","$$":[{"#name":"mrow","$$":[{"#name":"mover","$":{"accent":"true"},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"V"}]},{"#name":"mo","_":"^"}]}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"T"}]}]},{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"x"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]}]}]}]},{"#name":"mo","_":"="},{"#name":"munderover","$$":[{"#name":"mrow","$$":[{"#name":"mo","_":"∑"}]},{"#name":"mrow","$$":[{"#name":"mi","_":"i"},{"#name":"mo","_":"="},{"#name":"mn","_":"1"}]},{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"N"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"hC"}]}]}]}]},{"#name":"msubsup","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"Ŵ"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"T"}]}]},{"#name":"mfenced","$":{"close":")","open":"("},"$$":[{"#name":"mrow","$$":[{"#name":"mn","_":"1"},{"#name":"mo","_":","},{"#name":"mi","_":"i"}]}]},{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mover","$":{"accent":"true"},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"σ"}]},{"#name":"mo","_":"^"}]}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]}]},{"#name":"mfenced","$":{"close":")","open":"("},"$$":[{"#name":"mrow","$$":[{"#name":"munderover","$$":[{"#name":"mrow","$$":[{"#name":"mo","_":"∑"}]},{"#name":"mrow","$$":[{"#name":"mi","_":"j"},{"#name":"mo","_":"="},{"#name":"mn","_":"1"}]},{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"N"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"xC"}]}]}]}]},{"#name":"msubsup","$$":[{"#name":"mrow","$$":[{"#name":"mover","$":{"accent":"true"},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"V"}]},{"#name":"mo","_":"^"}]}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"T"}]}]},{"#name":"mfenced","$":{"close":")","open":"("},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"i"},{"#name":"mo","_":","},{"#name":"mi","_":"j"}]}]},{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"x"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]}]},{"#name":"mfenced","$":{"close":")","open":"("},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"j"},{"#name":"mo","_":","},{"#name":"mn","_":"1"}]}]}]}]},{"#name":"mo","_":","}]}]}]}]}]}]},{"#name":"__text__","_":"where "},{"#name":"italic","_":"N"},{"#name":"inf","$":{"loc":"post"},"_":"hC"},{"#name":"__text__","_":" is the number of nodes in the hidden layer and "},{"#name":"italic","_":"N"},{"#name":"inf","$":{"loc":"post"},"_":"xC"},{"#name":"__text__","_":" is the number of inputs to the critic network. The backpropagation error of the critic network indicates how closely the approximated long-term cost function "},{"#name":"italic","_":"J"},{"#name":"__text__","_":" follows Bellman’s principle of optimality and is defined as follows: "},{"#name":"display","$$":[{"#name":"formula","$":{"id":"fo0060"},"$$":[{"#name":"label","_":"(11)"},{"#name":"math","$":{"overflow":"scroll","altimg":"si38.gif"},"$$":[{"#name":"mtable","$":{"columnalign":"left"},"$$":[{"#name":"mtr","$$":[{"#name":"mtd","$":{"columnalign":"right"},"$$":[{"#name":"mfenced","$":{"close":"|","open":""},"$$":[{"#name":"mrow","$$":[{"#name":"msub","$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"e"}]},{"#name":"mrow","$$":[{"#name":"mtext","_":"C"}]}]}]}]},{"#name":"msub","$$":[{"#name":"mrow"},{"#name":"mrow","$$":[{"#name":"mfenced","$":{"close":"]","open":"["},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"k"}]}]}]}]},{"#name":"mo","_":"="},{"#name":"munder","$$":[{"#name":"mrow","$$":[{"#name":"munder","$":{"accentunder":"false"},"$$":[{"#name":"mrow","$$":[{"#name":"mfenced","$":{"close":"]","open":"["},"$$":[{"#name":"mrow","$$":[{"#name":"mfenced","$":{"close":"|","open":""},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"J"}]}]},{"#name":"msub","$$":[{"#name":"mrow"},{"#name":"mrow","$$":[{"#name":"mfenced","$":{"close":"]","open":"["},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"k"},{"#name":"mo","_":"−"},{"#name":"mn","_":"1"}]}]}]}]},{"#name":"mo","_":"−"},{"#name":"mfenced","$":{"close":"|","open":""},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"S"}]}]},{"#name":"msub","$$":[{"#name":"mrow"},{"#name":"mrow","$$":[{"#name":"mfenced","$":{"close":"]","open":"["},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"k"}]}]}]}]}]}]}]},{"#name":"mo","_":"︸"}]}]},{"#name":"mrow","$$":[{"#name":"mi","$":{"mathvariant":"normal"},"_":"target"}]}]},{"#name":"mo","_":"−"},{"#name":"munder","$$":[{"#name":"mrow","$$":[{"#name":"munder","$":{"accentunder":"false"},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"α"},{"#name":"mfenced","$":{"close":"|","open":""},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"J"}]}]},{"#name":"msub","$$":[{"#name":"mrow"},{"#name":"mrow","$$":[{"#name":"mfenced","$":{"close":"]","open":"["},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"k"}]}]}]}]},{"#name":"mo","_":"."}]},{"#name":"mo","_":"︸"}]}]},{"#name":"mrow","$$":[{"#name":"mtable","$":{"columnalign":"left"},"$$":[{"#name":"mtr","$$":[{"#name":"mtd","$$":[{"#name":"mstyle","$":{"mathvariant":"normal"},"$$":[{"#name":"mi","_":"current"},{"#name":"mspace","$":{"width":"1em"}},{"#name":"mi","_":"outcome"}]}]}]},{"#name":"mtr","$$":[{"#name":"mtd"}]}]}]}]}]}]}]}]}]}]}]}]},"pii":"B9780128052464000227","isbn":"9780128052464","issn":null,"version":"S300.1","contentType":"BK","cid":"315375","title":"Intelligent Control of a Prosthetic Ankle Joint Using Gait Recognition","displayName":"Control of Complex Systems","coverDateYear":"2016","authors":{"#name":"rootwrapper","$":{"xmlns:ce":""},"$$":[{"#name":"author-group","$":{"id":"ag0010"},"$$":[{"#name":"author","$":{"id":"au0010"},"$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Mai"}]},{"#name":"author","$":{"id":"au0015"},"$$":[{"#name":"given-name","_":"S."},{"#name":"surname","_":"Commuri"}]},{"#name":"affiliation","$":{"id":"af0010"},"$$":[{"#name":"textfn","$":{"id":"tn0010"},"_":"University of Oklahoma, Norman, OK, United States"},{"#name":"affiliation","$":{"xmlns:sa":"http://www.elsevier.com/xml/common/struct-aff/dtd"},"$$":[{"#name":"organization","_":"University of Oklahoma"},{"#name":"city","_":"Norman"},{"#name":"state","_":"OK"},{"#name":"country","_":"United States"}]}]}]}]},"floats":[],"attachments":[],"snippetMetadata":{"identifier":"B9780128052464000227","xpath":"//ce:section[@id='s0065']","version":"S300.1"}},{"body":{"#name":"section","$":{"view":"all","id":"s0150","xmlns:ce":""},"$$":[{"#name":"label","_":"1"},{"#name":"section-title","$":{"id":"st0150"},"_":"MCA Dynamic Programming Model Formulation"},{"#name":"para","$":{"view":"all","id":"p1230"},"$$":[{"#name":"__text__","_":"Consider the stochastic diffusion without Poisson jumps governed by the stochastic differential equation (SDE)"},{"#name":"display","$$":[{"#name":"formula","$":{"id":"fo0565"},"$$":[{"#name":"label","_":"(73)"},{"#name":"math","$":{"overflow":"scroll","altimg":"si167.gif","xmlns:mml":""},"$$":[{"#name":"mi","_":"d"},{"#name":"mi","$":{"mathvariant":"bold"},"_":"X"},{"#name":"mfenced","$":{"close":")","open":"("},"$$":[{"#name":"mi","_":"t"}]},{"#name":"mo","_":"="},{"#name":"mi","$":{"mathvariant":"bold"},"_":"F"},{"#name":"mfenced","$":{"close":")","separators":",,","open":"("},"$$":[{"#name":"mi","$":{"mathvariant":"bold"},"_":"X"},{"#name":"mi","$":{"mathvariant":"bold"},"_":"U"},{"#name":"mi","_":"t"}]},{"#name":"mi","_":"d"},{"#name":"mi","_":"t"},{"#name":"mo","_":"+"},{"#name":"mi","_":"G"},{"#name":"mfenced","$":{"close":")","separators":",","open":"("},"$$":[{"#name":"mi","$":{"mathvariant":"bold"},"_":"X"},{"#name":"mi","_":"t"}]},{"#name":"mi","_":"d"},{"#name":"mi","$":{"mathvariant":"bold"},"_":"W"},{"#name":"mfenced","$":{"close":")","open":"("},"$$":[{"#name":"mi","_":"t"}]},{"#name":"mtext","_":","}]}]}]}]},{"#name":"para","$":{"view":"all","id":"p1235"},"$$":[{"#name":"__text__","_":"where the notation is the same as in "},{"#name":"cross-ref","$":{"refid":"fo0005","id":"cf1325"},"_":"(1)"},{"#name":"__text__","_":". It is assumed that drift "},{"#name":"bold","_":"F"},{"#name":"__text__","_":" and Gaussian coefficient "},{"#name":"italic","_":"G"},{"#name":"__text__","_":" are bounded, continuous and Lipshitz continuous in the state "},{"#name":"bold","_":"X"},{"#name":"__text__","_":", while "},{"#name":"bold","_":"F"},{"#name":"__text__","_":" is uniformly so in the control "},{"#name":"bold","_":"U"},{"#name":"__text__","_":". Further, let the expected cost objective functional be"},{"#name":"display","$$":[{"#name":"formula","$":{"id":"fo0570"},"$$":[{"#name":"label","_":"(74)"},{"#name":"math","$":{"overflow":"scroll","altimg":"si168.gif"},"$$":[{"#name":"mtable","$":{"columnalign":"left"},"$$":[{"#name":"mtr","$":{"columnalign":"left"},"$$":[{"#name":"mtd","$":{"columnalign":"left"},"$$":[{"#name":"mover","$":{"accent":"true"},"$$":[{"#name":"mi","_":"V"},{"#name":"mo","$":{"stretchy":"true"},"_":"¯"}]},{"#name":"mfenced","$":{"close":")","separators":",,","open":"("},"$$":[{"#name":"mi","$":{"mathvariant":"bold"},"_":"x"},{"#name":"mi","$":{"mathvariant":"bold"},"_":"u"},{"#name":"mi","_":"t"}]}]},{"#name":"mtd","$":{"columnalign":"left"},"$$":[{"#name":"mo","_":"="}]},{"#name":"mtd","$":{"columnalign":"left"},"$$":[{"#name":"mi","$":{"mathvariant":"normal"},"_":"Mean"},{"#name":"mfenced","$":{"close":"","open":"["},"$$":[{"#name":"mstyle","$":{"displaystyle":"true"},"$$":[{"#name":"msubsup","$$":[{"#name":"mo","$":{"stretchy":"true"},"_":"∫"},{"#name":"mi","_":"t"},{"#name":"msub","$$":[{"#name":"mi","_":"t"},{"#name":"mi","_":"f"}]}]},{"#name":"mrow","$$":[{"#name":"mi","_":"d"},{"#name":"mi","_":"τ"},{"#name":"mspace","$":{"width":"0.12em"}},{"#name":"mi","_":"C"},{"#name":"mfenced","$":{"close":")","open":"("},"$$":[{"#name":"mrow","$$":[{"#name":"mi","$":{"mathvariant":"bold"},"_":"X"},{"#name":"mfenced","$":{"close":")","open":"("},"$$":[{"#name":"mi","_":"τ"}]},{"#name":"mo","_":","},{"#name":"mi","$":{"mathvariant":"bold"},"_":"U"},{"#name":"mfenced","$":{"close":")","open":"("},"$$":[{"#name":"mrow","$$":[{"#name":"mi","$":{"mathvariant":"bold"},"_":"X"},{"#name":"mfenced","$":{"close":")","open":"("},"$$":[{"#name":"mi","_":"τ"}]},{"#name":"mo","_":","},{"#name":"mi","_":"τ"}]}]},{"#name":"mo","_":","},{"#name":"mi","_":"τ"}]}]}]}]}]}]}]},{"#name":"mtr","$":{"columnalign":"left"},"$$":[{"#name":"mtd","$":{"columnalign":"left"}},{"#name":"mtd","$":{"columnalign":"left"},"$$":[{"#name":"mo","$":{"stretchy":"true"},"_":"|"}]},{"#name":"mtd","$":{"columnalign":"left"},"$$":[{"#name":"mfenced","$":{"close":"]","open":""},"$$":[{"#name":"mrow","$$":[{"#name":"mi","$":{"mathvariant":"bold"},"_":"X"},{"#name":"mfenced","$":{"close":")","open":"("},"$$":[{"#name":"mi","_":"t"}]},{"#name":"mo","_":"="},{"#name":"mi","$":{"mathvariant":"bold"},"_":"x"},{"#name":"mo","_":","},{"#name":"mi","$":{"mathvariant":"bold"},"_":"U"},{"#name":"mo","_":"="},{"#name":"mi","$":{"mathvariant":"bold"},"_":"u"}]}]},{"#name":"mo","_":"+"},{"#name":"mover","$":{"accent":"true"},"$$":[{"#name":"mi","_":"Z"},{"#name":"mo","$":{"stretchy":"true"},"_":"¯"}]},{"#name":"mfenced","$":{"close":")","separators":",","open":"("},"$$":[{"#name":"mi","$":{"mathvariant":"bold"},"_":"x"},{"#name":"msub","$$":[{"#name":"mi","_":"t"},{"#name":"mi","_":"f"}]}]},{"#name":"mtext","_":","}]}]}]}]}]}]}]},{"#name":"para","$":{"view":"all","id":"p1240"},"$$":[{"#name":"__text__","_":"with the same notation as in "},{"#name":"cross-ref","$":{"refid":"fo0010","id":"cf1330"},"_":"(2)"},{"#name":"__text__","_":". It is assumed that the instantaneous cost "},{"#name":"italic","_":"C"},{"#name":"__text__","_":" and the salvage cost "},{"#name":"math","$":{"overflow":"scroll","altimg":"si169.gif"},"$$":[{"#name":"mover","$":{"accent":"true"},"$$":[{"#name":"mi","_":"Z"},{"#name":"mo","$":{"stretchy":"true"},"_":"¯"}]}]},{"#name":"__text__","_":" are bounded and continuous. Much also may depend on the boundary conditions. The final side condition is the same as that in "},{"#name":"cross-ref","$":{"refid":"fo0040","id":"cf1335"},"_":"(8)"},{"#name":"__text__","_":" for SDP."}]},{"#name":"para","$":{"view":"all","id":"p1245"},"$$":[{"#name":"__text__","_":"The optimal costs are defined as"},{"#name":"display","$$":[{"#name":"formula","$":{"id":"fo0575"},"$$":[{"#name":"label","_":"(75)"},{"#name":"math","$":{"overflow":"scroll","altimg":"si170.gif"},"$$":[{"#name":"msup","$$":[{"#name":"mi","_":"υ"},{"#name":"mo","_":"*"}]},{"#name":"mfenced","$":{"close":")","separators":",","open":"("},"$$":[{"#name":"mi","$":{"mathvariant":"bold"},"_":"x"},{"#name":"mi","_":"t"}]},{"#name":"mo","_":"="},{"#name":"munder","$$":[{"#name":"mo","_":"inf"},{"#name":"mi","$":{"mathvariant":"bold"},"_":"u"}]},{"#name":"mfenced","$":{"close":"]","open":"["},"$$":[{"#name":"mrow","$$":[{"#name":"mover","$":{"accent":"true"},"$$":[{"#name":"mi","_":"V"},{"#name":"mo","$":{"stretchy":"true"},"_":"¯"}]},{"#name":"mfenced","$":{"close":")","separators":",,","open":"("},"$$":[{"#name":"mi","$":{"mathvariant":"bold"},"_":"x"},{"#name":"mi","$":{"mathvariant":"bold"},"_":"u"},{"#name":"mi","_":"t"}]}]}]},{"#name":"mtext","_":","}]}]}]}]},{"#name":"para","$":{"view":"all","id":"p1250"},"$$":[{"#name":"__text__","_":"using the infimum (inf), instead of the less general minimum (min) in the spirit of "},{"#name":"cross-ref","$":{"refid":"bb0380","id":"cf1340"},"_":"[76]"},{"#name":"__text__","_":", over all admissible controls."}]},{"#name":"para","$":{"view":"all","id":"p1255"},"$$":[{"#name":"__text__","_":"Upon application of the principle of optimality, the dynamic programming equation for the optimal expected cost "},{"#name":"italic","_":"υ"},{"#name":"__text__","_":"* is"},{"#name":"display","$$":[{"#name":"formula","$":{"id":"fo0580"},"$$":[{"#name":"label","_":"(76)"},{"#name":"math","$":{"overflow":"scroll","altimg":"si171.gif"},"$$":[{"#name":"mtable","$":{"columnalign":"left"},"$$":[{"#name":"mtr","$":{"columnalign":"left"},"$$":[{"#name":"mtd","$":{"columnalign":"left"},"$$":[{"#name":"mn","_":"0"}]},{"#name":"mtd","$":{"columnalign":"left"},"$$":[{"#name":"mo","_":"="}]},{"#name":"mtd","$":{"columnalign":"left"},"$$":[{"#name":"msubsup","$$":[{"#name":"mi","_":"υ"},{"#name":"mi","_":"t"},{"#name":"mo","_":"*"}]},{"#name":"mo","_":"+"},{"#name":"msub","$$":[{"#name":"mi","$":{"mathvariant":"normal"},"_":"ℒ"},{"#name":"mi","_":"x"}]},{"#name":"mfenced","$":{"close":"]","open":"["},"$$":[{"#name":"msup","$$":[{"#name":"mi","_":"υ"},{"#name":"mo","_":"*"}]}]},{"#name":"mfenced","$":{"close":")","separators":",","open":"("},"$$":[{"#name":"mi","$":{"mathvariant":"bold"},"_":"x"},{"#name":"mi","_":"t"}]}]}]},{"#name":"mtr","$":{"columnalign":"left"},"$$":[{"#name":"mtd","$":{"columnalign":"left"}},{"#name":"mtd","$":{"columnalign":"left"},"$$":[{"#name":"mo","_":"="}]},{"#name":"mtd","$":{"columnalign":"left"},"$$":[{"#name":"msubsup","$$":[{"#name":"mi","_":"υ"},{"#name":"mi","_":"t"},{"#name":"mo","_":"*"}]},{"#name":"mo","_":"+"},{"#name":"munder","$$":[{"#name":"mo","_":"inf"},{"#name":"mi","$":{"mathvariant":"bold"},"_":"u"}]},{"#name":"mfenced","$":{"close":"","open":"["},"$$":[{"#name":"mrow","$$":[{"#name":"msup","$$":[{"#name":"mi","$":{"mathvariant":"bold"},"_":"F"},{"#name":"mi","_":"T"}]},{"#name":"mfenced","$":{"close":")","open":"("},"$$":[{"#name":"mrow","$$":[{"#name":"mi","$":{"mathvariant":"bold"},"_":"x"},{"#name":"mo","_":","},{"#name":"mi","$":{"mathvariant":"bold"},"_":"u"},{"#name":"mi","_":"t"}]}]},{"#name":"msub","$$":[{"#name":"mo","_":"∇"},{"#name":"mi","_":"x"}]},{"#name":"mfenced","$":{"close":"]","open":"["},"$$":[{"#name":"msup","$$":[{"#name":"mi","_":"υ"},{"#name":"mo","_":"*"}]}]}]}]},{"#name":"mo","_":"+"},{"#name":"mfrac","$$":[{"#name":"mn","_":"1"},{"#name":"mn","_":"2"}]},{"#name":"mfenced","$":{"close":")","open":"("},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"G"},{"#name":"msup","$$":[{"#name":"mi","_":"G"},{"#name":"mi","_":"T"}]}]}]},{"#name":"mfenced","$":{"close":")","separators":",","open":"("},"$$":[{"#name":"mi","$":{"mathvariant":"bold"},"_":"x"},{"#name":"mi","_":"t"}]},{"#name":"mo","_":":"},{"#name":"msub","$$":[{"#name":"mo","_":"∇"},{"#name":"mi","_":"x"}]},{"#name":"msubsup","$$":[{"#name":"mo","_":"∇"},{"#name":"mi","_":"x"},{"#name":"mi","_":"T"}]},{"#name":"mfenced","$":{"close":"]","open":"["},"$$":[{"#name":"msup","$$":[{"#name":"mi","_":"υ"},{"#name":"mo","_":"*"}]}]}]}]},{"#name":"mtr","$":{"columnalign":"left"},"$$":[{"#name":"mtd","$":{"columnalign":"left"}},{"#name":"mtd","$":{"columnalign":"left"},"$$":[{"#name":"mo","_":"+"}]},{"#name":"mtd","$":{"columnalign":"left"},"$$":[{"#name":"mi","_":"C"},{"#name":"mfenced","$":{"close":")","separators":",,","open":"("},"$$":[{"#name":"mi","$":{"mathvariant":"bold"},"_":"x"},{"#name":"mi","$":{"mathvariant":"bold"},"_":"u"},{"#name":"mi","_":"t"}]},{"#name":"mtext","_":"."}]}]}]}]}]}]}]},{"#name":"para","$":{"view":"all","id":"p1260"},"$$":[{"#name":"anchor","$":{"id":"p146"}},{"#name":"__text__","_":"Since "},{"#name":"cross-ref","$":{"refid":"fo0580","id":"cf1345"},"_":"(76)"},{"#name":"__text__","_":" is a backward equation and since we want to keep it simple, "},{"#name":"cross-ref","$":{"refid":"fo0580","id":"cf1350"},"_":"(76)"},{"#name":"__text__","_":" is approximated with the Backward Euler approximation"},{"#name":"display","$$":[{"#name":"formula","$":{"id":"fo0585"},"$$":[{"#name":"label","_":"(77)"},{"#name":"math","$":{"overflow":"scroll","altimg":"si172.gif"},"$$":[{"#name":"mtable","$":{"columnalign":"left"},"$$":[{"#name":"mtr","$":{"columnalign":"left"},"$$":[{"#name":"mtd","$":{"columnalign":"left"},"$$":[{"#name":"msubsup","$$":[{"#name":"mi","_":"υ"},{"#name":"mrow","$$":[{"#name":"mi","_":"κ"},{"#name":"mo","_":"−"},{"#name":"mn","_":"1"}]},{"#name":"mo","_":"*"}]}]},{"#name":"mtd","$":{"columnalign":"left"},"$$":[{"#name":"mo","_":"="}]},{"#name":"mtd","$":{"columnalign":"left"},"$$":[{"#name":"msubsup","$$":[{"#name":"mi","_":"υ"},{"#name":"mi","_":"κ"},{"#name":"mo","_":"*"}]},{"#name":"mfenced","$":{"close":")","open":"("},"$$":[{"#name":"mi","$":{"mathvariant":"bold"},"_":"x"}]},{"#name":"mo","_":"+"},{"#name":"mi","_":"Δ"},{"#name":"msub","$$":[{"#name":"mi","_":"t"},{"#name":"mrow","$$":[{"#name":"mi","_":"κ"},{"#name":"mo","_":"−"},{"#name":"mn","_":"1"}]}]},{"#name":"mo","_":"⋅"},{"#name":"munder","$$":[{"#name":"mo","_":"inf"},{"#name":"mi","$":{"mathvariant":"bold"},"_":"u"}]},{"#name":"mfenced","$":{"close":"","open":"["},"$$":[{"#name":"mrow","$$":[{"#name":"msubsup","$$":[{"#name":"mi","$":{"mathvariant":"bold"},"_":"F"},{"#name":"mi","_":"κ"},{"#name":"mi","_":"T"}]},{"#name":"mfenced","$":{"close":")","separators":",","open":"("},"$$":[{"#name":"mi","$":{"mathvariant":"bold"},"_":"x"},{"#name":"mi","$":{"mathvariant":"bold"},"_":"u"}]},{"#name":"msub","$$":[{"#name":"mo","_":"∇"},{"#name":"mi","_":"x"}]},{"#name":"mfenced","$":{"close":"]","open":"["},"$$":[{"#name":"msubsup","$$":[{"#name":"mi","_":"υ"},{"#name":"mi","_":"x"},{"#name":"mo","_":"*"}]}]}]}]}]}]},{"#name":"mtr","$":{"columnalign":"left"},"$$":[{"#name":"mtd","$":{"columnalign":"left"}},{"#name":"mtd","$":{"columnalign":"left"},"$$":[{"#name":"mo","_":"+"}]},{"#name":"mtd","$":{"columnalign":"left"},"$$":[{"#name":"mfenced","$":{"close":"]","open":""},"$$":[{"#name":"mrow","$$":[{"#name":"mfrac","$$":[{"#name":"mn","_":"1"},{"#name":"mn","_":"2"}]},{"#name":"msub","$$":[{"#name":"mfenced","$":{"close":")","open":"("},"$$":[{"#name":"mrow","$$":[{"#name":"mi","_":"G"},{"#name":"msup","$$":[{"#name":"mi","_":"G"},{"#name":"mi","_":"T"}]}]}]},{"#name":"mi","_":"κ"}]},{"#name":"mfenced","$":{"close":")","open":"("},"$$":[{"#name":"mi","$":{"mathvariant":"bold"},"_":"x"}]},{"#name":"mo","_":":"},{"#name":"msub","$$":[{"#name":"mo","_":"∇"},{"#name":"mi","_":"x"}]},{"#name":"msubsup","$$":[{"#name":"mo","_":"∇"},{"#name":"mi","_":"x"},{"#name":"mi","_":"T"}]},{"#name":"mfenced","$":{"close":"]","open":"["},"$$":[{"#name":"msubsup","$$":[{"#name":"mi","_":"υ"},{"#name":"mi","_":"κ"},{"#name":"mo","_":"*"}]}]},{"#name":"mo","_":"+"},{"#name":"msub","$$":[{"#name":"mi","_":"C"},{"#name":"mi","_":"κ"}]},{"#name":"mfenced","$":{"close":")","separators":",","open":"("},"$$":[{"#name":"mi","$":{"mathvariant":"bold"},"_":"x"},{"#name":"mi","$":{"mathvariant":"bold"},"_":"u"}]}]}]}]}]}]},{"#name":"mtext","_":","}]}]}]}]},{"#name":"para","$":{"view":"all","id":"p1265"},"$$":[{"#name":"__text__","_":"for "},{"#name":"italic","_":"κ"},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"__text__","_":"="},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"__text__","_":"1 to "},{"#name":"italic","_":"K"},{"#name":"__text__","_":", with "},{"#name":"math","$":{"overflow":"scroll","altimg":"si173.gif"},"$$":[{"#name":"msubsup","$$":[{"#name":"mi","_":"υ"},{"#name":"mi","_":"κ"},{"#name":"mo","_":"*"}]},{"#name":"mfenced","$":{"close":")","open":"("},"$$":[{"#name":"mi","$":{"mathvariant":"bold"},"_":"x"}]},{"#name":"mo","_":"≃"},{"#name":"msup","$$":[{"#name":"mi","_":"υ"},{"#name":"mo","_":"*"}]},{"#name":"mfenced","$":{"close":")","separators":",","open":"("},"$$":[{"#name":"mi","$":{"mathvariant":"bold"},"_":"x"},{"#name":"msub","$$":[{"#name":"mi","_":"t"},{"#name":"mi","_":"κ"}]}]}]},{"#name":"__text__","_":" and similarly for "},{"#name":"bold","_":"F"},{"#name":"italic","$$":[{"#name":"inf","$":{"loc":"post"},"_":"κ"}]},{"#name":"__text__","_":", "},{"#name":"italic","$$":[{"#name":"__text__","_":"G"},{"#name":"inf","$":{"loc":"post"},"_":"κ"}]},{"#name":"__text__","_":" and "},{"#name":"italic","$$":[{"#name":"__text__","_":"C"},{"#name":"inf","$":{"loc":"post"},"_":"κ"}]},{"#name":"__text__","_":", while "},{"#name":"italic","$$":[{"#name":"__text__","_":"t"},{"#name":"inf","$":{"loc":"post"},"_":"κ"}]},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"__text__","_":"="},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"italic","_":"t"},{"#name":"inf","$":{"loc":"post"},"$$":[{"#name":"italic","_":"κ"},{"#name":"__text__","_":"–1"}]},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"__text__","_":"+"},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"__text__","_":"Δ"},{"#name":"italic","_":"t"},{"#name":"inf","$":{"loc":"post"},"$$":[{"#name":"italic","_":"κ"},{"#name":"__text__","_":"–1"}]},{"#name":"__text__","_":" is time in terms of the forward index "},{"#name":"italic","_":"κ."},{"#name":"__text__","_":" The final condition is "},{"#name":"math","$":{"overflow":"scroll","altimg":"si174.gif"},"$$":[{"#name":"msubsup","$$":[{"#name":"mi","_":"υ"},{"#name":"mi","_":"K"},{"#name":"mo","_":"*"}]},{"#name":"mfenced","$":{"close":")","open":"("},"$$":[{"#name":"mi","$":{"mathvariant":"bold"},"_":"x"}]},{"#name":"mo","_":"≃"},{"#name":"msup","$$":[{"#name":"mi","_":"υ"},{"#name":"mo","_":"*"}]},{"#name":"mfenced","$":{"close":")","separators":",","open":"("},"$$":[{"#name":"mi","$":{"mathvariant":"bold"},"_":"x"},{"#name":"msub","$$":[{"#name":"mi","_":"t"},{"#name":"mi","_":"f"}]}]},{"#name":"mo","_":"="},{"#name":"msup","$$":[{"#name":"mover","$":{"accent":"true"},"$$":[{"#name":"mi","_":"Z"},{"#name":"mo","$":{"stretchy":"true"},"_":"¯"}]},{"#name":"mo","_":"*"}]},{"#name":"mfenced","$":{"close":")","separators":",","open":"("},"$$":[{"#name":"mi","$":{"mathvariant":"bold"},"_":"x"},{"#name":"msub","$$":[{"#name":"mi","_":"t"},{"#name":"mi","_":"f"}]}]}]},{"#name":"__text__","_":". (The correlation, in the case of constant time increments, between the forward index "},{"#name":"italic","_":"κ"},{"#name":"__text__","_":" and the backward index "},{"#name":"italic","_":"k"},{"#name":"__text__","_":" used in SDP is that "},{"#name":"italic","$$":[{"#name":"__text__","_":"T"},{"#name":"inf","$":{"loc":"post"},"_":"k"}]},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"__text__","_":"="},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"italic","$$":[{"#name":"__text__","_":"t"},{"#name":"inf","$":{"loc":"post"},"_":"f"}]},{"#name":"__text__","_":" – "},{"#name":"italic","_":"k"},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"__text__","_":"·"},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"__text__","_":"Δ"},{"#name":"italic","_":"T"},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"__text__","_":"="},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"__text__","_":"("},{"#name":"italic","_":"K"},{"#name":"__text__","_":" – "},{"#name":"italic","_":"k"},{"#name":"__text__","_":")"},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"__text__","_":"·"},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"__text__","_":"Δ"},{"#name":"italic","_":"T"},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"__text__","_":"="},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"italic","_":"t"},{"#name":"inf","$":{"loc":"post"},"$$":[{"#name":"italic","_":"K"},{"#name":"__text__","_":"–"},{"#name":"italic","_":"k"}]},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"__text__","_":"="},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"italic","$$":[{"#name":"__text__","_":"t"},{"#name":"inf","$":{"loc":"post"},"_":"κ"}]},{"#name":"__text__","_":", so the forward and backward time indices are related by "},{"#name":"italic","_":"κ"},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"__text__","_":"="},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"italic","_":"K"},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"__text__","_":"="},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"italic","_":"k"},{"#name":"__text__","_":". Hence, "},{"#name":"italic","_":"T"},{"#name":"inf","$":{"loc":"post"},"_":"0"},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"__text__","_":"="},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"italic","$$":[{"#name":"__text__","_":"t"},{"#name":"inf","$":{"loc":"post"},"_":"f"}]},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"__text__","_":"="},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"italic","$$":[{"#name":"__text__","_":"t"},{"#name":"inf","$":{"loc":"post"},"_":"K"}]},{"#name":"__text__","_":" and "},{"#name":"italic","$$":[{"#name":"__text__","_":"T"},{"#name":"inf","$":{"loc":"post"},"_":"K"}]},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"__text__","_":"="},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"__text__","_":"0"},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"__text__","_":"="},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"italic","_":"t"},{"#name":"inf","$":{"loc":"post"},"_":"0"},{"#name":"__text__","_":", are the final and initial times, respectively, in either time direction.) The interpolation time increment is denoted by Δ"},{"#name":"italic","_":"t"},{"#name":"inf","$":{"loc":"post"},"$$":[{"#name":"italic","_":"κ"},{"#name":"__text__","_":"–1"}]},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"__text__","_":"="},{"#name":"hsp","$":{"sp":"0.12"}},{"#name":"italic","$$":[{"#name":"__text__","_":"t"},{"#name":"inf","$":{"loc":"post"},"_":"κ"}]},{"#name":"__text__","_":" – "},{"#name":"italic","_":"t"},{"#name":"inf","$":{"loc":"post"},"$$":[{"#name":"italic","_":"κ"},{"#name":"__text__","_":"–1"}]},{"#name":"__text__","_":" here and has important roles to play for modeling and for numerical convergence."}]},{"#name":"para","$":{"view":"all","id":"p1270"},"$$":[{"#name":"__text__","_":"However, since much of the literature on MCA, corresponding to much of the literature on stochastic control, is formulated as a stationary (time-independent) problem, the indices "},{"#name":"italic","_":"k"},{"#name":"__text__","_":" and "},{"#name":"italic","_":"κ"},{"#name":"__text__","_":" are treated as iteration indices for the time-independent problem. The time-independent problem may arise from ergodic problems or exit time problems or infinite horizon problems, for example."}]}]},"pii":"S009052679680017X","isbn":"9780120127764","issn":"00905267","version":"S300.1","contentType":"BS","cid":"275767","title":"Stochastic Digital Control System Techniques","displayName":"Control and Dynamic Systems","coverDateYear":"1996","authors":{"#name":"rootwrapper","$":{"xmlns:ce":""},"$$":[{"#name":"author-group","$":{"id":"ag0005"},"$$":[{"#name":"author","$":{"id":"au0005"},"$$":[{"#name":"given-name","_":"Floyd B."},{"#name":"surname","_":"Hanson"},{"#name":"cross-ref","$":{"refid":"fn0005","id":"cf0005"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"1"}]}]},{"#name":"affiliation","$":{"id":"af0005"},"$$":[{"#name":"textfn","$":{"id":"tn0005"},"_":"University of Illinois at Chicago Chicago Illinois 60607–7045"},{"#name":"affiliation","$":{"xmlns:sa":""},"$$":[{"#name":"organization","_":"University of Illinois at Chicago Chicago"},{"#name":"state","_":"Illinois"},{"#name":"postal-code","_":"60607–7045"}]}]},{"#name":"footnote","$":{"id":"fn0005"},"$$":[{"#name":"label","_":"1"},{"#name":"note-para","$":{"view":"all","id":"np0010"},"_":"Supported in part by National Science Foundation Grant DMS 93–0117, National Center for Supercomputing Applications, Pittsburgh Supercomputing Center, and Los Alamos National Laboratory’s Advanced Computing Laboratory; written while on sabbatical in Division of Applied Mathematics at Brown University, Providence, RI02912"}]}]}]},"floats":[],"attachments":[],"snippetMetadata":{"identifier":"S009052679680017X","xpath":"//ce:section[@id='s0150']","version":"S300.1"}},{"body":{"#name":"section","$":{"view":"all","id":"s0010","xmlns:ce":""},"$$":[{"#name":"label","_":"2.1"},{"#name":"section-title","$":{"id":"st0020"},"_":"Introduction"},{"#name":"para","$":{"view":"all","id":"p0010"},"$$":[{"#name":"anchor","$":{"id":"p27"}},{"#name":"__text__","_":"The existence of optimization methods can be traced back to the days of Newton, Lagrange, and Cauchy. Newton and Leibnitz made invaluable contributions to the literature of calculus which allowed the development of differential calculus methods for optimization. However, the minimization of some functions using calculus of variations has been established by Bernoulli, Euler, Lagrange, and Weierstrass. Then, Lagrange introduced the method of adding unknown multipliers to the minimization problem, which led him to cope with constrained optimization problems. For the solution of optimization problems, Cauchy introduced the first application of the steepest descent method to solve unconstrained optimization problems. By the middle of the 20th century, the high-speed digital computers made implementation of the complex optimization procedures possible and stimulated further research on newer methods. Spectacular advances followed, producing a massive literature on optimization techniques. This advancement also resulted in the emergence of several well-defined new areas in optimization theory."}]},{"#name":"para","$":{"view":"all","id":"p0015"},"$$":[{"#name":"__text__","_":"Some of the major developments in the area of numerical methods of unconstrained optimization can be outlined as follows. The work on optimization theory was born by the development of the simplex method by Dantzig in 1947 for linear programming (LP) problems "},{"#name":"cross-ref","$":{"id":"crf5","refid":"bib1"},"_":"[1]"},{"#name":"__text__","_":". Then, the principle of optimality was presented by Bellman for dynamic programming problems in 1957 "},{"#name":"cross-ref","$":{"id":"crf6","refid":"bib2"},"_":"[2]"},{"#name":"__text__","_":". Work by Kuhn and Tucker in 1951 on the necessary and sufficient conditions for the optimal solution of programming problems laid the foundation for later research in non-LP (NLP) "},{"#name":"cross-ref","$":{"id":"crf7","refid":"bib3"},"_":"[3]"},{"#name":"__text__","_":". But the most valuable contributions to NLP were made by Zoutendijk and Rosen during the early 1960s "},{"#name":"cross-refs","$":{"id":"crfs1","refid":"bib4 bib5"},"_":"[4,5]"},{"#name":"__text__","_":". Again in the same year, Duffin, Peterson, and Zener developed geometric programming, and Gomory did pioneering work in integer programming, which is one of the most exciting and rapidly developing areas of optimization "},{"#name":"cross-refs","$":{"id":"crfs2","refid":"bib6 bib7"},"_":"[6,7]"},{"#name":"__text__","_":". The reason for this is that most real world applications fall under this category of problems. Also, Dantzig, Charnes, Cooper and, Symons developed stochastic programming techniques and solved problems by assuming design parameters to be independent and normally distributed "},{"#name":"cross-refs","$":{"id":"crfs3","refid":"bib8 bib9 bib10"},"_":"[8–10]"},{"#name":"__text__","_":". In the last decade, simulated annealing (SA), genetic algorithms (GAs), and neural network methods were introduced to represent a new class of mathematical programming. Between them, SA is analogous to the physical process of annealing of metals and glass. The GAs are search techniques based on the mechanics of natural selection and natural genetics and finally neural network methods are based on solving the problem using the computing power of a network of interconnected “neuron” processors."},{"#name":"anchor","$":{"id":"p28"}}]},{"#name":"para","$":{"view":"all","id":"p0020"},"_":"To indicate the widespread scope of the subject, some major applications in different engineering disciplines can be listed as follows: Design of civil engineering structures such as frames, foundations, bridges, towers, chimneys, and dams for minimum cost; design of minimum weight structures for earth quake, wind, and other types of random loading; design of water resources systems for obtaining maximum benefit; design of aircraft and aerospace structure for minimum weight; finding the optimal trajectories of space vehicles; design of pumps, turbines and heat transfer equipment for maximum efficiency; optimum design of electrical machinery such as motors, generators, and transformers; optimum design of electrical networks; finding out the optimal energy production and distribution strategy; optimum design of control systems; optimum design of chemical processing equipments and plants; optimal selection of a site for an industry; optimal planning of maintenance and replacement of equipment to reduce operating costs; allocation of resources or services among several activities to maximize the benefit; controlling the waiting and idle times in production lines to reduce the cost of production; designing the shortest route to be taken by a salesperson to visit various cities in a single tour and optimal production planning, controlling, and scheduling."}]},"pii":"B9780081010419000028","isbn":"9780081010419","issn":null,"version":"S300.1","contentType":"BK","cid":"315898","title":"Introduction to Optimization","displayName":"Optimization in Renewable Energy Systems","coverDateYear":"2017","authors":{"#name":"rootwrapper","$":{"xmlns:ce":""},"$$":[{"#name":"author-group","$":{"id":"aug0010"},"$$":[{"#name":"author","$":{"id":"au0010","author-id":"B9780081010419000028-729b4c1d0d2034cb5b82dde90734748a"},"$$":[{"#name":"given-name","_":"Yavuz"},{"#name":"surname","_":"Eren"},{"#name":"cross-ref","$":{"id":"crf1","refid":"aff1"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"1"}]}]},{"#name":"author","$":{"id":"au0015","author-id":"B9780081010419000028-caf2d4f8eb2dc5e587402a8fda972ca3"},"$$":[{"#name":"given-name","_":"İbrahim B."},{"#name":"surname","_":"Küçükdemiral"},{"#name":"cross-ref","$":{"id":"crf2","refid":"aff1"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"1"}]},{"#name":"cross-ref","$":{"id":"crf3","refid":"aff2"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"2"}]}]},{"#name":"author","$":{"id":"au0020","author-id":"B9780081010419000028-6dba7ed0cc04bc4766ebde9d0dbec645"},"$$":[{"#name":"given-name","_":"İlker"},{"#name":"surname","_":"Üstoğlu"},{"#name":"cross-ref","$":{"id":"crf4","refid":"aff1"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"1"}]}]},{"#name":"affiliation","$":{"id":"aff1"},"$$":[{"#name":"label","_":"1"},{"#name":"textfn","_":"Yildiz Technical University, Istanbul, Turkey"},{"#name":"affiliation","$":{"xmlns:sa":"http://www.elsevier.com/xml/common/struct-aff/dtd"},"$$":[{"#name":"organization","_":"Yildiz Technical University"},{"#name":"city","_":"Istanbul"},{"#name":"country","_":"Turkey"}]}]},{"#name":"affiliation","$":{"id":"aff2"},"$$":[{"#name":"label","_":"2"},{"#name":"textfn","_":"Glasgow Caledonian University, Glasgow, United Kingdom"},{"#name":"affiliation","$":{"xmlns:sa":"http://www.elsevier.com/xml/common/struct-aff/dtd"},"$$":[{"#name":"organization","_":"Glasgow Caledonian University"},{"#name":"city","_":"Glasgow"},{"#name":"country","_":"United Kingdom"}]}]}]}]},"floats":[],"attachments":[],"snippetMetadata":{"identifier":"B9780081010419000028","xpath":"//ce:section[@id='s0010']","version":"S300.1"}},{"body":{"#name":"section","$":{"view":"all","id":"s0040","xmlns:ce":""},"$$":[{"#name":"label","_":"6.2.2"},{"#name":"section-title","$":{"id":"st0050"},"_":"Optimal solution: Dynamic programming"},{"#name":"para","$":{"view":"all","id":"p0325"},"_":"Dynamic programming is herewith implemented offline with low requirements in terms of computational time and effort. The algorithm is implemented with a simplified vehicle model with sufficient accuracy to capture the optimal working conditions of the hybrid components, but limited computational requirements as provided by a processor, the Intel CORE i7. This offline implementation allows the use of a dynamic programming algorithm implemented in MATLAB and used to optimise a vehicle model included in a MATLAB function file. Although there are numerous approaches in the literature to obtain optimal results that can reduce the computational effort required, the beneficial characteristics and numerous satisfactory implementations in the research on dynamic programming suggest the implementation of this methodology for this application."},{"#name":"para","$":{"view":"all","id":"p0330"},"$$":[{"#name":"__text__","_":"The dynamic programming algorithm can obtain global optimal results of multivariable nonlinear problems. In common with other optimisation algorithms, the solution is found by minimising an unwanted outcome or maximising a sought benefit. In minimisation problems, this unwanted outcome is called a cost function, although other commonly used terms include target and objective function. The optimal solution is strongly conditioned by the target or targets of interest, which determine the control strategy to follow "},{"#name":"cross-ref","$":{"id":"cf0205","refid":"bb0095"},"_":"[18]"},{"#name":"__text__","_":". Dynamic programming is particularly recommended for offline energy management optimisation due to the possibility of achieving global optimal solutions and reducing the baseline problem into subproblems. "},{"#name":"italic","_":"N"},{"#name":"__text__","_":"-Dimensional problems are divided into "},{"#name":"italic","_":"N"},{"#name":"__text__","_":" problems of one dimension, easier and faster to solve, whose optimality is guaranteed through the principle of optimality "},{"#name":"cross-refs","$":{"id":"cf0210","refid":"bb0190 bb0195 bb0200"},"_":"[37–39]"},{"#name":"__text__","_":". This optimisation algorithm is particularly useful when dealing with solutions distributed in common branches that converge into a single state. In the event that more than one solution candidate converges into the same instantaneous conditions, the strategies associated with higher cost can be automatically discarded, as it can be ensured that they would not outperform the candidate converging into the same state with lower cost; “"},{"#name":"italic","_":"optimal policies have optimal subpolicies"},{"#name":"__text__","_":"” "},{"#name":"cross-ref","$":{"id":"cf0215","refid":"bb0190"},"_":"[37]"},{"#name":"__text__","_":". This implies that, given a common state, alternative branches that lead to it can be simplified, maintaining only the ones that provide minimum cost "},{"#name":"cross-ref","$":{"id":"cf0220","refid":"bb0205"},"_":"[40]"},{"#name":"__text__","_":". This process reduces the solution candidates that need to be further elaborated and carried forward and consequently decrements considerably the computational effort required. Hybrid vehicle control is known to have a solution of the characteristics described, which is why they benefit from dynamic programming as observed in numerous publications. More information about the characteristics of this algorithm are detailed in "},{"#name":"intra-ref","$":{"xmlns:xlink":"","href":"pii:B978-0-12-815010-8.00002-8#s0050","id":"ia0020","type":"simple"},"_":"Section 2.4.2"},{"#name":"__text__","_":"."}]},{"#name":"para","$":{"view":"all","id":"p0335"},"_":"Dynamic programming is implemented with its deterministic version, since the characteristics of the cycles are perfectly known and collected with complete information from real-life conditions. In offline optimisation and with the aim of generating expert data for training, it is assumed that all disturbances are perfectly controlled. After implementation, the optimal controller would operate based on the predicted future power demand, as generated by the long-term speed prediction algorithm. Although the methodology implementation is clear, the solution is particularly dependent on the selection criteria, that is, the cost function. The most popular objective is fuel consumption reduction; the objective function can be expressed in terms of other variables such as tailpipe emissions reduction, performance enhancement or a combination of these with multiobjective approaches. When dealing with conflicting objectives, the combined optimal values require parallel computation and pareto solutions analysis. This computationally expensive resolution can be simplified using a single objective function in which the objectives are mixed through weight summation or constrained within desired intervals. Whilst constrained objectives cannot be efficiently optimised, the combination of weighted objectives can achieve an optimal trade-off, provided the weights are properly selected, that is, they properly represent the relative importance of each objective and their selection is mathematically justified."},{"#name":"para","$":{"view":"all","id":"p0340"},"_":"The approach taken here consists of a combination of electric and chemical power weighted using the relative cost between the sources of energy. Fuel and electricity prices are used to combine the two power signals and generate a cost function that targets the minimisation of the overall energy cost. This approach allows an analysis of the trade-off between electricity and fuel and the effect of the energy cost in the control strategy. However, in practise and due to the higher cost of fuel and the lower efficiency of the internal combustion engine compared to the electric components, the previous cost function is equivalent to fuel consumption minimisation. Nevertheless, it also allows for modification of the relative price of the electricity and fuel cost and study of their effect on the energy management strategy."}]},"pii":"B9780128150108000065","isbn":"9780128150108","issn":null,"version":"S300.1","contentType":"BK","cid":"319571","title":"iHorizon driver energy management for PHEV real-time control","displayName":"Ihorizon-Enabled Energy Management for Electrified Vehicles","coverDateYear":"2019","authors":{"#name":"rootwrapper","$":{"xmlns:ce":""},"$$":[{"#name":"author-group","$":{"xfab-added":"true"},"$$":[{"#name":"author","$":{"id":"au0015","author-id":"C20170028690-2040e4cdbe8c380dd448c38605af79fd"},"$$":[{"#name":"given-name","_":"Clara Marina"},{"#name":"surname","_":"Martínez"}]}]},{"#name":"author-group","$":{"xfab-added":"true"},"$$":[{"#name":"author","$":{"id":"au0010","author-id":"C20170028690-3b058dfc0bdce7d197e460bc8f03734c"},"$$":[{"#name":"given-name","_":"Dongpu"},{"#name":"surname","_":"Cao"}]}]}]},"floats":[],"attachments":[],"snippetMetadata":{"identifier":"B9780128150108000065","xpath":"//ce:section[@id='s0040']","version":"S300.1"}},{"body":{"#name":"section","$":{"view":"all","id":"s0010","xmlns:ce":""},"$$":[{"#name":"label","_":"2.1"},{"#name":"section-title","$":{"id":"st0010"},"_":"Discrete representations and dynamic programming algorithms"},{"#name":"para","$":{"view":"all","id":"p0010"},"$$":[{"#name":"__text__","_":"In optimization, a process is regarded as dynamic when it can be described as a well-defined sequence of steps in time or space. Dynamic processes can be either discrete or continuous. Cascades ("},{"#name":"cross-ref","$":{"refid":"f0010"},"_":"Figure 2.1"},{"#name":"float-anchor","$":{"refid":"f0010"}},{"#name":"__text__","_":"), which are systems characterized by sequential arrangement of stages, are examples of dynamic discrete processes. The stages can be of finite size, in which case the process is “inherently discrete”, or may be infinitesimally small. The latter case refers to a limiting situation where the concept of very many steps serves to approximate the development of a continuous process. In general, optimization theories of discrete and continuous processes differ in their assumptions, formal descriptions and strength of optimality conditions; thus they usually constitute two different fields. Here, however, for brevity, we present a heuristic derivation of optimization conditions focusing on those which in many respects are common for both discrete and continuous processes. Consequently we shall formulate first a basic discrete algorithm for a general model of a discrete cascade process, and then consider its limiting properties when the number of infinitesimal discrete steps tends towards infinity."}]},{"#name":"para","$":{"view":"all","id":"p0020"},"$$":[{"#name":"__text__","_":"The method of dynamic programming (DP; "},{"#name":"intra-refs","$":{"xmlns:xlink":"","type":"extended"},"$$":[{"#name":"intra-refs-text","$":{"id":"itt0010","label":"intra-refs-start","type":"resource"},"_":"Bellman, 1957; Aris, 1964; Findeisen et al., 1980"},{"#name":"intra-ref-end","$":{"href":"pii:B978-0-08-045141-1.00021-4#bib1420","label":"intra-ref-end","type":"locator"},"$$":[{"#name":"intra-ref-title","$":{"type":"title"},"_":"Bellman, 1957"}]},{"#name":"intra-ref-end","$":{"href":"pii:B978-0-08-045141-1.00021-4#bib0500","label":"intra-ref-end","type":"locator"},"$$":[{"#name":"intra-ref-title","$":{"type":"title"},"_":"Aris, 1964"}]},{"#name":"intra-ref-end","$":{"href":"pii:B978-0-08-045141-1.00021-4#bib3950","label":"intra-ref-end","type":"locator"},"$$":[{"#name":"intra-ref-title","$":{"type":"title"},"_":"Findeisen et al., 1980"}]},{"#name":"intra-refs-link","$":{"from":"intra-refs-start","to":"intra-ref-end","type":"arc"}}]},{"#name":"__text__","_":") constitutes a suitable tool to handle optimality conditions for inherently discrete processes. Yet, the method only enables an easy passage to"},{"#name":"anchor","$":{"id":"p46"}},{"#name":"__text__","_":" its limiting form for continuous systems under the differentiability assumption. Application of the method is straightforward when it is applied in optimization of control systems without feedback. Dynamic programming is crucial for the existence of the optimal performance potentials discussed in this book, and for the derivation of pertinent equations which describe these potentials. The DP method is based on Bellman's principle of optimality, which makes it possible to replace the simultaneous evaluation of all optimal controls by sequences of local evaluations at sequentially included stages, for evolving subprocesses ("},{"#name":"cross-refs","$":{"refid":"f0010 f0020"},"_":"Figures 2.1 and 2.2"},{"#name":"float-anchor","$":{"refid":"f0020"}},{"#name":"__text__","_":")."}]},{"#name":"para","$":{"view":"all","id":"p0030"},"$$":[{"#name":"__text__","_":"Let us focus first on "},{"#name":"cross-ref","$":{"refid":"f0010"},"_":"Figure 2.1"},{"#name":"__text__","_":", where the optimal performance function is generated in terms of the initial states and initial time. The principle of optimality may then be stated as follows: "},{"#name":"italic","_":"In a continuous or discrete process which is described by an additive performance criterion"},{"#name":"__text__","_":", "},{"#name":"italic","_":"the optimal strategy and optimal profit are functions of the initial state"},{"#name":"__text__","_":", "},{"#name":"italic","_":"initial time and (in a discrete process) total number of stages"},{"#name":"__text__","_":". A consequence of this property is that each final segment of an optimal path (continuous or discrete) is optimal with respect to its own initial state, initial time and (in a discrete process) the corresponding number of stages. An easy proof of this formulation by contradiction uses the additivity property of the performance criterion ("},{"#name":"intra-ref","$":{"id":"it0010","href":"pii:B978-0-08-045141-1.00021-4#bib0500","type":"simple"},"_":"Aris, 1964"},{"#name":"__text__","_":")."}]},{"#name":"para","$":{"view":"all","id":"p0040"},"$$":[{"#name":"__text__","_":"The above formulation of the optimality principle refers to the so-called backward algorithm of the dynamic programming method ("},{"#name":"cross-ref","$":{"refid":"f0010"},"_":"Figure 2.1"},{"#name":"__text__","_":"). In this mode, the recursive procedure for applying a governing functional equation begins at the final process state and terminates at its initial state. Consequently, local optimizations take place in the direction opposite to the direction of physical time or the direction of flow of matter. (The process to which this can be applied may be arbitrary: it may be discrete by nature or may be obtained by the discretization of an originally continuous process.) The state transformations possess in the backward algorithm their most natural form, as they describe output states in terms"},{"#name":"anchor","$":{"id":"p47"}},{"#name":"__text__","_":" of input states and controls at a stage. The optimization at a stage and optimal functions recursively involve the information generated in earlier subprocesses."}]},{"#name":"para","$":{"view":"all","id":"p0050"},"$$":[{"#name":"__text__","_":"However, one may also generate the optimal profit function in terms of the final states and final time. The optimality principle then has a dual form: "},{"#name":"italic","_":"In a continuous or discrete process"},{"#name":"__text__","_":", "},{"#name":"italic","_":"which is described by an additive performance criterion"},{"#name":"__text__","_":", "},{"#name":"italic","_":"the optimal strategy and optimal profit are functions of the final state"},{"#name":"__text__","_":", "},{"#name":"italic","_":"final time and (in a discrete process) total number of stages"},{"#name":"__text__","_":". A basic consequence of this property is that each initial segment of the optimal path (continuous or discrete) is optimal with respect to its final state, final time and (in a discrete process) the corresponding number of stages. This formulation refers to the so-called forward algorithm of the dynamic programming method. In this algorithm the recursive optimization procedure for solving the governing functional equation begins from the initial process state and terminates at its final state. With the forward DP algorithm, one makes local optimizations in the direction of real time."}]},{"#name":"para","$":{"view":"all","id":"p0060"},"_":"It is the dual (forward) formulation of the optimality principle and the associated forward algorithm that we commonly apply to multistage processes considered later in this chapter. The state transformations used in this case have the form which describes input states in terms of output states and controls at a process stage. Transformations of this sort are directly obtained for multistage processes with an ideal mixing at the stage, otherwise the inverse transformations (applicable to the backward algorithm) might be difficult to obtain in an explicit form. Again, as in the case of the original form of the optimality principle, its dual form makes it possible to replace the simultaneous evaluation of all optimal controls by successive evaluations for evolving optimal subprocesses."},{"#name":"para","$":{"view":"all","id":"p0070"},"$$":[{"#name":"__text__","_":"In the continuous case under the differentiability assumption the method of dynamic programming leads to a basic equation of optimal continuous processes called the Hamilton–Jacobi–Bellman equation which constitutes a control counterpart of the well-known Hamilton–Jacobi equation of classical mechanics ("},{"#name":"intra-refs","$":{"type":"extended"},"$$":[{"#name":"intra-refs-text","$":{"id":"itt0020","label":"intra-refs-start","type":"resource"},"_":"Rund, 1966; Landau and Lifshitz, 1971"},{"#name":"intra-ref-end","$":{"href":"pii:B978-0-08-045141-1.00021-4#bib10080","label":"intra-ref-end","type":"locator"},"$$":[{"#name":"intra-ref-title","$":{"type":"title"},"_":"Rund, 1966"}]},{"#name":"intra-ref-end","$":{"href":"pii:B978-0-08-045141-1.00021-4#bib6850","label":"intra-ref-end","type":"locator"},"$$":[{"#name":"intra-ref-title","$":{"type":"title"},"_":"Landau and Lifshitz, 1971"}]},{"#name":"intra-refs-link","$":{"from":"intra-refs-start","to":"intra-ref-end","type":"arc"}}]},{"#name":"__text__","_":"). Moreover, as we shall see later, a similar equation can be derived for special discrete processes: those with unconstrained time intervals "},{"#name":"italic","_":"θ"},{"#name":"sup","$":{"loc":"post"},"$$":[{"#name":"italic","_":"n"}]},{"#name":"__text__","_":"."}]}]},"pii":"B9780080451411000020","isbn":"9780080451411","issn":null,"version":"S300.3","contentType":"BK","cid":"278602","title":"Dynamic optimization problems","displayName":"Energy Optimization in Process Systems","coverDateYear":"2009","authors":{"#name":"rootwrapper","$":{"xmlns:ce":""},"$$":[{"#name":"author-group","$":{"xfab-added":"true"},"$$":[{"#name":"author","$":{"id":"au0010"},"$$":[{"#name":"given-name","_":"Stanisław"},{"#name":"surname","_":"Sieniutycz"}]},{"#name":"affiliation","$":{"id":"aff0010"},"$$":[{"#name":"textfn","$":{"id":"tfn0010"},"_":"Warsaw University of Technology, Faculty of Chemical and Process Engineering, Warsaw, Poland"}]}]},{"#name":"author-group","$":{"xfab-added":"true"},"$$":[{"#name":"author","$":{"id":"au0020"},"$$":[{"#name":"given-name","_":"Jacek"},{"#name":"surname","_":"Jeżowski"}]},{"#name":"affiliation","$":{"id":"aff0020"},"$$":[{"#name":"textfn","$":{"id":"tfn0020"},"_":"Rzeszów University of Technology, Department of Chemical and Process Engineering, Poland"}]}]}]},"floats":[{"#name":"figure","$":{"id":"f0010"},"$$":[{"#name":"label","_":"Figure 2.1"},{"#name":"caption","$$":[{"#name":"simple-para","$":{"view":"all","id":"sp0010"},"$$":[{"#name":"__text__","_":"Backward optimization algorithm and typical mode of stage numbering in the dynamic programming method. The results are generated in terms of the initial states "},{"#name":"bold","_":"x"},{"#name":"sup","$":{"loc":"post"},"$$":[{"#name":"italic","_":"n"}]},{"#name":"__text__","_":"."}]}]},{"#name":"link","$":{"id":"lk0010","locator":"gr1"}}]},{"#name":"figure","$":{"id":"f0020"},"$$":[{"#name":"label","_":"Figure 2.2"},{"#name":"caption","$$":[{"#name":"simple-para","$":{"view":"all","id":"sp0020"},"$$":[{"#name":"__text__","_":"Forward optimization algorithm; the results are generated in terms of the final states "},{"#name":"bold","_":"x"},{"#name":"sup","$":{"loc":"post"},"$$":[{"#name":"italic","_":"n"}]},{"#name":"__text__","_":"."}]}]},{"#name":"link","$":{"id":"lk0020","locator":"gr2"}}]}],"attachments":[{"attachment-eid":"3-s2.0-B9780080451411000020-gr1.jpg","file-basename":"gr1","filename":"gr1.jpg","pixel-height":"251","attachment-type":"IMAGE-DOWNSAMPLED"},{"attachment-eid":"3-s2.0-B9780080451411000020-gr1.sml","file-basename":"gr1","filename":"gr1.sml","pixel-height":"112","attachment-type":"IMAGE-THUMBNAIL"},{"attachment-eid":"3-s2.0-B9780080451411000020-gr2.jpg","file-basename":"gr2","filename":"gr2.jpg","pixel-height":"265","attachment-type":"IMAGE-DOWNSAMPLED"},{"attachment-eid":"3-s2.0-B9780080451411000020-gr2.sml","file-basename":"gr2","filename":"gr2.sml","pixel-height":"110","attachment-type":"IMAGE-THUMBNAIL"}],"snippetMetadata":{"identifier":"B9780080451411000020","xpath":"//ce:section[@id='s0010']","version":"S300.3"}}],"topicId":"15_493555671","definitionSourceTitle":null,"definitionSourcePii":null,"definitionSourceXPath":null,"definitionSourceYear":null,"topicUrlPath":"/engineering/principle-of-optimality","relatedConcepts":[{"parentDomain":"Physical Sciences and Engineering","childDomain":"Engineering","topicName":"Sustainable Development","topicURLPath":"/engineering/sustainable-development","topicId":"15_492298943"},{"parentDomain":"Physical Sciences and Engineering","childDomain":"Engineering","topicName":"Prosthetics","topicURLPath":"/engineering/prosthetics","topicId":"15_493014812"},{"parentDomain":"Physical Sciences and Engineering","childDomain":"Engineering","topicName":"Optimality","topicURLPath":"/engineering/optimality","topicId":"15_493554053"},{"parentDomain":"Physical Sciences and Engineering","childDomain":"Engineering","topicName":"dynamic programming","topicURLPath":"/engineering/dynamic-programming","topicId":"15_493564315"},{"parentDomain":"Physical Sciences and Engineering","childDomain":"Engineering","topicName":"Optimal Policy","topicURLPath":"/engineering/optimal-policy","topicId":"15_493656411"},{"parentDomain":"Physical Sciences and Engineering","childDomain":"Engineering","topicName":"Performance Criterion","topicURLPath":"/engineering/performance-criterion","topicId":"15_493658546"}],"piiList":["B9780080446745500250","B9781785480492500049","B9780444632340500294","B9780128052464000070","B9780080273105500138","B9780128052464000227","S009052679680017X","B9780081010419000028","B9780128150108000065","B9780080451411000020"]},"pdfDownload":{},"renderTarget":"html","alerts":{"showAlertsModal":false},"entitlements":{"B9780080446745500250":false,"B9781785480492500049":false,"B9780444632340500294":false,"B9780128052464000070":false,"B9780080273105500138":false,"B9780128052464000227":false,"S009052679680017X":false,"B9780081010419000028":false,"B9780128150108000065":false,"B9780080451411000020":false}};
                        </script></div>
<script src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/10/js/babel-polyfill/6.26.0/babel-polyfill.min.js" type="2975f070f66ff17199d53d68-text/javascript"></script>
<script src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/26/js/react/16.8.4/react.production.min.js" type="2975f070f66ff17199d53d68-text/javascript"></script>
<script src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/26/js/react-dom/16.8.4/react-dom.production.min.js" type="2975f070f66ff17199d53d68-text/javascript"></script>
<script type="2975f070f66ff17199d53d68-text/javascript">(function(){
    if (document.querySelector('math')) {
      var hasMathML = false;
      if (document.createElementNS) {
        var ns = 'http://www.w3.org/1998/Math/MathML', div = document.createElement('div');
        div.style.position = 'absolute';
        var mfrac = div.appendChild(document.createElementNS(ns, 'math')).appendChild(document.createElementNS(ns, 'mfrac'));
        mfrac.appendChild(document.createElementNS(ns, 'mi')).appendChild(document.createTextNode('xx'));
        mfrac.appendChild(document.createElementNS(ns, 'mi')).appendChild(document.createTextNode('yy'));
        document.body.appendChild(div);
        hasMathML = div.offsetHeight > div.offsetWidth;
        document.body.removeChild(div);
      }
      if (!hasMathML) {
        var script = document.createElement('script');
        script.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=MML_SVG';
        document.body.appendChild(script);
      }
    }
  })()</script>
<script type="2975f070f66ff17199d53d68-text/javascript">
      window.isIE11 = !!window.MSInputMethodContext && !!document.documentMode;
    </script>
<script type="2975f070f66ff17199d53d68-text/javascript">
        window.assetsBaseURL = 'https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/726ce6de1d3d8212198e38c30b5dd31f20fa8fff';
        window.pageData = {"page":{"businessUnit":"els:rp:st","language":"en","name":"foundationalcontent:topics:topicdetail","noTracking":"false","productName":"sd","type":"cp-cr","environment":"prod","loadTimestamp":"1566313573041"},"content":[{"title":"engineering ^ principle-of-optimality","format":"MIME-XHTML","id":"sd:topic:15_493555671","type":"sd:topic"}],"visitor":{"accessType":"ae:ANON_IP","accountId":"ae:46800","accountName":"ae:Sorbonne University Pierre and Marie Curie Campus","userId":"ae:870092","ipAddress":"134.157.19.127","appSessionId":"e8b31718-1694-4376-ba4a-f9186507ce0a"}};
      </script>
<div id="dynamic-js-holder"></div>
<script src='https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/726ce6de1d3d8212198e38c30b5dd31f20fa8fff/client.js' async type="2975f070f66ff17199d53d68-text/javascript"></script>

<script type="2975f070f66ff17199d53d68-text/javascript">
        window.lightningjs||function(c){function g(b,d){d&&(d+=(/\?/.test(d)?"&":"?")+"lv=1");c[b]||function(){var i=window,h=document,j=b,g=h.location.protocol,l="load",k=0;(function(){function b(){a.P(l);a.w=1;c[j]("_load")}c[j]=function(){function m(){m.id=e;return c[j].apply(m,arguments)}var b,e=++k;b=this&&this!=i?this.id||0:0;(a.s=a.s||[]).push([e,b,arguments]);m.then=function(b,c,h){var d=a.fh[e]=a.fh[e]||[],j=a.eh[e]=a.eh[e]||[],f=a.ph[e]=a.ph[e]||[];b&&d.push(b);c&&j.push(c);h&&f.push(h);return m};return m};var a=c[j]._={};a.fh={};a.eh={};a.ph={};a.l=d?d.replace(/^\/\//,(g=="https:"?g:"http:")+"//"):d;a.p={0:+new Date};a.P=function(b){a.p[b]=new Date-a.p[0]};a.w&&b();i.addEventListener?i.addEventListener(l,b,!1):i.attachEvent("on"+l,b);var q=function(){function b(){return["<head></head><",c,' onload="var d=',n,";d.getElementsByTagName('head')[0].",d,"(d.",g,"('script')).",i,"='",a.l,"'\"></",c,">"].join("")}var c="body",e=h[c];if(!e)return setTimeout(q,100);a.P(1);var d="appendChild",g="createElement",i="src",k=h[g]("div"),l=k[d](h[g]("div")),f=h[g]("iframe"),n="document",p;k.style.display="none";e.insertBefore(k,e.firstChild).id=o+"-"+j;f.frameBorder="0";f.id=o+"-frame-"+j;/MSIE[ ]+6/.test(navigator.userAgent)&&(f[i]="javascript:false");f.allowTransparency="true";l[d](f);try{f.contentWindow[n].open()}catch(s){a.domain=h.domain,p="javascript:var d="+n+".open();d.domain='"+h.domain+"';",f[i]=p+"void(0);"}try{var r=f.contentWindow[n];r.write(b());r.close()}catch(t){f[i]=p+'d.write("'+b().replace(/"/g,String.fromCharCode(92)+'"')+'");d.close();'}a.P(2)};a.l&&setTimeout(q,0)})()}();c[b].lv="1";return c[b]}var o="lightningjs",k=window[o]=g(o);k.require=g;k.modules=c}({});
        window.usabilla_live = lightningjs.require("usabilla_live", "https://w.usabilla.com/4061dbc431ee.js");
        var customData = {};

        if(window.pageData && pageData.content && pageData.content[0]) {
          customData.entitlementType = pageData.content[0].entitlementType;
        }
        if(window.pageData && pageData.visitor) {
          customData.accessType = pageData.visitor.accessType;
          customData.accountId = pageData.visitor.accountId;
          customData.loginStatus = pageData.visitor.loginStatus;
        }
        usabilla_live("data", {"custom": customData });
      </script>

<script type="2975f070f66ff17199d53d68-text/javascript">
        function getPageLoadTime() {
          var returnValue = '';
          if (typeof(performance) !== 'undefined' && typeof(performance.timing) == 'object') {
              var timing = performance.timing;
              var startTime = timing.redirectStart || timing.fetchStart || timing.requestStart;
              var endTime = timing.domContentLoadedEventEnd || timing.domInteractive || timing.domComplete || timing.loadEventComplete;
              if (startTime && endTime && startTime < endTime) returnValue = endTime - startTime;
          }
          return returnValue.toString();
        }
        setTimeout(function() {
          window.pageData.page.loadTime = getPageLoadTime();
        }, 0);
        try { pageDataTracker.trackPageLoad(); }
        catch(e) { console.warn("There was an error loading or running Adobe DTM: ", e); }
      </script>
<script src="https://ajax.cloudflare.com/cdn-cgi/scripts/95c75768/cloudflare-static/rocket-loader.min.js" data-cf-settings="2975f070f66ff17199d53d68-|49" defer=""></script></body>
</html>